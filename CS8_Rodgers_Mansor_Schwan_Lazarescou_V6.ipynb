{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "    \n",
    "<h1><center>Machine Learning Models and Predictive Analysis</center></h1>    \n",
    "\n",
    "<h3><center>Laura Lazarescou, John Rodgers, Maysam Mansor and Mel Schwan</center></h3>\n",
    "\n",
    "<h3><center>March 1, 2021</center></h3>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Introduction**\n",
    "\n",
    "All machine learning models are categorized as either supervised or unsupervised. Supervised learning involves learning a function that maps an input to an output based on example input-output pairs. Supervised models are then sub-categorized as a regression or classification model. In regression models, the result is continuous. Linear regression is merely finding a line that best fits the data. Decision trees are a popular model used in operations research, strategic planning, and machine learning. The last node of the decision tree, where a decision is made, is called the tree leaves. (Terence Shin - towards data science, 2020)\n",
    "\n",
    "Extreme Gradient Boosting is a model that creates a partition tree to make predictions on class-level outcomes using data subsets. New, subsequent partition trees are applied to the remaining batches of the dataset until residual error is minimized. The weight of each sample batch is adaptively changed after each round of boosting (new tree). The model focuses on building trees to correctly explain data contributing to incorrect classifications. This is repeated until optimal performance is obtained. However, XGBoost is prone to over-fitting.\n",
    "\n",
    "Support Vector Machine, is a supervised classification technique that can get pretty complicated but is intuitive at the most fundamental level. A support vector machine will find a hyperplane or a boundary between the the classes of data that maximizes the margin between the the classes. Many planes can separate the classes, but only one plane can maximize the margin or distance between the classes. This plane becomes the optimal solution for the model.\n",
    "\n",
    "The third model type, Random Forest, is an ensemble learning technique that builds off of decision trees. Random forests involve creating multiple decision trees using bootstrapped datasets of the original data and randomly selecting a subset of variables at each decision tree step. Relying on a \"majority wins\" model reduces the risk of error from an individual tree.\n",
    "\n",
    "We will train all three models in this study and vary the hyperparameters to maximize the models' accuracy values and minimize log-loss while considering the runtime requirements.\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Methods**\n",
    "\n",
    "## **Data Preparation**\n",
    "\n",
    "Financial data, containing 538 features and a binary target are the corpus used for this study. There were no feature descriptions included. The features were labeled with non-descriptive letters like v1, v2 etc.\n",
    "\n",
    "Our prepared dataset included 538 features once we applied one-hot encoding and categorical transformation to all non-numeric factors.  \n",
    "\n",
    "Factor v22 received exceptional treatment since it included over 18000 unique character values.  Using a grouping approach, we categorized v22 into 53 factors based on the rationale that a value should have at least 125 occurrences to be represented in the dataset.  If we had one-hot encoded v22 without this transformation, our final dataset would have included more than 19000 factors and it would have caused the feature space to grow intractably. \n",
    "\n",
    "Sparce matrices can lead to poor models and results. Thus we have choosen to reduce the model feature set to the most impactful factors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Types and Data Distribution**\n",
    "\n",
    "The majority of our original factors were numeric.  These factors are naturally compatible with machine learning models that we have used in this study.  Figure 1 shows the unique values counts of non-numeric features, except for factor v22.  It was removed from this plot because of its large number of unique values (18,210). v56 feature has the next greatest number of unique values.(125)\n",
    "\n",
    "![](./images/feature_unique.png)\n",
    "\n",
    "<h4><center>Unique Value Count per Non-Numeric Feature (excluding v22) (Figure 1)</center></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Validation**\n",
    "\n",
    "The models were validated using five(5)-fold cross-validation.\n",
    "The steps for model validation are given below.  Hyperameter tuning procedures and choices are discussed in each Model Discussion.\n",
    "\n",
    "\n",
    "**Model Validation Procedure**\n",
    "\n",
    "* Split data into 67% training and 33% test sets.  The train dataset consisted of 76595 rows and the test dataset included 37726 rows.  Both datasets included 538 factors.  \n",
    "\n",
    "* Use the train dataset with cross-validation to build multiple models of each type.\n",
    "\n",
    "* Estimate the log-loss of XGBoost and Random Forest models, and the accuracy for all models by using the test dataset as a validation dataset, then comparing the predicted target values to the known target values.\n",
    "\n",
    "* Statistics and performance of each model are listed in Results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Models**\n",
    "\n",
    "In this case study, we use XGBoost, Support Vector Machines, and Random Forest to model the data.\n",
    "In each section we will desrcibe how these models work, and what steps were taking to tune each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extreme Gradient Boosting**\n",
    "\n",
    "Extreme Gradient Boosting (XGBoost) is laser focused on computational speed and model performance. (Jason Brownlee; 2016, machine learning mastery)\n",
    "\n",
    "#### **Model Features** \n",
    "\n",
    "Three main forms of gradient boosting are supported:\n",
    "\n",
    "* Gradient Boosting algorithm also called gradient boosting machine including the learning rate.\n",
    "\n",
    "* Stochastic Gradient Boosting with sub-sampling at the row, column and column per split levels.\n",
    "\n",
    "* Regularized Gradient Boosting with both L1 and L2 regularization.\n",
    "\n",
    "#### **Algorithm Features** \n",
    "\n",
    "Some key algorithm implementation features include:\n",
    "\n",
    "* Sparse Aware implementation with automatic handling of missing data values.\n",
    "\n",
    "* Block Structure to support the parallelization of tree construction.\n",
    "\n",
    "* Continued Training so that you can further boost an already fitted model on new data.\n",
    "\n"
   ]
  },
  {
   "source": [
    "#### **XGBoost Hyperparameter Tuning**\n",
    "\n",
    "To find an optimal combination of hyperparameters for an XGBoost model, a randomized search of combinations was performed to identify the best performing model based on the value of log loss. Each of these hyperparameter combinations was evaluated using 5-fold cross validation of the training data set. The following hyper-paramaters and values were incorporated into the randomized grid search. (Table 1)\n",
    "\n",
    "\n",
    "| Hyperparameter | Values |   \n",
    "| ----------------- | --------------------------------- |              \n",
    "| max_depth | 6, 10, 15, 20 |\n",
    "| learning_rate | 0.001, 0.01, 0.1, 0.2, 0.3 |\n",
    "| subsample | 0.5, 0.6, 0.7, 0.8, 0.9, 1.0 |\n",
    "| colsample_bytree | 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0 |\n",
    "| colsample_bylevel | 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0 |\n",
    "| min_child_weight | 0.5, 1.0, 3.0, 5.0, 7.0, 10.0 |\n",
    "| gamma | 0, 0.25, 0.5, 1.0 |\n",
    "| reg_lambda | 0.1, 1.0, 5.0, 10.0, 50.0, 100.0 |\n",
    "\n",
    "<h4><center>Table 1</center></h4>\n",
    "\n",
    "The search model selected 5 hyperparameter combinations at random from the list above. With each of these 5 models being evaluated with a 5 cross-fold cross-validation, a total of 25 models were evaluated to determine the best-performing combination of hyperparameters. Log loss was used to identify the best-performing model, with the following combination of hyperparameters returning a log-loss value of 0.4691 and an accuracy score of 0.7683. (Table 2)\n",
    "\n",
    "\n",
    "| Hyperparameter | Value |   \n",
    "| ----------------- | ------ |  \n",
    "| max_depth | 10\n",
    "| learning_rate | 0.1 |\n",
    "| subsample | 0.9 |\n",
    "| colsample_bytree | 0.5 |\n",
    "| colsample_bylevel | 0.4 |\n",
    "| min_child_weight | 7.0 |\n",
    "| gamma | 0.5 |\n",
    "| reg_lambda | 10.0 |\n",
    "\n",
    "<h4><center>Table 2</center></h4>\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "Additional metrics for the tuned XGBoost model were also evaluated. The following figure shows the actual classes of the test data compared to the value that the model predicted. (Figure 2)\n",
    "\n",
    "\n",
    "![](./images/XGB_Class_Prediction_Error_sm.png)\n",
    "\n",
    "<h4><center>XGB Class Prediction (Figure 2)</center></h4>\n",
    "\n",
    "\n",
    "\n",
    "The figure below shows the precision, recall, and f1 score for each of the two classes. (Figure 3)\n",
    "\n",
    "\n",
    "![](./images/XGB_Classification_Report_sm.png)\n",
    "\n",
    "<h4><center>XGB Classification Report (Figure 3)</center></h4>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Support Vector Machine**\n",
    "\n",
    "TA support vector machine is a supervised learning algorithm that sorts data into two categories. It is trained with a series of data already classified into two categories, building the model as it is initially trained. The task of an SVM algorithm is to determine which category a new data point belongs in. This makes SVM a kind of non-binary linear classifier.\n",
    "\n",
    "An SVM algorithm should not only place objects into categories, but have the margins between them on a graph as wide as possible.\n",
    "\n",
    "#### **Advantages:**\n",
    "\n",
    "* Works relatively well when there is a clear margin of separation between classes\n",
    "\n",
    "* More effective in high dimensional spaces\n",
    "\n",
    "* Effective in cases where the number of dimensions is greater than the number of samples\n",
    "\n",
    "* Relatively memory efficient\n",
    "\n",
    "#### **Disadvantages:**\n",
    "\n",
    "* Algorithm is not suitable for large data sets\n",
    "\n",
    "* Does not perform very well when the data set has more noise i.e. target classes are overlapping\n",
    "\n",
    "* In cases where the number of features for each data point exceeds the number of training data samples, the SVM will underperform\n",
    "\n",
    "* Works by putting data points, above and below the classifying hyperplane there is no probabilistic explanation for the classification\n",
    "\n",
    "Estimating the SVM in these high-dimensional spaces is considerably computationally expensive. Consider the model complexity when determining whether SVM should be implemented.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SVM Hyperparameter Tuning**\n",
    "\n",
    "Hyperparameters were selected with a randomized search.GridSearchCV is a library functions that is a member of sklearn's model_selection package. It loop through predefined Hyperparameter and fit the model on the training set.In the end best parameteres from the list of hyperparameteres can be selected. In our LinearSVC we evaluated hyperparameteres(C,loss,penalty,dual and tol,max_iter) and set a range for each and at the end we got accuracy of 0.77 with best parametereswere selected and tabulated in the table which gained 0.001 for C, squared_hinge for param_loss and with param_dual become False, tol =1e-05 with 100 max_iter with 872 sec long and finally with accuracy of 0.771137.\n",
    "We also hypertuned LinearSVC for sample size 1000, 2000, 5000, 10000 and find out accuracy for each and time of fiting the model was calculated and reported respectively. We showed results of parameter tuning and accuracy in a coresponsing tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest**\n",
    "\n",
    "A Random Forest is an emsemble model created from a collection of decision trees and bootstrapped aggregated (bagged) data (Breiman, 1996; James et al, 2013).\n",
    "The following steps are used to create bagged trees:\n",
    "\n",
    "  * bootstrap sample (repeated sampling with replacement) the dataset to create $B$ separate datasets.\n",
    "  * fit a model $f^b(x)$ on each $B$ dataset.\n",
    "\n",
    "\n",
    "The bagged decision tree model is the majority vote of the classifiers resulting in the class prediction.\n",
    "Generally an ensemble should consist of a large number of decision trees.\n",
    "The number of decision trees was used as a hyperparameter and we tuned it with cross-validation.\n"
   ]
  },
  {
   "source": [
    "#### **Random Forest Hyperparameter Tuning**\n",
    "\n",
    "For Random Forest we also used GridSearchCV to randomly select combinations of hyper parameters. Outside of the Grid, the value of n_iterations is one of the most influential parameters in Random Forest.  In our base model we chose n_iterations = 10 and ran it on the complete train dataset.\n",
    "\n",
    "Below in figure 4 is a list of the default or base parameters used in our RF Base Model:\n",
    "\n",
    "![](./images/RF_base_params.png)\n",
    "\n",
    "<h4><center>Random Forest Base Parameters (Figure 4)</center></h4>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### **Grid Parameter Options**\n",
    "\n",
    "We did not include all possible parameters that could be tuned in our grid definition.  We also limited n_iterations to 5000 and in our results, the algorithm only chose 1000.  From this we learned that if one wants to test some extreme conditions or specific grid configurations, a random grid search may not be the best approach.  Figure 4 shows the grid parameters that could be chosen at random by the GridSearchCV function (Figure 5).\n",
    "\n",
    "![](./images/RF_grid_params.png)\n",
    "\n",
    "<h4><center>Random Forest Grid Parameters (Figure 5)</center></h4>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### **Top Features**\n",
    "\n",
    "We will not share the top features from all models that were run, however we did notice that the top ten features from different models were not consistent.  The feature importance graph in Figure 4 is difficult to read because there are so many features.  However, what it does show well is that no features has a significant percent of importance.  The top 10 features out of 508 features represent approximately 30% of the influence in the model.  This says that the variability of the model is high, and we have seen that in our different scenarios (Figure 6)\n",
    "\n",
    "![](./images/RF_feature_importance.png)\n",
    "\n",
    "<h4><center>Random Forest Feature Importance - All Features (Figure 6)</center></h4>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top Ten Features**\n",
    "\n",
    "| Rank | Feature ID | Importances |\n",
    "| ------------- | ------------------  | ----------  |\n",
    "| 1. | feature 44 | (0.060483) |\n",
    "| 2. | feature 11 | (0.027440) |\n",
    "| 3. | feature 9 | (0.025312) |\n",
    "| 4. | feature 96 | (0.024937) |\n",
    "| 5. | feature 35 | (0.023831) |\n",
    "| 6. | feature 20 | (0.023625) |\n",
    "| 7. | feature 29 | (0.023525) |\n",
    "| 8. | feature 13 | (0.022473) |\n",
    "| 9. | feature 0 | (0.021958) |\n",
    "| 10. | feature 338 | (0.006959) |"
   ]
  },
  {
   "source": [
    "#### **Example Tree from our Random Forest Base Model\"\n",
    "\n",
    "The Figure below demonstrates a very small portion of the total Random Forest model.  In this example, we intentionally limited the max_depth of the tree to be able to visualize each element. (Figure 7)\n",
    "\n",
    "![](./images/small_tree.png)\n",
    "<h4><center>Random Forest Tree with max_depth=3 and n_iterations=10 (Figure 7)</center></h4>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Results**"
   ]
  },
  {
   "source": [
    "## **Validation Results**\n",
    "\n",
    "Model results are provided in Table 4.  Base models were constructed with the parameters that were provided by Dr. Slater.  Hypertuned models are listed by type and variation.  We were able to provide log-loss and accuracy for XGBoost and Random Forest.  SVM does not provide log-loss so it is excluded from the table.  In addition to log-loss and accuracy, we have provided timing or estimated timing for some models.  This allows us to evaluate the cost/accuracy trade-offs.\n",
    "\n",
    "Of the Random Forest models, our best performer was also the most simple and took the least amount of processing time because we did not use RandomizedSearchCV.  The number of iterations for all randomized models was n_iter=5 and the best_params were all very similar between the different cases.  It's very possible that the default parameters just happened to be the best performing combination of tunable parameters for this dataset.  Given the relatively small amount of feature importance and the large number of features, it's also possible that the test dataset was very similar to the train dataset in its lack of correlation or internal trend.  Whatever the reason, we find that random forest outperforms the XGBoost and SVM models with this data. (Table 3)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "| Model | Log-Loss | Accuracy | Wall Time (Seconds) |\n",
    "| ------------- | ------------------  | ----------  | ----------- |\n",
    "| XGBoost (Pre-Tuned Model) | 0.585068 |  0.768330 | 8 | \n",
    "| XGBoost (RandomizedSearchCV) | 0.469189 | 0.781848 | 1534 |\n",
    "| SVM, Entire DSet|  NA |  0.7608   | 1179.79   | \n",
    "| SVM, For_1000  |  NA | 0.779    |13.2 |\n",
    "| SVM, For_2000  |  NA | 0.4075     | 28.39 |\n",
    "| SVM, For_5000  |  NA | 0.7662    |  71.83| \n",
    "| SVM, For_10000 |  NA | 0.7599     | 161.57 | \n",
    "| Random Forest Base  | 0.248184 | 0.927400 | 41 | \n",
    "| RF Tuned, 1000 Entries  | 0.483830 | 0.786000 | 120 | \n",
    "| RF Tuned, 5000 Entries  | 0.258795 | 0.917200 | 420 | \n",
    "| RF Tuned, Full Dataset  | 0.264958 | 0.913960  | 540 |\n",
    "\n",
    "<h4><center>Table of Model Performance and Results (Table 3)</center></h4>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC Comparisions for LinearSVC and Random Forest\n",
    "\n",
    "Below in figure 1, is the comparision of the AUC performance for the LinearSVC and Random Forest model. This plot indicates that the Random Forest model trends towards more true positives than LinearSVC.decision_function (Figure 8)\n",
    "\n",
    "![](./images/rf_svc_auc.png)\n",
    "<h4><center>LinearSVC and Random Forest Model Comparisions (Figure 8)</center></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion**\n",
    "\n"
   ]
  },
  {
   "source": [
    "The best accuracy and log-loss values of our Random Forest (RF), Support Vector Machine (SVM), and XGBoost tuned models varied greatly depending on the hyperparameter tuning. Random Forest accuracy results were significantly higher than the other models. XGBoost and SVM were similar in their accuracy, but their execution time was significantly different.  The main difference between all models appeared in the compute time required to ensure these results. The log-loss values for XGBoost were also higher than Random Forest. This difference in the predicted probability from the actual value in XGBoost and Random Forest makes our choice less difficult if you have the computing power. Random Forest appears to be the best model for this type of data set.\n",
    "\n",
    "SVM is a useful model for small data sets that are highly dimensional. If you have a Big Data corpus, then XGBoost would be a good model. Random Forest works with categorical features very well and can handle high dimensional spaces and large numbers of training examples.\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **References**\n",
    "\n",
    "Terence Shin (2020), towards data science - All Machine Learning Models Explained in 6 Minutes\n",
    "\n",
    "Breiman, L. (1996). Bagging Predictors. Machine Learning, 24, 123-140.\n",
    "\n",
    "CJason Brownlee (2016), machine learning mastery - A Gentle Introduction to XGBoost for Applied Machine Learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tabulate import tabulate\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from pprint import pprint\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "import sklearn.feature_selection as fs\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Directory for image files - Comment out if you are not LL\n",
    "\n",
    "import os\n",
    "os.chdir('C:\\\\SMU_Local\\\\SMU_T5_QTW_CapA\\\\QTW_7333\\\\Unit 7 and 8\\\\case_study_81_2\\\\CS8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\SMU_Local\\\\SMU_T5_QTW_CapA\\\\QTW_7333\\\\Unit 7 and 8\\\\case_study_81_2\\\\CS8'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Prepare for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "# load data and separate target variable from dataset\n",
    "train = pd.read_csv('Data/case_8.csv')\n",
    "target = train['target']\n",
    "train.drop(['target'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(target, open(\"Pickle/target.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114321 entries, 0 to 114320\n",
      "Data columns (total 132 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   ID      int64  \n",
      " 1   v1      float64\n",
      " 2   v2      float64\n",
      " 3   v3      object \n",
      " 4   v4      float64\n",
      " 5   v5      float64\n",
      " 6   v6      float64\n",
      " 7   v7      float64\n",
      " 8   v8      float64\n",
      " 9   v9      float64\n",
      " 10  v10     float64\n",
      " 11  v11     float64\n",
      " 12  v12     float64\n",
      " 13  v13     float64\n",
      " 14  v14     float64\n",
      " 15  v15     float64\n",
      " 16  v16     float64\n",
      " 17  v17     float64\n",
      " 18  v18     float64\n",
      " 19  v19     float64\n",
      " 20  v20     float64\n",
      " 21  v21     float64\n",
      " 22  v22     object \n",
      " 23  v23     float64\n",
      " 24  v24     object \n",
      " 25  v25     float64\n",
      " 26  v26     float64\n",
      " 27  v27     float64\n",
      " 28  v28     float64\n",
      " 29  v29     float64\n",
      " 30  v30     object \n",
      " 31  v31     object \n",
      " 32  v32     float64\n",
      " 33  v33     float64\n",
      " 34  v34     float64\n",
      " 35  v35     float64\n",
      " 36  v36     float64\n",
      " 37  v37     float64\n",
      " 38  v38     int64  \n",
      " 39  v39     float64\n",
      " 40  v40     float64\n",
      " 41  v41     float64\n",
      " 42  v42     float64\n",
      " 43  v43     float64\n",
      " 44  v44     float64\n",
      " 45  v45     float64\n",
      " 46  v46     float64\n",
      " 47  v47     object \n",
      " 48  v48     float64\n",
      " 49  v49     float64\n",
      " 50  v50     float64\n",
      " 51  v51     float64\n",
      " 52  v52     object \n",
      " 53  v53     float64\n",
      " 54  v54     float64\n",
      " 55  v55     float64\n",
      " 56  v56     object \n",
      " 57  v57     float64\n",
      " 58  v58     float64\n",
      " 59  v59     float64\n",
      " 60  v60     float64\n",
      " 61  v61     float64\n",
      " 62  v62     int64  \n",
      " 63  v63     float64\n",
      " 64  v64     float64\n",
      " 65  v65     float64\n",
      " 66  v66     object \n",
      " 67  v67     float64\n",
      " 68  v68     float64\n",
      " 69  v69     float64\n",
      " 70  v70     float64\n",
      " 71  v71     object \n",
      " 72  v72     int64  \n",
      " 73  v73     float64\n",
      " 74  v74     object \n",
      " 75  v75     object \n",
      " 76  v76     float64\n",
      " 77  v77     float64\n",
      " 78  v78     float64\n",
      " 79  v79     object \n",
      " 80  v80     float64\n",
      " 81  v81     float64\n",
      " 82  v82     float64\n",
      " 83  v83     float64\n",
      " 84  v84     float64\n",
      " 85  v85     float64\n",
      " 86  v86     float64\n",
      " 87  v87     float64\n",
      " 88  v88     float64\n",
      " 89  v89     float64\n",
      " 90  v90     float64\n",
      " 91  v91     object \n",
      " 92  v92     float64\n",
      " 93  v93     float64\n",
      " 94  v94     float64\n",
      " 95  v95     float64\n",
      " 96  v96     float64\n",
      " 97  v97     float64\n",
      " 98  v98     float64\n",
      " 99  v99     float64\n",
      " 100 v100    float64\n",
      " 101 v101    float64\n",
      " 102 v102    float64\n",
      " 103 v103    float64\n",
      " 104 v104    float64\n",
      " 105 v105    float64\n",
      " 106 v106    float64\n",
      " 107 v107    object \n",
      " 108 v108    float64\n",
      " 109 v109    float64\n",
      " 110 v110    object \n",
      " 111 v111    float64\n",
      " 112 v112    object \n",
      " 113 v113    object \n",
      " 114 v114    float64\n",
      " 115 v115    float64\n",
      " 116 v116    float64\n",
      " 117 v117    float64\n",
      " 118 v118    float64\n",
      " 119 v119    float64\n",
      " 120 v120    float64\n",
      " 121 v121    float64\n",
      " 122 v122    float64\n",
      " 123 v123    float64\n",
      " 124 v124    float64\n",
      " 125 v125    object \n",
      " 126 v126    float64\n",
      " 127 v127    float64\n",
      " 128 v128    float64\n",
      " 129 v129    int64  \n",
      " 130 v130    float64\n",
      " 131 v131    float64\n",
      "dtypes: float64(108), int64(5), object(19)\n",
      "memory usage: 115.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# evaluate data types\n",
    "train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate object data type columns\n",
    "train_object_dtype_cols = train.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v3</th>\n",
       "      <th>v22</th>\n",
       "      <th>v24</th>\n",
       "      <th>v30</th>\n",
       "      <th>v31</th>\n",
       "      <th>v47</th>\n",
       "      <th>v52</th>\n",
       "      <th>v56</th>\n",
       "      <th>v66</th>\n",
       "      <th>v71</th>\n",
       "      <th>v74</th>\n",
       "      <th>v75</th>\n",
       "      <th>v79</th>\n",
       "      <th>v91</th>\n",
       "      <th>v107</th>\n",
       "      <th>v110</th>\n",
       "      <th>v112</th>\n",
       "      <th>v113</th>\n",
       "      <th>v125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>XDX</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>DI</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>O</td>\n",
       "      <td>G</td>\n",
       "      <td>AU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>GUV</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>DY</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>U</td>\n",
       "      <td>G</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>FQ</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>AS</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "      <td>AE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>ACUE</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>BW</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>J</td>\n",
       "      <td>G</td>\n",
       "      <td>CJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>HIT</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>H</td>\n",
       "      <td>BW</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  v3   v22 v24 v30 v31 v47 v52 v56 v66 v71 v74 v75 v79 v91 v107 v110 v112  \\\n",
       "0  C   XDX   C   C   A   C   G  DI   C   F   B   D   E   A    E    B    O   \n",
       "1  C   GUV   C   C   A   E   G  DY   A   F   B   D   D   B    B    A    U   \n",
       "2  C    FQ   E   C   A   C   F  AS   A   B   B   B   E   G    C    B    S   \n",
       "3  C  ACUE   D   C   B   C   H  BW   A   F   B   D   B   B    B    B    J   \n",
       "4  C   HIT   E   C   A   I   H  BW   C   F   B   D   C   G    C    A    T   \n",
       "\n",
       "  v113 v125  \n",
       "0    G   AU  \n",
       "1    G   AF  \n",
       "2    G   AE  \n",
       "3    G   CJ  \n",
       "4    G    Z  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review head of object columns\n",
    "train_object_dtype_cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v3          3\n",
       "v22     18210\n",
       "v24         5\n",
       "v30         7\n",
       "v31         3\n",
       "v47        10\n",
       "v52        12\n",
       "v56       122\n",
       "v66         3\n",
       "v71         9\n",
       "v74         3\n",
       "v75         4\n",
       "v79        18\n",
       "v91         7\n",
       "v107        7\n",
       "v110        3\n",
       "v112       22\n",
       "v113       36\n",
       "v125       90\n",
       "Name: unique, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count unique values in object columns\n",
    "train_object_dtype_cols.describe(include='all').loc['unique', :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"278.964375pt\" version=\"1.1\" viewBox=\"0 0 375.2875 278.964375\" width=\"375.2875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 278.964375 \n",
       "L 375.2875 278.964375 \n",
       "L 375.2875 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 33.2875 239.758125 \n",
       "L 368.0875 239.758125 \n",
       "L 368.0875 22.318125 \n",
       "L 33.2875 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 37.9375 239.758125 \n",
       "L 47.2375 239.758125 \n",
       "L 47.2375 234.665853 \n",
       "L 37.9375 234.665853 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 56.5375 239.758125 \n",
       "L 65.8375 239.758125 \n",
       "L 65.8375 231.271006 \n",
       "L 56.5375 231.271006 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 75.1375 239.758125 \n",
       "L 84.4375 239.758125 \n",
       "L 84.4375 227.876158 \n",
       "L 75.1375 227.876158 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 93.7375 239.758125 \n",
       "L 103.0375 239.758125 \n",
       "L 103.0375 234.665853 \n",
       "L 93.7375 234.665853 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_7\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 112.3375 239.758125 \n",
       "L 121.6375 239.758125 \n",
       "L 121.6375 222.783886 \n",
       "L 112.3375 222.783886 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 130.9375 239.758125 \n",
       "L 140.2375 239.758125 \n",
       "L 140.2375 219.389038 \n",
       "L 130.9375 219.389038 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 149.5375 239.758125 \n",
       "L 158.8375 239.758125 \n",
       "L 158.8375 32.672411 \n",
       "L 149.5375 32.672411 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 168.1375 239.758125 \n",
       "L 177.4375 239.758125 \n",
       "L 177.4375 234.665853 \n",
       "L 168.1375 234.665853 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 186.7375 239.758125 \n",
       "L 196.0375 239.758125 \n",
       "L 196.0375 224.48131 \n",
       "L 186.7375 224.48131 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 205.3375 239.758125 \n",
       "L 214.6375 239.758125 \n",
       "L 214.6375 234.665853 \n",
       "L 205.3375 234.665853 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 223.9375 239.758125 \n",
       "L 233.2375 239.758125 \n",
       "L 233.2375 232.968429 \n",
       "L 223.9375 232.968429 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 242.5375 239.758125 \n",
       "L 251.8375 239.758125 \n",
       "L 251.8375 209.204495 \n",
       "L 242.5375 209.204495 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 261.1375 239.758125 \n",
       "L 270.4375 239.758125 \n",
       "L 270.4375 227.876158 \n",
       "L 261.1375 227.876158 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 279.7375 239.758125 \n",
       "L 289.0375 239.758125 \n",
       "L 289.0375 227.876158 \n",
       "L 279.7375 227.876158 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_17\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 298.3375 239.758125 \n",
       "L 307.6375 239.758125 \n",
       "L 307.6375 234.665853 \n",
       "L 298.3375 234.665853 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 316.9375 239.758125 \n",
       "L 326.2375 239.758125 \n",
       "L 326.2375 202.414799 \n",
       "L 316.9375 202.414799 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_19\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 335.5375 239.758125 \n",
       "L 344.8375 239.758125 \n",
       "L 344.8375 178.650865 \n",
       "L 335.5375 178.650865 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_20\">\n",
       "    <path clip-path=\"url(#p2314eb82a8)\" d=\"M 354.1375 239.758125 \n",
       "L 363.4375 239.758125 \n",
       "L 363.4375 86.989975 \n",
       "L 354.1375 86.989975 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"md8e60c2ce2\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.5875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- v3 -->\n",
       "      <defs>\n",
       "       <path d=\"M 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 8.796875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "L 35.6875 0 \n",
       "L 23.484375 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-118\"/>\n",
       "       <path d=\"M 40.578125 39.3125 \n",
       "Q 47.65625 37.796875 51.625 33 \n",
       "Q 55.609375 28.21875 55.609375 21.1875 \n",
       "Q 55.609375 10.40625 48.1875 4.484375 \n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \n",
       "Q 12.796875 0.390625 7.625 2.203125 \n",
       "L 7.625 11.71875 \n",
       "Q 11.71875 9.328125 16.59375 8.109375 \n",
       "Q 21.484375 6.890625 26.8125 6.890625 \n",
       "Q 36.078125 6.890625 40.9375 10.546875 \n",
       "Q 45.796875 14.203125 45.796875 21.1875 \n",
       "Q 45.796875 27.640625 41.28125 31.265625 \n",
       "Q 36.765625 34.90625 28.71875 34.90625 \n",
       "L 20.21875 34.90625 \n",
       "L 20.21875 43.015625 \n",
       "L 29.109375 43.015625 \n",
       "Q 36.375 43.015625 40.234375 45.921875 \n",
       "Q 44.09375 48.828125 44.09375 54.296875 \n",
       "Q 44.09375 59.90625 40.109375 62.90625 \n",
       "Q 36.140625 65.921875 28.71875 65.921875 \n",
       "Q 24.65625 65.921875 20.015625 65.03125 \n",
       "Q 15.375 64.15625 9.8125 62.3125 \n",
       "L 9.8125 71.09375 \n",
       "Q 15.4375 72.65625 20.34375 73.4375 \n",
       "Q 25.25 74.21875 29.59375 74.21875 \n",
       "Q 40.828125 74.21875 47.359375 69.109375 \n",
       "Q 53.90625 64.015625 53.90625 55.328125 \n",
       "Q 53.90625 49.265625 50.4375 45.09375 \n",
       "Q 46.96875 40.921875 40.578125 39.3125 \n",
       "z\n",
       "\" id=\"DejaVuSans-51\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(45.346875 259.039375)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"61.1875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- v24 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(63.946875 265.401875)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"79.7875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- v30 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(82.546875 265.401875)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"98.3875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- v31 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(101.146875 265.401875)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"116.9875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- v47 -->\n",
       "      <defs>\n",
       "       <path d=\"M 8.203125 72.90625 \n",
       "L 55.078125 72.90625 \n",
       "L 55.078125 68.703125 \n",
       "L 28.609375 0 \n",
       "L 18.3125 0 \n",
       "L 43.21875 64.59375 \n",
       "L 8.203125 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-55\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(119.746875 265.401875)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"135.5875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- v52 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(138.346875 265.401875)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"154.1875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- v56 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(156.946875 265.401875)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"172.7875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- v66 -->\n",
       "      <g transform=\"translate(175.546875 265.401875)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"191.3875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- v71 -->\n",
       "      <g transform=\"translate(194.146875 265.401875)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_10\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"209.9875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- v74 -->\n",
       "      <g transform=\"translate(212.746875 265.401875)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_11\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"228.5875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- v75 -->\n",
       "      <g transform=\"translate(231.346875 265.401875)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_12\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"247.1875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- v79 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.984375 1.515625 \n",
       "L 10.984375 10.5 \n",
       "Q 14.703125 8.734375 18.5 7.8125 \n",
       "Q 22.3125 6.890625 25.984375 6.890625 \n",
       "Q 35.75 6.890625 40.890625 13.453125 \n",
       "Q 46.046875 20.015625 46.78125 33.40625 \n",
       "Q 43.953125 29.203125 39.59375 26.953125 \n",
       "Q 35.25 24.703125 29.984375 24.703125 \n",
       "Q 19.046875 24.703125 12.671875 31.3125 \n",
       "Q 6.296875 37.9375 6.296875 49.421875 \n",
       "Q 6.296875 60.640625 12.9375 67.421875 \n",
       "Q 19.578125 74.21875 30.609375 74.21875 \n",
       "Q 43.265625 74.21875 49.921875 64.515625 \n",
       "Q 56.59375 54.828125 56.59375 36.375 \n",
       "Q 56.59375 19.140625 48.40625 8.859375 \n",
       "Q 40.234375 -1.421875 26.421875 -1.421875 \n",
       "Q 22.703125 -1.421875 18.890625 -0.6875 \n",
       "Q 15.09375 0.046875 10.984375 1.515625 \n",
       "z\n",
       "M 30.609375 32.421875 \n",
       "Q 37.25 32.421875 41.125 36.953125 \n",
       "Q 45.015625 41.5 45.015625 49.421875 \n",
       "Q 45.015625 57.28125 41.125 61.84375 \n",
       "Q 37.25 66.40625 30.609375 66.40625 \n",
       "Q 23.96875 66.40625 20.09375 61.84375 \n",
       "Q 16.21875 57.28125 16.21875 49.421875 \n",
       "Q 16.21875 41.5 20.09375 36.953125 \n",
       "Q 23.96875 32.421875 30.609375 32.421875 \n",
       "z\n",
       "\" id=\"DejaVuSans-57\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(249.946875 265.401875)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_13\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"265.7875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- v91 -->\n",
       "      <g transform=\"translate(268.546875 265.401875)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-57\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_14\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"284.3875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- v107 -->\n",
       "      <g transform=\"translate(287.146875 271.764375)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"186.425781\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_15\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.9875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- v110 -->\n",
       "      <g transform=\"translate(305.746875 271.764375)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"186.425781\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_16\">\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"321.5875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- v112 -->\n",
       "      <g transform=\"translate(324.346875 271.764375)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"186.425781\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_17\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"340.1875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_17\">\n",
       "      <!-- v113 -->\n",
       "      <g transform=\"translate(342.946875 271.764375)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"186.425781\" xlink:href=\"#DejaVuSans-51\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_18\">\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"358.7875\" xlink:href=\"#md8e60c2ce2\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_18\">\n",
       "      <!-- v125 -->\n",
       "      <g transform=\"translate(361.546875 271.764375)rotate(-90)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-118\"/>\n",
       "       <use x=\"59.179688\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"122.802734\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"186.425781\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m18a9869115\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m18a9869115\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(19.925 243.557344)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m18a9869115\" y=\"205.809647\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_20\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(13.5625 209.608866)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m18a9869115\" y=\"171.861169\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_21\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(13.5625 175.660388)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m18a9869115\" y=\"137.912692\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_22\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(13.5625 141.71191)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m18a9869115\" y=\"103.964214\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_23\">\n",
       "      <!-- 80 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(13.5625 107.763433)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_24\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m18a9869115\" y=\"70.015736\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_24\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(7.2 73.814955)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m18a9869115\" y=\"36.067258\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_25\">\n",
       "      <!-- 120 -->\n",
       "      <g transform=\"translate(7.2 39.866477)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_21\">\n",
       "    <path d=\"M 33.2875 239.758125 \n",
       "L 33.2875 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_22\">\n",
       "    <path d=\"M 368.0875 239.758125 \n",
       "L 368.0875 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_23\">\n",
       "    <path d=\"M 33.2875 239.758125 \n",
       "L 368.0875 239.758125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_24\">\n",
       "    <path d=\"M 33.2875 22.318125 \n",
       "L 368.0875 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_26\">\n",
       "    <!-- Feature Unique Value Count -->\n",
       "    <defs>\n",
       "     <path d=\"M 9.8125 72.90625 \n",
       "L 51.703125 72.90625 \n",
       "L 51.703125 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.109375 \n",
       "L 48.578125 43.109375 \n",
       "L 48.578125 34.8125 \n",
       "L 19.671875 34.8125 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-70\"/>\n",
       "     <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "     <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "     <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "     <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-117\"/>\n",
       "     <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "     <path id=\"DejaVuSans-32\"/>\n",
       "     <path d=\"M 8.6875 72.90625 \n",
       "L 18.609375 72.90625 \n",
       "L 18.609375 28.609375 \n",
       "Q 18.609375 16.890625 22.84375 11.734375 \n",
       "Q 27.09375 6.59375 36.625 6.59375 \n",
       "Q 46.09375 6.59375 50.34375 11.734375 \n",
       "Q 54.59375 16.890625 54.59375 28.609375 \n",
       "L 54.59375 72.90625 \n",
       "L 64.5 72.90625 \n",
       "L 64.5 27.390625 \n",
       "Q 64.5 13.140625 57.4375 5.859375 \n",
       "Q 50.390625 -1.421875 36.625 -1.421875 \n",
       "Q 22.796875 -1.421875 15.734375 5.859375 \n",
       "Q 8.6875 13.140625 8.6875 27.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-85\"/>\n",
       "     <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "     <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "     <path d=\"M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "M 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "L 45.40625 54.6875 \n",
       "L 54.390625 54.6875 \n",
       "L 54.390625 -20.796875 \n",
       "L 45.40625 -20.796875 \n",
       "z\n",
       "\" id=\"DejaVuSans-113\"/>\n",
       "     <path d=\"M 28.609375 0 \n",
       "L 0.78125 72.90625 \n",
       "L 11.078125 72.90625 \n",
       "L 34.1875 11.53125 \n",
       "L 57.328125 72.90625 \n",
       "L 67.578125 72.90625 \n",
       "L 39.796875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-86\"/>\n",
       "     <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "     <path d=\"M 64.40625 67.28125 \n",
       "L 64.40625 56.890625 \n",
       "Q 59.421875 61.53125 53.78125 63.8125 \n",
       "Q 48.140625 66.109375 41.796875 66.109375 \n",
       "Q 29.296875 66.109375 22.65625 58.46875 \n",
       "Q 16.015625 50.828125 16.015625 36.375 \n",
       "Q 16.015625 21.96875 22.65625 14.328125 \n",
       "Q 29.296875 6.6875 41.796875 6.6875 \n",
       "Q 48.140625 6.6875 53.78125 8.984375 \n",
       "Q 59.421875 11.28125 64.40625 15.921875 \n",
       "L 64.40625 5.609375 \n",
       "Q 59.234375 2.09375 53.4375 0.328125 \n",
       "Q 47.65625 -1.421875 41.21875 -1.421875 \n",
       "Q 24.65625 -1.421875 15.125 8.703125 \n",
       "Q 5.609375 18.84375 5.609375 36.375 \n",
       "Q 5.609375 53.953125 15.125 64.078125 \n",
       "Q 24.65625 74.21875 41.21875 74.21875 \n",
       "Q 47.75 74.21875 53.53125 72.484375 \n",
       "Q 59.328125 70.75 64.40625 67.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-67\"/>\n",
       "     <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(115.9225 16.318125)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "     <use x=\"57.441406\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"118.964844\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"180.244141\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "     <use x=\"219.453125\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"282.832031\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"323.914062\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"385.4375\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"417.224609\" xlink:href=\"#DejaVuSans-85\"/>\n",
       "     <use x=\"490.417969\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     <use x=\"553.796875\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "     <use x=\"581.580078\" xlink:href=\"#DejaVuSans-113\"/>\n",
       "     <use x=\"645.056641\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"708.435547\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"769.958984\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"801.746094\" xlink:href=\"#DejaVuSans-86\"/>\n",
       "     <use x=\"870.044922\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"931.324219\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"959.107422\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"1022.486328\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"1084.009766\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"1115.796875\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "     <use x=\"1185.621094\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"1246.802734\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"1310.181641\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     <use x=\"1373.560547\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_25\">\n",
       "     <path d=\"M 294.795313 44.99625 \n",
       "L 361.0875 44.99625 \n",
       "Q 363.0875 44.99625 363.0875 42.99625 \n",
       "L 363.0875 29.318125 \n",
       "Q 363.0875 27.318125 361.0875 27.318125 \n",
       "L 294.795313 27.318125 \n",
       "Q 292.795313 27.318125 292.795313 29.318125 \n",
       "L 292.795313 42.99625 \n",
       "Q 292.795313 44.99625 294.795313 44.99625 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"patch_26\">\n",
       "     <path d=\"M 296.795313 38.916562 \n",
       "L 316.795313 38.916562 \n",
       "L 316.795313 31.916562 \n",
       "L 296.795313 31.916562 \n",
       "z\n",
       "\" style=\"fill:#1f77b4;\"/>\n",
       "    </g>\n",
       "    <g id=\"text_27\">\n",
       "     <!-- unique -->\n",
       "     <g transform=\"translate(324.795313 38.916562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-117\"/>\n",
       "      <use x=\"63.378906\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"126.757812\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"154.541016\" xlink:href=\"#DejaVuSans-113\"/>\n",
       "      <use x=\"218.017578\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "      <use x=\"281.396484\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p2314eb82a8\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count unique values without v22 in object columns and plot\n",
    "unique_series = train_object_dtype_cols.describe(include='all').loc['unique', :]\n",
    "unique_df = pd.DataFrame(unique_series)\n",
    "unique_df = unique_df.drop(['v22'])\n",
    "ax = unique_df.plot.bar(title='Feature Unique Value Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      61.000000\n",
       "mean      281.704918\n",
       "std       431.560670\n",
       "min       126.000000\n",
       "25%       147.000000\n",
       "50%       167.000000\n",
       "75%       226.000000\n",
       "max      2886.000000\n",
       "Name: v22, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA on v22 feature\n",
    "\n",
    "v22_counts = train_object_dtype_cols.groupby('v22').v22.count()\n",
    "v22_counts.describe()\n",
    "v22_counts.median()\n",
    "v22_counts[v22_counts>125].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 22:04:04,974 [35816] WARNING  py.warnings:110: [JupyterRequire] C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114321 entries, 0 to 114320\n",
      "Data columns (total 19 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   v3      114321 non-null  object\n",
      " 1   v22     17184 non-null   object\n",
      " 2   v24     114321 non-null  object\n",
      " 3   v30     114321 non-null  object\n",
      " 4   v31     114321 non-null  object\n",
      " 5   v47     114321 non-null  object\n",
      " 6   v52     114321 non-null  object\n",
      " 7   v56     114321 non-null  object\n",
      " 8   v66     114321 non-null  object\n",
      " 9   v71     114321 non-null  object\n",
      " 10  v74     114321 non-null  object\n",
      " 11  v75     114321 non-null  object\n",
      " 12  v79     114321 non-null  object\n",
      " 13  v91     114321 non-null  object\n",
      " 14  v107    114321 non-null  object\n",
      " 15  v110    114321 non-null  object\n",
      " 16  v112    114321 non-null  object\n",
      " 17  v113    114321 non-null  object\n",
      " 18  v125    114321 non-null  object\n",
      "dtypes: object(19)\n",
      "memory usage: 16.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count      61.000000\n",
       "mean      281.704918\n",
       "std       431.560670\n",
       "min       126.000000\n",
       "25%       147.000000\n",
       "50%       167.000000\n",
       "75%       226.000000\n",
       "max      2886.000000\n",
       "Name: v22, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get counts of unique values in v22\n",
    "val = train_object_dtype_cols['v22'].value_counts()\n",
    "# identify values with counts > 125\n",
    "y = val[val < 125].index\n",
    "# replace values with count < 125 with NaN\n",
    "train_object_dtype_cols['v22'] = train_object_dtype_cols['v22'].replace({x:math.nan for x in y})\n",
    "# Output v22 information after removing values less than 125\n",
    "train_object_dtype_cols.info()\n",
    "train_object_dtype_cols.groupby('v22').v22.count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114321 entries, 0 to 114320\n",
      "Data columns (total 425 columns):\n",
      " #   Column    Dtype\n",
      "---  ------    -----\n",
      " 0   v3_A      uint8\n",
      " 1   v3_B      uint8\n",
      " 2   v3_C      uint8\n",
      " 3   v22_AAPP  uint8\n",
      " 4   v22_ABF   uint8\n",
      " 5   v22_ABOF  uint8\n",
      " 6   v22_ACHJ  uint8\n",
      " 7   v22_ACWE  uint8\n",
      " 8   v22_ACXD  uint8\n",
      " 9   v22_ADDF  uint8\n",
      " 10  v22_ADGN  uint8\n",
      " 11  v22_ADMI  uint8\n",
      " 12  v22_ADMP  uint8\n",
      " 13  v22_AFOZ  uint8\n",
      " 14  v22_AFYU  uint8\n",
      " 15  v22_AGDF  uint8\n",
      " 16  v22_AGON  uint8\n",
      " 17  v22_AGZT  uint8\n",
      " 18  v22_AHE   uint8\n",
      " 19  v22_AJQ   uint8\n",
      " 20  v22_AMR   uint8\n",
      " 21  v22_AWT   uint8\n",
      " 22  v22_AXH   uint8\n",
      " 23  v22_BLE   uint8\n",
      " 24  v22_DJU   uint8\n",
      " 25  v22_EJC   uint8\n",
      " 26  v22_GBS   uint8\n",
      " 27  v22_GEB   uint8\n",
      " 28  v22_GEJ   uint8\n",
      " 29  v22_HDD   uint8\n",
      " 30  v22_HUU   uint8\n",
      " 31  v22_HZE   uint8\n",
      " 32  v22_JGY   uint8\n",
      " 33  v22_KLZ   uint8\n",
      " 34  v22_LIP   uint8\n",
      " 35  v22_MNZ   uint8\n",
      " 36  v22_MQE   uint8\n",
      " 37  v22_NGS   uint8\n",
      " 38  v22_NRT   uint8\n",
      " 39  v22_NWG   uint8\n",
      " 40  v22_NXE   uint8\n",
      " 41  v22_OFD   uint8\n",
      " 42  v22_PBC   uint8\n",
      " 43  v22_PFR   uint8\n",
      " 44  v22_PSE   uint8\n",
      " 45  v22_PTJ   uint8\n",
      " 46  v22_PTO   uint8\n",
      " 47  v22_PWR   uint8\n",
      " 48  v22_QKI   uint8\n",
      " 49  v22_QKP   uint8\n",
      " 50  v22_QVR   uint8\n",
      " 51  v22_RIC   uint8\n",
      " 52  v22_ROZ   uint8\n",
      " 53  v22_TG    uint8\n",
      " 54  v22_TVR   uint8\n",
      " 55  v22_UAG   uint8\n",
      " 56  v22_VVI   uint8\n",
      " 57  v22_VZF   uint8\n",
      " 58  v22_WFT   uint8\n",
      " 59  v22_WNI   uint8\n",
      " 60  v22_WRI   uint8\n",
      " 61  v22_YEP   uint8\n",
      " 62  v22_YGJ   uint8\n",
      " 63  v22_YOD   uint8\n",
      " 64  v24_A     uint8\n",
      " 65  v24_B     uint8\n",
      " 66  v24_C     uint8\n",
      " 67  v24_D     uint8\n",
      " 68  v24_E     uint8\n",
      " 69  v30_A     uint8\n",
      " 70  v30_B     uint8\n",
      " 71  v30_C     uint8\n",
      " 72  v30_D     uint8\n",
      " 73  v30_E     uint8\n",
      " 74  v30_F     uint8\n",
      " 75  v30_G     uint8\n",
      " 76  v31_A     uint8\n",
      " 77  v31_B     uint8\n",
      " 78  v31_C     uint8\n",
      " 79  v47_A     uint8\n",
      " 80  v47_B     uint8\n",
      " 81  v47_C     uint8\n",
      " 82  v47_D     uint8\n",
      " 83  v47_E     uint8\n",
      " 84  v47_F     uint8\n",
      " 85  v47_G     uint8\n",
      " 86  v47_H     uint8\n",
      " 87  v47_I     uint8\n",
      " 88  v47_J     uint8\n",
      " 89  v52_A     uint8\n",
      " 90  v52_B     uint8\n",
      " 91  v52_C     uint8\n",
      " 92  v52_D     uint8\n",
      " 93  v52_E     uint8\n",
      " 94  v52_F     uint8\n",
      " 95  v52_G     uint8\n",
      " 96  v52_H     uint8\n",
      " 97  v52_I     uint8\n",
      " 98  v52_J     uint8\n",
      " 99  v52_K     uint8\n",
      " 100 v52_L     uint8\n",
      " 101 v56_A     uint8\n",
      " 102 v56_AA    uint8\n",
      " 103 v56_AB    uint8\n",
      " 104 v56_AC    uint8\n",
      " 105 v56_AE    uint8\n",
      " 106 v56_AF    uint8\n",
      " 107 v56_AG    uint8\n",
      " 108 v56_AH    uint8\n",
      " 109 v56_AI    uint8\n",
      " 110 v56_AJ    uint8\n",
      " 111 v56_AK    uint8\n",
      " 112 v56_AL    uint8\n",
      " 113 v56_AM    uint8\n",
      " 114 v56_AN    uint8\n",
      " 115 v56_AO    uint8\n",
      " 116 v56_AP    uint8\n",
      " 117 v56_AR    uint8\n",
      " 118 v56_AS    uint8\n",
      " 119 v56_AT    uint8\n",
      " 120 v56_AU    uint8\n",
      " 121 v56_AV    uint8\n",
      " 122 v56_AW    uint8\n",
      " 123 v56_AX    uint8\n",
      " 124 v56_AY    uint8\n",
      " 125 v56_AZ    uint8\n",
      " 126 v56_B     uint8\n",
      " 127 v56_BA    uint8\n",
      " 128 v56_BC    uint8\n",
      " 129 v56_BD    uint8\n",
      " 130 v56_BE    uint8\n",
      " 131 v56_BF    uint8\n",
      " 132 v56_BG    uint8\n",
      " 133 v56_BH    uint8\n",
      " 134 v56_BI    uint8\n",
      " 135 v56_BJ    uint8\n",
      " 136 v56_BK    uint8\n",
      " 137 v56_BL    uint8\n",
      " 138 v56_BM    uint8\n",
      " 139 v56_BN    uint8\n",
      " 140 v56_BO    uint8\n",
      " 141 v56_BP    uint8\n",
      " 142 v56_BQ    uint8\n",
      " 143 v56_BR    uint8\n",
      " 144 v56_BS    uint8\n",
      " 145 v56_BT    uint8\n",
      " 146 v56_BU    uint8\n",
      " 147 v56_BV    uint8\n",
      " 148 v56_BW    uint8\n",
      " 149 v56_BX    uint8\n",
      " 150 v56_BY    uint8\n",
      " 151 v56_BZ    uint8\n",
      " 152 v56_C     uint8\n",
      " 153 v56_CA    uint8\n",
      " 154 v56_CB    uint8\n",
      " 155 v56_CC    uint8\n",
      " 156 v56_CD    uint8\n",
      " 157 v56_CE    uint8\n",
      " 158 v56_CF    uint8\n",
      " 159 v56_CG    uint8\n",
      " 160 v56_CH    uint8\n",
      " 161 v56_CI    uint8\n",
      " 162 v56_CJ    uint8\n",
      " 163 v56_CK    uint8\n",
      " 164 v56_CL    uint8\n",
      " 165 v56_CM    uint8\n",
      " 166 v56_CN    uint8\n",
      " 167 v56_CO    uint8\n",
      " 168 v56_CP    uint8\n",
      " 169 v56_CQ    uint8\n",
      " 170 v56_CS    uint8\n",
      " 171 v56_CT    uint8\n",
      " 172 v56_CV    uint8\n",
      " 173 v56_CW    uint8\n",
      " 174 v56_CX    uint8\n",
      " 175 v56_CY    uint8\n",
      " 176 v56_CZ    uint8\n",
      " 177 v56_D     uint8\n",
      " 178 v56_DA    uint8\n",
      " 179 v56_DB    uint8\n",
      " 180 v56_DC    uint8\n",
      " 181 v56_DD    uint8\n",
      " 182 v56_DE    uint8\n",
      " 183 v56_DF    uint8\n",
      " 184 v56_DG    uint8\n",
      " 185 v56_DH    uint8\n",
      " 186 v56_DI    uint8\n",
      " 187 v56_DJ    uint8\n",
      " 188 v56_DK    uint8\n",
      " 189 v56_DL    uint8\n",
      " 190 v56_DM    uint8\n",
      " 191 v56_DN    uint8\n",
      " 192 v56_DO    uint8\n",
      " 193 v56_DP    uint8\n",
      " 194 v56_DQ    uint8\n",
      " 195 v56_DR    uint8\n",
      " 196 v56_DS    uint8\n",
      " 197 v56_DT    uint8\n",
      " 198 v56_DU    uint8\n",
      " 199 v56_DV    uint8\n",
      " 200 v56_DW    uint8\n",
      " 201 v56_DX    uint8\n",
      " 202 v56_DY    uint8\n",
      " 203 v56_DZ    uint8\n",
      " 204 v56_E     uint8\n",
      " 205 v56_F     uint8\n",
      " 206 v56_G     uint8\n",
      " 207 v56_H     uint8\n",
      " 208 v56_I     uint8\n",
      " 209 v56_L     uint8\n",
      " 210 v56_M     uint8\n",
      " 211 v56_N     uint8\n",
      " 212 v56_O     uint8\n",
      " 213 v56_P     uint8\n",
      " 214 v56_Q     uint8\n",
      " 215 v56_R     uint8\n",
      " 216 v56_T     uint8\n",
      " 217 v56_U     uint8\n",
      " 218 v56_V     uint8\n",
      " 219 v56_W     uint8\n",
      " 220 v56_X     uint8\n",
      " 221 v56_Y     uint8\n",
      " 222 v56_Z     uint8\n",
      " 223 v66_A     uint8\n",
      " 224 v66_B     uint8\n",
      " 225 v66_C     uint8\n",
      " 226 v71_A     uint8\n",
      " 227 v71_B     uint8\n",
      " 228 v71_C     uint8\n",
      " 229 v71_D     uint8\n",
      " 230 v71_F     uint8\n",
      " 231 v71_G     uint8\n",
      " 232 v71_I     uint8\n",
      " 233 v71_K     uint8\n",
      " 234 v71_L     uint8\n",
      " 235 v74_A     uint8\n",
      " 236 v74_B     uint8\n",
      " 237 v74_C     uint8\n",
      " 238 v75_A     uint8\n",
      " 239 v75_B     uint8\n",
      " 240 v75_C     uint8\n",
      " 241 v75_D     uint8\n",
      " 242 v79_A     uint8\n",
      " 243 v79_B     uint8\n",
      " 244 v79_C     uint8\n",
      " 245 v79_D     uint8\n",
      " 246 v79_E     uint8\n",
      " 247 v79_F     uint8\n",
      " 248 v79_G     uint8\n",
      " 249 v79_H     uint8\n",
      " 250 v79_I     uint8\n",
      " 251 v79_J     uint8\n",
      " 252 v79_K     uint8\n",
      " 253 v79_L     uint8\n",
      " 254 v79_M     uint8\n",
      " 255 v79_N     uint8\n",
      " 256 v79_O     uint8\n",
      " 257 v79_P     uint8\n",
      " 258 v79_Q     uint8\n",
      " 259 v79_R     uint8\n",
      " 260 v91_A     uint8\n",
      " 261 v91_B     uint8\n",
      " 262 v91_C     uint8\n",
      " 263 v91_D     uint8\n",
      " 264 v91_E     uint8\n",
      " 265 v91_F     uint8\n",
      " 266 v91_G     uint8\n",
      " 267 v107_A    uint8\n",
      " 268 v107_B    uint8\n",
      " 269 v107_C    uint8\n",
      " 270 v107_D    uint8\n",
      " 271 v107_E    uint8\n",
      " 272 v107_F    uint8\n",
      " 273 v107_G    uint8\n",
      " 274 v110_A    uint8\n",
      " 275 v110_B    uint8\n",
      " 276 v110_C    uint8\n",
      " 277 v112_A    uint8\n",
      " 278 v112_B    uint8\n",
      " 279 v112_C    uint8\n",
      " 280 v112_D    uint8\n",
      " 281 v112_E    uint8\n",
      " 282 v112_F    uint8\n",
      " 283 v112_G    uint8\n",
      " 284 v112_H    uint8\n",
      " 285 v112_I    uint8\n",
      " 286 v112_J    uint8\n",
      " 287 v112_K    uint8\n",
      " 288 v112_L    uint8\n",
      " 289 v112_M    uint8\n",
      " 290 v112_N    uint8\n",
      " 291 v112_O    uint8\n",
      " 292 v112_P    uint8\n",
      " 293 v112_Q    uint8\n",
      " 294 v112_R    uint8\n",
      " 295 v112_S    uint8\n",
      " 296 v112_T    uint8\n",
      " 297 v112_U    uint8\n",
      " 298 v112_V    uint8\n",
      " 299 v113_A    uint8\n",
      " 300 v113_AA   uint8\n",
      " 301 v113_AB   uint8\n",
      " 302 v113_AC   uint8\n",
      " 303 v113_AD   uint8\n",
      " 304 v113_AE   uint8\n",
      " 305 v113_AF   uint8\n",
      " 306 v113_AG   uint8\n",
      " 307 v113_AH   uint8\n",
      " 308 v113_AI   uint8\n",
      " 309 v113_AJ   uint8\n",
      " 310 v113_AK   uint8\n",
      " 311 v113_B    uint8\n",
      " 312 v113_C    uint8\n",
      " 313 v113_D    uint8\n",
      " 314 v113_E    uint8\n",
      " 315 v113_F    uint8\n",
      " 316 v113_G    uint8\n",
      " 317 v113_H    uint8\n",
      " 318 v113_I    uint8\n",
      " 319 v113_J    uint8\n",
      " 320 v113_L    uint8\n",
      " 321 v113_M    uint8\n",
      " 322 v113_N    uint8\n",
      " 323 v113_O    uint8\n",
      " 324 v113_P    uint8\n",
      " 325 v113_Q    uint8\n",
      " 326 v113_R    uint8\n",
      " 327 v113_S    uint8\n",
      " 328 v113_T    uint8\n",
      " 329 v113_U    uint8\n",
      " 330 v113_V    uint8\n",
      " 331 v113_W    uint8\n",
      " 332 v113_X    uint8\n",
      " 333 v113_Y    uint8\n",
      " 334 v113_Z    uint8\n",
      " 335 v125_A    uint8\n",
      " 336 v125_AA   uint8\n",
      " 337 v125_AB   uint8\n",
      " 338 v125_AC   uint8\n",
      " 339 v125_AD   uint8\n",
      " 340 v125_AE   uint8\n",
      " 341 v125_AF   uint8\n",
      " 342 v125_AG   uint8\n",
      " 343 v125_AH   uint8\n",
      " 344 v125_AI   uint8\n",
      " 345 v125_AJ   uint8\n",
      " 346 v125_AK   uint8\n",
      " 347 v125_AL   uint8\n",
      " 348 v125_AM   uint8\n",
      " 349 v125_AN   uint8\n",
      " 350 v125_AO   uint8\n",
      " 351 v125_AP   uint8\n",
      " 352 v125_AQ   uint8\n",
      " 353 v125_AR   uint8\n",
      " 354 v125_AS   uint8\n",
      " 355 v125_AT   uint8\n",
      " 356 v125_AU   uint8\n",
      " 357 v125_AV   uint8\n",
      " 358 v125_AW   uint8\n",
      " 359 v125_AX   uint8\n",
      " 360 v125_AY   uint8\n",
      " 361 v125_AZ   uint8\n",
      " 362 v125_B    uint8\n",
      " 363 v125_BA   uint8\n",
      " 364 v125_BB   uint8\n",
      " 365 v125_BC   uint8\n",
      " 366 v125_BD   uint8\n",
      " 367 v125_BE   uint8\n",
      " 368 v125_BF   uint8\n",
      " 369 v125_BG   uint8\n",
      " 370 v125_BH   uint8\n",
      " 371 v125_BI   uint8\n",
      " 372 v125_BJ   uint8\n",
      " 373 v125_BK   uint8\n",
      " 374 v125_BL   uint8\n",
      " 375 v125_BM   uint8\n",
      " 376 v125_BN   uint8\n",
      " 377 v125_BO   uint8\n",
      " 378 v125_BP   uint8\n",
      " 379 v125_BQ   uint8\n",
      " 380 v125_BR   uint8\n",
      " 381 v125_BS   uint8\n",
      " 382 v125_BT   uint8\n",
      " 383 v125_BU   uint8\n",
      " 384 v125_BV   uint8\n",
      " 385 v125_BW   uint8\n",
      " 386 v125_BX   uint8\n",
      " 387 v125_BY   uint8\n",
      " 388 v125_BZ   uint8\n",
      " 389 v125_C    uint8\n",
      " 390 v125_CA   uint8\n",
      " 391 v125_CB   uint8\n",
      " 392 v125_CC   uint8\n",
      " 393 v125_CD   uint8\n",
      " 394 v125_CE   uint8\n",
      " 395 v125_CF   uint8\n",
      " 396 v125_CG   uint8\n",
      " 397 v125_CH   uint8\n",
      " 398 v125_CI   uint8\n",
      " 399 v125_CJ   uint8\n",
      " 400 v125_CK   uint8\n",
      " 401 v125_CL   uint8\n",
      " 402 v125_D    uint8\n",
      " 403 v125_E    uint8\n",
      " 404 v125_F    uint8\n",
      " 405 v125_G    uint8\n",
      " 406 v125_H    uint8\n",
      " 407 v125_I    uint8\n",
      " 408 v125_J    uint8\n",
      " 409 v125_K    uint8\n",
      " 410 v125_L    uint8\n",
      " 411 v125_M    uint8\n",
      " 412 v125_N    uint8\n",
      " 413 v125_O    uint8\n",
      " 414 v125_P    uint8\n",
      " 415 v125_Q    uint8\n",
      " 416 v125_R    uint8\n",
      " 417 v125_S    uint8\n",
      " 418 v125_T    uint8\n",
      " 419 v125_U    uint8\n",
      " 420 v125_V    uint8\n",
      " 421 v125_W    uint8\n",
      " 422 v125_X    uint8\n",
      " 423 v125_Y    uint8\n",
      " 424 v125_Z    uint8\n",
      "dtypes: uint8(425)\n",
      "memory usage: 46.3 MB\n"
     ]
    }
   ],
   "source": [
    "# one-hot encode remaining object columns\n",
    "object_one_hot_df = pd.get_dummies(data=train_object_dtype_cols) \n",
    "# Output one-hot encodeing results\n",
    "object_one_hot_df.info(verbose=True)\n",
    "# get list of columns that were one-hot encoded\n",
    "drop_cols = train_object_dtype_cols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop one-hot encoded columns from dataframe\n",
    "train = train.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114321 entries, 0 to 114320\n",
      "Data columns (total 538 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   ID        int64  \n",
      " 1   v1        float64\n",
      " 2   v2        float64\n",
      " 3   v4        float64\n",
      " 4   v5        float64\n",
      " 5   v6        float64\n",
      " 6   v7        float64\n",
      " 7   v8        float64\n",
      " 8   v9        float64\n",
      " 9   v10       float64\n",
      " 10  v11       float64\n",
      " 11  v12       float64\n",
      " 12  v13       float64\n",
      " 13  v14       float64\n",
      " 14  v15       float64\n",
      " 15  v16       float64\n",
      " 16  v17       float64\n",
      " 17  v18       float64\n",
      " 18  v19       float64\n",
      " 19  v20       float64\n",
      " 20  v21       float64\n",
      " 21  v23       float64\n",
      " 22  v25       float64\n",
      " 23  v26       float64\n",
      " 24  v27       float64\n",
      " 25  v28       float64\n",
      " 26  v29       float64\n",
      " 27  v32       float64\n",
      " 28  v33       float64\n",
      " 29  v34       float64\n",
      " 30  v35       float64\n",
      " 31  v36       float64\n",
      " 32  v37       float64\n",
      " 33  v38       int64  \n",
      " 34  v39       float64\n",
      " 35  v40       float64\n",
      " 36  v41       float64\n",
      " 37  v42       float64\n",
      " 38  v43       float64\n",
      " 39  v44       float64\n",
      " 40  v45       float64\n",
      " 41  v46       float64\n",
      " 42  v48       float64\n",
      " 43  v49       float64\n",
      " 44  v50       float64\n",
      " 45  v51       float64\n",
      " 46  v53       float64\n",
      " 47  v54       float64\n",
      " 48  v55       float64\n",
      " 49  v57       float64\n",
      " 50  v58       float64\n",
      " 51  v59       float64\n",
      " 52  v60       float64\n",
      " 53  v61       float64\n",
      " 54  v62       int64  \n",
      " 55  v63       float64\n",
      " 56  v64       float64\n",
      " 57  v65       float64\n",
      " 58  v67       float64\n",
      " 59  v68       float64\n",
      " 60  v69       float64\n",
      " 61  v70       float64\n",
      " 62  v72       int64  \n",
      " 63  v73       float64\n",
      " 64  v76       float64\n",
      " 65  v77       float64\n",
      " 66  v78       float64\n",
      " 67  v80       float64\n",
      " 68  v81       float64\n",
      " 69  v82       float64\n",
      " 70  v83       float64\n",
      " 71  v84       float64\n",
      " 72  v85       float64\n",
      " 73  v86       float64\n",
      " 74  v87       float64\n",
      " 75  v88       float64\n",
      " 76  v89       float64\n",
      " 77  v90       float64\n",
      " 78  v92       float64\n",
      " 79  v93       float64\n",
      " 80  v94       float64\n",
      " 81  v95       float64\n",
      " 82  v96       float64\n",
      " 83  v97       float64\n",
      " 84  v98       float64\n",
      " 85  v99       float64\n",
      " 86  v100      float64\n",
      " 87  v101      float64\n",
      " 88  v102      float64\n",
      " 89  v103      float64\n",
      " 90  v104      float64\n",
      " 91  v105      float64\n",
      " 92  v106      float64\n",
      " 93  v108      float64\n",
      " 94  v109      float64\n",
      " 95  v111      float64\n",
      " 96  v114      float64\n",
      " 97  v115      float64\n",
      " 98  v116      float64\n",
      " 99  v117      float64\n",
      " 100 v118      float64\n",
      " 101 v119      float64\n",
      " 102 v120      float64\n",
      " 103 v121      float64\n",
      " 104 v122      float64\n",
      " 105 v123      float64\n",
      " 106 v124      float64\n",
      " 107 v126      float64\n",
      " 108 v127      float64\n",
      " 109 v128      float64\n",
      " 110 v129      int64  \n",
      " 111 v130      float64\n",
      " 112 v131      float64\n",
      " 113 v3_A      uint8  \n",
      " 114 v3_B      uint8  \n",
      " 115 v3_C      uint8  \n",
      " 116 v22_AAPP  uint8  \n",
      " 117 v22_ABF   uint8  \n",
      " 118 v22_ABOF  uint8  \n",
      " 119 v22_ACHJ  uint8  \n",
      " 120 v22_ACWE  uint8  \n",
      " 121 v22_ACXD  uint8  \n",
      " 122 v22_ADDF  uint8  \n",
      " 123 v22_ADGN  uint8  \n",
      " 124 v22_ADMI  uint8  \n",
      " 125 v22_ADMP  uint8  \n",
      " 126 v22_AFOZ  uint8  \n",
      " 127 v22_AFYU  uint8  \n",
      " 128 v22_AGDF  uint8  \n",
      " 129 v22_AGON  uint8  \n",
      " 130 v22_AGZT  uint8  \n",
      " 131 v22_AHE   uint8  \n",
      " 132 v22_AJQ   uint8  \n",
      " 133 v22_AMR   uint8  \n",
      " 134 v22_AWT   uint8  \n",
      " 135 v22_AXH   uint8  \n",
      " 136 v22_BLE   uint8  \n",
      " 137 v22_DJU   uint8  \n",
      " 138 v22_EJC   uint8  \n",
      " 139 v22_GBS   uint8  \n",
      " 140 v22_GEB   uint8  \n",
      " 141 v22_GEJ   uint8  \n",
      " 142 v22_HDD   uint8  \n",
      " 143 v22_HUU   uint8  \n",
      " 144 v22_HZE   uint8  \n",
      " 145 v22_JGY   uint8  \n",
      " 146 v22_KLZ   uint8  \n",
      " 147 v22_LIP   uint8  \n",
      " 148 v22_MNZ   uint8  \n",
      " 149 v22_MQE   uint8  \n",
      " 150 v22_NGS   uint8  \n",
      " 151 v22_NRT   uint8  \n",
      " 152 v22_NWG   uint8  \n",
      " 153 v22_NXE   uint8  \n",
      " 154 v22_OFD   uint8  \n",
      " 155 v22_PBC   uint8  \n",
      " 156 v22_PFR   uint8  \n",
      " 157 v22_PSE   uint8  \n",
      " 158 v22_PTJ   uint8  \n",
      " 159 v22_PTO   uint8  \n",
      " 160 v22_PWR   uint8  \n",
      " 161 v22_QKI   uint8  \n",
      " 162 v22_QKP   uint8  \n",
      " 163 v22_QVR   uint8  \n",
      " 164 v22_RIC   uint8  \n",
      " 165 v22_ROZ   uint8  \n",
      " 166 v22_TG    uint8  \n",
      " 167 v22_TVR   uint8  \n",
      " 168 v22_UAG   uint8  \n",
      " 169 v22_VVI   uint8  \n",
      " 170 v22_VZF   uint8  \n",
      " 171 v22_WFT   uint8  \n",
      " 172 v22_WNI   uint8  \n",
      " 173 v22_WRI   uint8  \n",
      " 174 v22_YEP   uint8  \n",
      " 175 v22_YGJ   uint8  \n",
      " 176 v22_YOD   uint8  \n",
      " 177 v24_A     uint8  \n",
      " 178 v24_B     uint8  \n",
      " 179 v24_C     uint8  \n",
      " 180 v24_D     uint8  \n",
      " 181 v24_E     uint8  \n",
      " 182 v30_A     uint8  \n",
      " 183 v30_B     uint8  \n",
      " 184 v30_C     uint8  \n",
      " 185 v30_D     uint8  \n",
      " 186 v30_E     uint8  \n",
      " 187 v30_F     uint8  \n",
      " 188 v30_G     uint8  \n",
      " 189 v31_A     uint8  \n",
      " 190 v31_B     uint8  \n",
      " 191 v31_C     uint8  \n",
      " 192 v47_A     uint8  \n",
      " 193 v47_B     uint8  \n",
      " 194 v47_C     uint8  \n",
      " 195 v47_D     uint8  \n",
      " 196 v47_E     uint8  \n",
      " 197 v47_F     uint8  \n",
      " 198 v47_G     uint8  \n",
      " 199 v47_H     uint8  \n",
      " 200 v47_I     uint8  \n",
      " 201 v47_J     uint8  \n",
      " 202 v52_A     uint8  \n",
      " 203 v52_B     uint8  \n",
      " 204 v52_C     uint8  \n",
      " 205 v52_D     uint8  \n",
      " 206 v52_E     uint8  \n",
      " 207 v52_F     uint8  \n",
      " 208 v52_G     uint8  \n",
      " 209 v52_H     uint8  \n",
      " 210 v52_I     uint8  \n",
      " 211 v52_J     uint8  \n",
      " 212 v52_K     uint8  \n",
      " 213 v52_L     uint8  \n",
      " 214 v56_A     uint8  \n",
      " 215 v56_AA    uint8  \n",
      " 216 v56_AB    uint8  \n",
      " 217 v56_AC    uint8  \n",
      " 218 v56_AE    uint8  \n",
      " 219 v56_AF    uint8  \n",
      " 220 v56_AG    uint8  \n",
      " 221 v56_AH    uint8  \n",
      " 222 v56_AI    uint8  \n",
      " 223 v56_AJ    uint8  \n",
      " 224 v56_AK    uint8  \n",
      " 225 v56_AL    uint8  \n",
      " 226 v56_AM    uint8  \n",
      " 227 v56_AN    uint8  \n",
      " 228 v56_AO    uint8  \n",
      " 229 v56_AP    uint8  \n",
      " 230 v56_AR    uint8  \n",
      " 231 v56_AS    uint8  \n",
      " 232 v56_AT    uint8  \n",
      " 233 v56_AU    uint8  \n",
      " 234 v56_AV    uint8  \n",
      " 235 v56_AW    uint8  \n",
      " 236 v56_AX    uint8  \n",
      " 237 v56_AY    uint8  \n",
      " 238 v56_AZ    uint8  \n",
      " 239 v56_B     uint8  \n",
      " 240 v56_BA    uint8  \n",
      " 241 v56_BC    uint8  \n",
      " 242 v56_BD    uint8  \n",
      " 243 v56_BE    uint8  \n",
      " 244 v56_BF    uint8  \n",
      " 245 v56_BG    uint8  \n",
      " 246 v56_BH    uint8  \n",
      " 247 v56_BI    uint8  \n",
      " 248 v56_BJ    uint8  \n",
      " 249 v56_BK    uint8  \n",
      " 250 v56_BL    uint8  \n",
      " 251 v56_BM    uint8  \n",
      " 252 v56_BN    uint8  \n",
      " 253 v56_BO    uint8  \n",
      " 254 v56_BP    uint8  \n",
      " 255 v56_BQ    uint8  \n",
      " 256 v56_BR    uint8  \n",
      " 257 v56_BS    uint8  \n",
      " 258 v56_BT    uint8  \n",
      " 259 v56_BU    uint8  \n",
      " 260 v56_BV    uint8  \n",
      " 261 v56_BW    uint8  \n",
      " 262 v56_BX    uint8  \n",
      " 263 v56_BY    uint8  \n",
      " 264 v56_BZ    uint8  \n",
      " 265 v56_C     uint8  \n",
      " 266 v56_CA    uint8  \n",
      " 267 v56_CB    uint8  \n",
      " 268 v56_CC    uint8  \n",
      " 269 v56_CD    uint8  \n",
      " 270 v56_CE    uint8  \n",
      " 271 v56_CF    uint8  \n",
      " 272 v56_CG    uint8  \n",
      " 273 v56_CH    uint8  \n",
      " 274 v56_CI    uint8  \n",
      " 275 v56_CJ    uint8  \n",
      " 276 v56_CK    uint8  \n",
      " 277 v56_CL    uint8  \n",
      " 278 v56_CM    uint8  \n",
      " 279 v56_CN    uint8  \n",
      " 280 v56_CO    uint8  \n",
      " 281 v56_CP    uint8  \n",
      " 282 v56_CQ    uint8  \n",
      " 283 v56_CS    uint8  \n",
      " 284 v56_CT    uint8  \n",
      " 285 v56_CV    uint8  \n",
      " 286 v56_CW    uint8  \n",
      " 287 v56_CX    uint8  \n",
      " 288 v56_CY    uint8  \n",
      " 289 v56_CZ    uint8  \n",
      " 290 v56_D     uint8  \n",
      " 291 v56_DA    uint8  \n",
      " 292 v56_DB    uint8  \n",
      " 293 v56_DC    uint8  \n",
      " 294 v56_DD    uint8  \n",
      " 295 v56_DE    uint8  \n",
      " 296 v56_DF    uint8  \n",
      " 297 v56_DG    uint8  \n",
      " 298 v56_DH    uint8  \n",
      " 299 v56_DI    uint8  \n",
      " 300 v56_DJ    uint8  \n",
      " 301 v56_DK    uint8  \n",
      " 302 v56_DL    uint8  \n",
      " 303 v56_DM    uint8  \n",
      " 304 v56_DN    uint8  \n",
      " 305 v56_DO    uint8  \n",
      " 306 v56_DP    uint8  \n",
      " 307 v56_DQ    uint8  \n",
      " 308 v56_DR    uint8  \n",
      " 309 v56_DS    uint8  \n",
      " 310 v56_DT    uint8  \n",
      " 311 v56_DU    uint8  \n",
      " 312 v56_DV    uint8  \n",
      " 313 v56_DW    uint8  \n",
      " 314 v56_DX    uint8  \n",
      " 315 v56_DY    uint8  \n",
      " 316 v56_DZ    uint8  \n",
      " 317 v56_E     uint8  \n",
      " 318 v56_F     uint8  \n",
      " 319 v56_G     uint8  \n",
      " 320 v56_H     uint8  \n",
      " 321 v56_I     uint8  \n",
      " 322 v56_L     uint8  \n",
      " 323 v56_M     uint8  \n",
      " 324 v56_N     uint8  \n",
      " 325 v56_O     uint8  \n",
      " 326 v56_P     uint8  \n",
      " 327 v56_Q     uint8  \n",
      " 328 v56_R     uint8  \n",
      " 329 v56_T     uint8  \n",
      " 330 v56_U     uint8  \n",
      " 331 v56_V     uint8  \n",
      " 332 v56_W     uint8  \n",
      " 333 v56_X     uint8  \n",
      " 334 v56_Y     uint8  \n",
      " 335 v56_Z     uint8  \n",
      " 336 v66_A     uint8  \n",
      " 337 v66_B     uint8  \n",
      " 338 v66_C     uint8  \n",
      " 339 v71_A     uint8  \n",
      " 340 v71_B     uint8  \n",
      " 341 v71_C     uint8  \n",
      " 342 v71_D     uint8  \n",
      " 343 v71_F     uint8  \n",
      " 344 v71_G     uint8  \n",
      " 345 v71_I     uint8  \n",
      " 346 v71_K     uint8  \n",
      " 347 v71_L     uint8  \n",
      " 348 v74_A     uint8  \n",
      " 349 v74_B     uint8  \n",
      " 350 v74_C     uint8  \n",
      " 351 v75_A     uint8  \n",
      " 352 v75_B     uint8  \n",
      " 353 v75_C     uint8  \n",
      " 354 v75_D     uint8  \n",
      " 355 v79_A     uint8  \n",
      " 356 v79_B     uint8  \n",
      " 357 v79_C     uint8  \n",
      " 358 v79_D     uint8  \n",
      " 359 v79_E     uint8  \n",
      " 360 v79_F     uint8  \n",
      " 361 v79_G     uint8  \n",
      " 362 v79_H     uint8  \n",
      " 363 v79_I     uint8  \n",
      " 364 v79_J     uint8  \n",
      " 365 v79_K     uint8  \n",
      " 366 v79_L     uint8  \n",
      " 367 v79_M     uint8  \n",
      " 368 v79_N     uint8  \n",
      " 369 v79_O     uint8  \n",
      " 370 v79_P     uint8  \n",
      " 371 v79_Q     uint8  \n",
      " 372 v79_R     uint8  \n",
      " 373 v91_A     uint8  \n",
      " 374 v91_B     uint8  \n",
      " 375 v91_C     uint8  \n",
      " 376 v91_D     uint8  \n",
      " 377 v91_E     uint8  \n",
      " 378 v91_F     uint8  \n",
      " 379 v91_G     uint8  \n",
      " 380 v107_A    uint8  \n",
      " 381 v107_B    uint8  \n",
      " 382 v107_C    uint8  \n",
      " 383 v107_D    uint8  \n",
      " 384 v107_E    uint8  \n",
      " 385 v107_F    uint8  \n",
      " 386 v107_G    uint8  \n",
      " 387 v110_A    uint8  \n",
      " 388 v110_B    uint8  \n",
      " 389 v110_C    uint8  \n",
      " 390 v112_A    uint8  \n",
      " 391 v112_B    uint8  \n",
      " 392 v112_C    uint8  \n",
      " 393 v112_D    uint8  \n",
      " 394 v112_E    uint8  \n",
      " 395 v112_F    uint8  \n",
      " 396 v112_G    uint8  \n",
      " 397 v112_H    uint8  \n",
      " 398 v112_I    uint8  \n",
      " 399 v112_J    uint8  \n",
      " 400 v112_K    uint8  \n",
      " 401 v112_L    uint8  \n",
      " 402 v112_M    uint8  \n",
      " 403 v112_N    uint8  \n",
      " 404 v112_O    uint8  \n",
      " 405 v112_P    uint8  \n",
      " 406 v112_Q    uint8  \n",
      " 407 v112_R    uint8  \n",
      " 408 v112_S    uint8  \n",
      " 409 v112_T    uint8  \n",
      " 410 v112_U    uint8  \n",
      " 411 v112_V    uint8  \n",
      " 412 v113_A    uint8  \n",
      " 413 v113_AA   uint8  \n",
      " 414 v113_AB   uint8  \n",
      " 415 v113_AC   uint8  \n",
      " 416 v113_AD   uint8  \n",
      " 417 v113_AE   uint8  \n",
      " 418 v113_AF   uint8  \n",
      " 419 v113_AG   uint8  \n",
      " 420 v113_AH   uint8  \n",
      " 421 v113_AI   uint8  \n",
      " 422 v113_AJ   uint8  \n",
      " 423 v113_AK   uint8  \n",
      " 424 v113_B    uint8  \n",
      " 425 v113_C    uint8  \n",
      " 426 v113_D    uint8  \n",
      " 427 v113_E    uint8  \n",
      " 428 v113_F    uint8  \n",
      " 429 v113_G    uint8  \n",
      " 430 v113_H    uint8  \n",
      " 431 v113_I    uint8  \n",
      " 432 v113_J    uint8  \n",
      " 433 v113_L    uint8  \n",
      " 434 v113_M    uint8  \n",
      " 435 v113_N    uint8  \n",
      " 436 v113_O    uint8  \n",
      " 437 v113_P    uint8  \n",
      " 438 v113_Q    uint8  \n",
      " 439 v113_R    uint8  \n",
      " 440 v113_S    uint8  \n",
      " 441 v113_T    uint8  \n",
      " 442 v113_U    uint8  \n",
      " 443 v113_V    uint8  \n",
      " 444 v113_W    uint8  \n",
      " 445 v113_X    uint8  \n",
      " 446 v113_Y    uint8  \n",
      " 447 v113_Z    uint8  \n",
      " 448 v125_A    uint8  \n",
      " 449 v125_AA   uint8  \n",
      " 450 v125_AB   uint8  \n",
      " 451 v125_AC   uint8  \n",
      " 452 v125_AD   uint8  \n",
      " 453 v125_AE   uint8  \n",
      " 454 v125_AF   uint8  \n",
      " 455 v125_AG   uint8  \n",
      " 456 v125_AH   uint8  \n",
      " 457 v125_AI   uint8  \n",
      " 458 v125_AJ   uint8  \n",
      " 459 v125_AK   uint8  \n",
      " 460 v125_AL   uint8  \n",
      " 461 v125_AM   uint8  \n",
      " 462 v125_AN   uint8  \n",
      " 463 v125_AO   uint8  \n",
      " 464 v125_AP   uint8  \n",
      " 465 v125_AQ   uint8  \n",
      " 466 v125_AR   uint8  \n",
      " 467 v125_AS   uint8  \n",
      " 468 v125_AT   uint8  \n",
      " 469 v125_AU   uint8  \n",
      " 470 v125_AV   uint8  \n",
      " 471 v125_AW   uint8  \n",
      " 472 v125_AX   uint8  \n",
      " 473 v125_AY   uint8  \n",
      " 474 v125_AZ   uint8  \n",
      " 475 v125_B    uint8  \n",
      " 476 v125_BA   uint8  \n",
      " 477 v125_BB   uint8  \n",
      " 478 v125_BC   uint8  \n",
      " 479 v125_BD   uint8  \n",
      " 480 v125_BE   uint8  \n",
      " 481 v125_BF   uint8  \n",
      " 482 v125_BG   uint8  \n",
      " 483 v125_BH   uint8  \n",
      " 484 v125_BI   uint8  \n",
      " 485 v125_BJ   uint8  \n",
      " 486 v125_BK   uint8  \n",
      " 487 v125_BL   uint8  \n",
      " 488 v125_BM   uint8  \n",
      " 489 v125_BN   uint8  \n",
      " 490 v125_BO   uint8  \n",
      " 491 v125_BP   uint8  \n",
      " 492 v125_BQ   uint8  \n",
      " 493 v125_BR   uint8  \n",
      " 494 v125_BS   uint8  \n",
      " 495 v125_BT   uint8  \n",
      " 496 v125_BU   uint8  \n",
      " 497 v125_BV   uint8  \n",
      " 498 v125_BW   uint8  \n",
      " 499 v125_BX   uint8  \n",
      " 500 v125_BY   uint8  \n",
      " 501 v125_BZ   uint8  \n",
      " 502 v125_C    uint8  \n",
      " 503 v125_CA   uint8  \n",
      " 504 v125_CB   uint8  \n",
      " 505 v125_CC   uint8  \n",
      " 506 v125_CD   uint8  \n",
      " 507 v125_CE   uint8  \n",
      " 508 v125_CF   uint8  \n",
      " 509 v125_CG   uint8  \n",
      " 510 v125_CH   uint8  \n",
      " 511 v125_CI   uint8  \n",
      " 512 v125_CJ   uint8  \n",
      " 513 v125_CK   uint8  \n",
      " 514 v125_CL   uint8  \n",
      " 515 v125_D    uint8  \n",
      " 516 v125_E    uint8  \n",
      " 517 v125_F    uint8  \n",
      " 518 v125_G    uint8  \n",
      " 519 v125_H    uint8  \n",
      " 520 v125_I    uint8  \n",
      " 521 v125_J    uint8  \n",
      " 522 v125_K    uint8  \n",
      " 523 v125_L    uint8  \n",
      " 524 v125_M    uint8  \n",
      " 525 v125_N    uint8  \n",
      " 526 v125_O    uint8  \n",
      " 527 v125_P    uint8  \n",
      " 528 v125_Q    uint8  \n",
      " 529 v125_R    uint8  \n",
      " 530 v125_S    uint8  \n",
      " 531 v125_T    uint8  \n",
      " 532 v125_U    uint8  \n",
      " 533 v125_V    uint8  \n",
      " 534 v125_W    uint8  \n",
      " 535 v125_X    uint8  \n",
      " 536 v125_Y    uint8  \n",
      " 537 v125_Z    uint8  \n",
      "dtypes: float64(108), int64(5), uint8(425)\n",
      "memory usage: 144.9 MB\n"
     ]
    }
   ],
   "source": [
    "# merge one-hot encoded columns to dataframe \n",
    "frames = [train, object_one_hot_df]\n",
    "train = pd.concat(frames,axis=1)\n",
    "# Output train dataframe \n",
    "train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training set to pickle\n",
    "pickle.dump(train, open(\"Pickle/train.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train pickle for consistent shared data across models\n",
    "train = pickle.load( open(\"Pickle/train.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test/train split of data and target\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save split train and test sets for consistant model testing and time savings.\n",
    "pickle.dump(X_train, open(\"Pickle/X_train.pkl\", \"wb\"))\n",
    "pickle.dump(y_train, open(\"Pickle/y_train.pkl\", \"wb\"))\n",
    "pickle.dump(X_test, open(\"Pickle/X_test.pkl\", \"wb\"))\n",
    "pickle.dump(y_test, open(\"Pickle/y_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load split train and test sets for consistant model testing and time savings.\n",
    "X_train = pickle.load( open(\"Pickle/X_train.pkl\", \"rb\"))\n",
    "y_train = pickle.load( open(\"Pickle/y_train.pkl\", \"rb\"))\n",
    "X_test = pickle.load( open(\"Pickle/X_test.pkl\", \"rb\"))\n",
    "y_test = pickle.load( open(\"Pickle/y_test.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# End of Data Preparation\n",
    "\n",
    "# Begin Models\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# XGBoost Model\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN JR XGB RANDOMIZED SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data into DMatrix for XGBoost\n",
    "xgtrain = xgb.DMatrix(X_train.values, y_train.values)\n",
    "xgtest = xgb.DMatrix(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'silent': [False],\n",
    "        'max_depth': [6, 10, 15, 20],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "        'gamma': [0, 0.25, 0.5, 1.0],\n",
    "        'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "        'n_estimators': [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rs_clf = RandomizedSearchCV(clf, param_grid, n_iter=5,\n",
    "                            n_jobs=-1, verbose=2, cv=5,\n",
    "                            scoring='neg_log_loss', refit=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(\"Randomized search..\")\n",
    "search_time_start = time.time()\n",
    "xgb_rs_clf.fit(X_train, y_train)\n",
    "xgb_rs_elapsed = time.time() - search_time_start\n",
    "print(\"Randomized search time:\", xgb_rs_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb_rs_elapsed, open(\"xgb_rs_elapsed.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rs_elapsed = pickle.load( open(\"xgb_rs_elapsed.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb_rs_clf, open(\"xgb_rs_clf.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rs_clf = pickle.load( open(\"xgb_rs_clf.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best combination of parameters, based on an evaluation of log-loss is:')\n",
    "xgb_rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = xgb_rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The log-loss value for the best model is {round(xgb_rs_clf.best_score_ * -1,4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(xgb_rs_clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results, open(\"results.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load( open(\"results.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.iloc[xgb_rs_clf.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_preds = xgb_rs_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb_test_preds, open(\"xgb_test_preds.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_preds = pickle.load( open(\"xgb_test_preds.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,np.rint(xgb_test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = pd.DataFrame([['XGBoost', 'RandomSearchCV',xgb_rs_clf.best_score_ * -1,accuracy_score(y_test,np.rint(xgb_test_preds)),xgb_rs_elapsed ]],columns=['Model', 'Tuning', 'log loss', 'accuracy', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####   END JR XGB RANDOMIZED SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### BEGIN JR XGB ORIGINAL EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fit the model...')\n",
    "# XGBoost params:\n",
    "xgboost_params = { \n",
    "   \"objective\": \"binary:logistic\",\n",
    "   \"booster\": \"gbtree\",\n",
    "   \"eval_metric\": \"logloss\",\n",
    "   \"eta\": 0.01, \n",
    "   \"subsample\": 0.5,\n",
    "   \"colsample_bytree\": 0.5,\n",
    "   \"max_depth\": 3\n",
    "}\n",
    "boost_round = 50\n",
    "\n",
    "xgb_clf_start = time.time()\n",
    "xgb_clf = xgb.train(xgboost_params,xgtrain,num_boost_round=boost_round,verbose_eval=True,maximize=False)\n",
    "xgb_clf_elapsed = time.time() - xgb_clf_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb_clf_elapsed, open(\"xgb_clf_elapsed.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_elapsed = pickle.load( open(\"xgb_clf_elapsed.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predict\n",
    "print('Predict...')\n",
    "\n",
    "xgb_test_preds_orig = clf.predict(xgtest, ntree_limit=clf.best_iteration)\n",
    "\n",
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb_clf, open(\"xgb_clf.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = pickle.load( open(\"xgb_clf.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_loss(y_test,xgb_test_preds_orig))\n",
    "print(accuracy_score(y_test,np.rint(xgb_test_preds_orig)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = results_summary.append(pd.DataFrame([['XGBoost','Base',log_loss(y_test,xgb_test_preds_orig),accuracy_score(y_test,np.rint(xgb_test_preds_orig)), xgb_clf_elapsed ]],columns=['Model', 'Tuning', 'log loss', 'accuracy', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = results_summary.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results_summary, open(\"jr_results_summary.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  END XGB XGB ORIGINAL EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### BEGIN XGB VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30, 30))\n",
    "plot_tree(xgb_rs_clf.best_estimator_, num_trees=1, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassificationReport, ClassPredictionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = ClassificationReport(xgb_rs_clf, size=(1080, 720), classes=[0,1])\n",
    "\n",
    "report.score(X_test, y_test)\n",
    "c = report.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = ClassPredictionError(xgb_rs_clf, size=(1080, 720), classes=[0,1])\n",
    "\n",
    "error.score(X_test, y_test)\n",
    "e = error.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### END XGB VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# SVM model\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load split train and test sets for consistant model testing and time savings.\n",
    "X_train = pickle.load( open(\"Pickle/X_train.pkl\", \"rb\"))\n",
    "y_train = pickle.load( open(\"Pickle/y_train.pkl\", \"rb\"))\n",
    "X_test = pickle.load( open(\"Pickle/X_test.pkl\", \"rb\"))\n",
    "y_test = pickle.load( open(\"Pickle/y_test.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 00:26:57,492 [35816] WARNING  py.warnings:110: [JupyterRequire] C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55.44"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "###   Original SVM Code from Dr. Slater with Added Timing\n",
    "#########################################################\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "#####################################\n",
    "# WARNING THIS TAKES AN HOUR TO RUN #\n",
    "# Using LinearSVC for faster returns#\n",
    "#####################################\n",
    "\n",
    "svm = LinearSVC(verbose=True, random_state=42)  \n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "LinearSVC_time=round((end-start),2)\n",
    "LinearSVC_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5046122037851879\n"
     ]
    }
   ],
   "source": [
    "# Predict using the model and Measure Accuracy\n",
    "\n",
    "X_pred=svm.predict(X_test)\n",
    "\n",
    "#from sklearn.metrics import accuracy_score\n",
    "svm_base_accuracy = accuracy_score(y_test,X_pred)\n",
    "print(svm_base_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the SCM curve\n",
    "svm_disp = plot_roc_curve(svm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#### Begin MM CODE\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL DATASET TUNED SVM MODEL\n",
    "# Ignore to save time - Picked Models are available\n",
    "\n",
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'C': [0.001,0.01,0.1],\n",
    "              'loss': ['hinge', 'squared_hinge'],\n",
    "              'penalty' : ['l2'],\n",
    "              'dual' : [True,False],\n",
    "              'tol': [0.00001,0.01], #0.0001 is the Default\n",
    "              'max_iter': [100],\n",
    "             }\n",
    "\n",
    "SVC_Linear = LinearSVC(random_state=42)\n",
    "CV_svc = GridSearchCV(estimator = SVC_Linear, param_grid=param_grid, cv= 5, n_jobs =-1,verbose=1)\n",
    "Start=time.time()\n",
    "CV_svc_mod = CV_svc.fit(X_train, y_train)\n",
    "Stop=time.time()\n",
    "Time1=Stop-Start\n",
    "Time1\n",
    "pkl_filename = \"Pickle/CV_SVM_Linear.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(CV_svc_mod, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CV_svc_mod\n",
    "#with open(\"C://Users/18322/OneDrive - Southern Methodist University/Desktop/QOW/week7/case study 8/case_study_81_2/CV_SVM_Linear.pkl\", 'rb') as file:\n",
    "#    CV_svc = pickle.load(file)\n",
    "\n",
    "CV_svc_mod = pickle.load( open(\"Pickle/CV_SVM_Linear.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_gridsearch = pd.DataFrame(CV_svc_mod.cv_results_)\n",
    "svc_columns = [\n",
    "    \"param_C\",\n",
    "    \"param_loss\",\n",
    "    \"param_dual\",\n",
    "    \"param_tol\",\n",
    "    \"param_max_iter\",\n",
    "    \"mean_fit_time\",\n",
    "    \"mean_test_score\",\n",
    "    \"rank_test_score\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>872.557506</td>\n",
       "      <td>0.771134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>94.016914</td>\n",
       "      <td>0.771134</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>77.806056</td>\n",
       "      <td>0.771134</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>119.676386</td>\n",
       "      <td>0.771069</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>145.308221</td>\n",
       "      <td>0.771029</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1386.344374</td>\n",
       "      <td>0.771003</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>269.671581</td>\n",
       "      <td>0.770990</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1003.456923</td>\n",
       "      <td>0.770873</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>207.509046</td>\n",
       "      <td>0.770768</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>214.311796</td>\n",
       "      <td>0.770768</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_dual param_tol param_max_iter  mean_fit_time  \\\n",
       "6    0.001  squared_hinge      False     1e-05            100     872.557506   \n",
       "2    0.001  squared_hinge       True     1e-05            100      94.016914   \n",
       "3    0.001  squared_hinge       True      0.01            100      77.806056   \n",
       "7    0.001  squared_hinge      False      0.01            100     119.676386   \n",
       "23     0.1  squared_hinge      False      0.01            100     145.308221   \n",
       "14    0.01  squared_hinge      False     1e-05            100    1386.344374   \n",
       "15    0.01  squared_hinge      False      0.01            100     269.671581   \n",
       "22     0.1  squared_hinge      False     1e-05            100    1003.456923   \n",
       "10    0.01  squared_hinge       True     1e-05            100     207.509046   \n",
       "11    0.01  squared_hinge       True      0.01            100     214.311796   \n",
       "\n",
       "    mean_test_score  rank_test_score  \n",
       "6          0.771134                1  \n",
       "2          0.771134                2  \n",
       "3          0.771134                2  \n",
       "7          0.771069                4  \n",
       "23         0.771029                5  \n",
       "14         0.771003                6  \n",
       "15         0.770990                7  \n",
       "22         0.770873                8  \n",
       "10         0.770768                9  \n",
       "11         0.770768                9  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_gridsearch[svc_columns].sort_values(by=\"rank_test_score\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Accuracy:', CV_svc_mod.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features 1000: (1000, 538)\n",
      "Training Labels 1000: (1000,)\n",
      "Testing Features 1000: (1000, 538)\n",
      "Testing Labels 1000: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Create Dataframe of 1000 Rows\n",
    "Xtrain_1000 = pd.DataFrame.sample(X_train, n=1000, random_state=123)\n",
    "ytrain_1000 = pd.DataFrame.sample(y_train,n=1000, random_state=123)\n",
    "Xtest_1000 = pd.DataFrame.sample(X_test,n=1000, random_state=123)\n",
    "ytest_1000 = pd.DataFrame.sample(y_test,n=1000, random_state=123)\n",
    "print('Training Features 1000:', Xtrain_1000.shape)\n",
    "print('Training Labels 1000:', ytrain_1000.shape)\n",
    "print('Testing Features 1000:', Xtest_1000.shape)\n",
    "print('Testing Labels 1000:', ytest_1000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "#1000 Rows\n",
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'C': [0.001,0.01,0.1],\n",
    "              'loss': ['hinge', 'squared_hinge'],\n",
    "              'penalty' : ['l2'],\n",
    "              'dual' : [True,False],\n",
    "              'tol': [0.00001,0.01], #0.0001 is the Default\n",
    "              'max_iter': [100],\n",
    "             }\n",
    "\n",
    "SVC_Linear = LinearSVC(random_state=42)\n",
    "CV_svc = GridSearchCV(estimator = SVC_Linear, param_grid=param_grid, cv= 5, n_jobs =-1,verbose=1)\n",
    "Start=time.time()\n",
    "CV_svc_mod_1000 = CV_svc.fit(Xtrain_1000, ytrain_1000)\n",
    "Stop=time.time()\n",
    "Time2=Stop-Start\n",
    "Time2\n",
    "pkl_filename = \"Pickle/CV_SVM_Linear_1000.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(CV_svc_mod_1000, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1000 \n",
    "#with open(\"C://Users/18322/OneDrive - Southern Methodist University/Desktop/QOW/week7/case study 8/case_study_81_2/CV_SVM_Linear_1000.pkl\", 'rb') as file:\n",
    "#    CV_svc = pickle.load(file)\n",
    "    \n",
    "CV_svc_mod_1000 = pickle.load( open(\"Pickle/CV_SVM_Linear_1000.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_gridsearch = pd.DataFrame(CV_svc_mod_1000.cv_results_)\n",
    "svc_columns = [\n",
    "    \"param_C\",\n",
    "    \"param_loss\",\n",
    "    \"param_dual\",\n",
    "    \"param_tol\",\n",
    "    \"param_max_iter\",\n",
    "    \"mean_fit_time\",\n",
    "    \"mean_test_score\",\n",
    "    \"rank_test_score\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>0.745</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.087365</td>\n",
       "      <td>0.745</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.058641</td>\n",
       "      <td>0.745</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>0.117089</td>\n",
       "      <td>0.740</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>0.164079</td>\n",
       "      <td>0.725</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>0.122875</td>\n",
       "      <td>0.711</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>0.158082</td>\n",
       "      <td>0.672</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.165455</td>\n",
       "      <td>0.672</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.156181</td>\n",
       "      <td>0.661</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>0.143215</td>\n",
       "      <td>0.661</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_dual param_tol param_max_iter  mean_fit_time  \\\n",
       "23     0.1  squared_hinge      False      0.01            100       0.044880   \n",
       "15    0.01  squared_hinge      False      0.01            100       0.087365   \n",
       "7    0.001  squared_hinge      False      0.01            100       0.058641   \n",
       "6    0.001  squared_hinge      False     1e-05            100       0.117089   \n",
       "14    0.01  squared_hinge      False     1e-05            100       0.164079   \n",
       "22     0.1  squared_hinge      False     1e-05            100       0.122875   \n",
       "10    0.01  squared_hinge       True     1e-05            100       0.158082   \n",
       "11    0.01  squared_hinge       True      0.01            100       0.165455   \n",
       "1    0.001          hinge       True      0.01            100       0.156181   \n",
       "0    0.001          hinge       True     1e-05            100       0.143215   \n",
       "\n",
       "    mean_test_score  rank_test_score  \n",
       "23            0.745                1  \n",
       "15            0.745                1  \n",
       "7             0.745                1  \n",
       "6             0.740                4  \n",
       "14            0.725                5  \n",
       "22            0.711                6  \n",
       "10            0.672                7  \n",
       "11            0.672                7  \n",
       "1             0.661                9  \n",
       "0             0.661                9  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for 1000 samples\n",
    "svc_gridsearch[svc_columns].sort_values(by=\"rank_test_score\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Accuracy:', CV_svc_mod_1000.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features 2000: (2000, 538)\n",
      "Training Labels 2000: (2000,)\n",
      "Testing Features 2000: (2000, 538)\n",
      "Testing Labels 2000: (2000,)\n"
     ]
    }
   ],
   "source": [
    "#2000\n",
    "# Create Dataframe of 2000 Rows\n",
    "Xtrain_2000 = pd.DataFrame.sample(X_train, n=2000, random_state=123)\n",
    "ytrain_2000 = pd.DataFrame.sample(y_train,n=2000, random_state=123)\n",
    "Xtest_2000 = pd.DataFrame.sample(X_test,n=2000, random_state=123)\n",
    "ytest_2000 = pd.DataFrame.sample(y_test,n=2000, random_state=123)\n",
    "print('Training Features 2000:', Xtrain_2000.shape)\n",
    "print('Training Labels 2000:', ytrain_2000.shape)\n",
    "print('Testing Features 2000:', Xtest_2000.shape)\n",
    "print('Testing Labels 2000:', ytest_2000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   10.6s finished\n",
      "2021-03-01 00:17:45,154 [35816] WARNING  py.warnings:110: [JupyterRequire] C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2000 \n",
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'C': [0.001,0.01,0.1],\n",
    "              'loss': ['hinge', 'squared_hinge'],\n",
    "              'penalty' : ['l2'],\n",
    "              'dual' : [True,False],\n",
    "              'tol': [0.00001,0.01], #0.0001 is the Default\n",
    "              'max_iter': [100],\n",
    "             }\n",
    "\n",
    "SVC_Linear = LinearSVC(random_state=42)\n",
    "CV_svc = GridSearchCV(estimator = SVC_Linear, param_grid=param_grid, cv= 5, n_jobs =-1,verbose=1)\n",
    "Start=time.time()\n",
    "CV_svc_mod_2000 = CV_svc.fit(Xtrain_2000, ytrain_2000)\n",
    "Stop=time.time()\n",
    "Time3=Stop-Start\n",
    "Time3\n",
    "pkl_filename = \"Pickle/CV_SVM_Linear_2000.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(CV_svc_mod_2000, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2000\n",
    "#with open(\"C://Users/18322/OneDrive - Southern Methodist University/Desktop/QOW/week7/case study 8/case_study_81_2/CV_SVM_Linear_2000.pkl\", 'rb') as file:\n",
    "#    CV_svc = pickle.load(file)\n",
    "    \n",
    "CV_svc_mod_2000 = pickle.load( open(\"Pickle/CV_SVM_Linear_2000.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_gridsearch = pd.DataFrame(CV_svc_mod_2000.cv_results_)\n",
    "svc_columns = [\n",
    "    \"param_C\",\n",
    "    \"param_loss\",\n",
    "    \"param_dual\",\n",
    "    \"param_tol\",\n",
    "    \"param_max_iter\",\n",
    "    \"mean_fit_time\",\n",
    "    \"mean_test_score\",\n",
    "    \"rank_test_score\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>0.417046</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.132361</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.134945</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.139359</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>0.567534</td>\n",
       "      <td>0.7630</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>0.492509</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.442345</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>0.464916</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.449724</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.1</td>\n",
       "      <td>hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>0.507707</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_dual param_tol param_max_iter  mean_fit_time  \\\n",
       "6    0.001  squared_hinge      False     1e-05            100       0.417046   \n",
       "23     0.1  squared_hinge      False      0.01            100       0.132361   \n",
       "15    0.01  squared_hinge      False      0.01            100       0.134945   \n",
       "7    0.001  squared_hinge      False      0.01            100       0.139359   \n",
       "14    0.01  squared_hinge      False     1e-05            100       0.567534   \n",
       "22     0.1  squared_hinge      False     1e-05            100       0.492509   \n",
       "19     0.1  squared_hinge       True      0.01            100       0.442345   \n",
       "18     0.1  squared_hinge       True     1e-05            100       0.464916   \n",
       "17     0.1          hinge       True      0.01            100       0.449724   \n",
       "16     0.1          hinge       True     1e-05            100       0.507707   \n",
       "\n",
       "    mean_test_score  rank_test_score  \n",
       "6            0.7675                1  \n",
       "23           0.7650                2  \n",
       "15           0.7650                2  \n",
       "7            0.7650                2  \n",
       "14           0.7630                5  \n",
       "22           0.7600                6  \n",
       "19           0.7550                7  \n",
       "18           0.7550                7  \n",
       "17           0.7550                7  \n",
       "16           0.7550                7  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_gridsearch[svc_columns].sort_values(by=\"rank_test_score\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Accuracy:', CV_svc_mod_2000.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features 5000: (5000, 538)\n",
      "Training Labels 5000: (5000,)\n",
      "Testing Features 5000: (5000, 538)\n",
      "Testing Labels 5000: (5000,)\n"
     ]
    }
   ],
   "source": [
    "#5000\n",
    "# Create Dataframe of 5000 Rows\n",
    "Xtrain_5000 = pd.DataFrame.sample(X_train, n=5000, random_state=123)\n",
    "ytrain_5000 = pd.DataFrame.sample(y_train,n=5000, random_state=123)\n",
    "Xtest_5000 = pd.DataFrame.sample(X_test,n=5000, random_state=123)\n",
    "ytest_5000 = pd.DataFrame.sample(y_test,n=5000, random_state=123)\n",
    "print('Training Features 5000:', Xtrain_5000.shape)\n",
    "print('Training Labels 5000:', ytrain_5000.shape)\n",
    "print('Testing Features 5000:', Xtest_5000.shape)\n",
    "print('Testing Labels 5000:', ytest_5000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'C': [0.001,0.01,0.1],\n",
    "              'loss': ['hinge', 'squared_hinge'],\n",
    "              'penalty' : ['l2'],\n",
    "              'dual' : [True,False],\n",
    "              'tol': [0.00001,0.01], #0.0001 is the Default\n",
    "              'max_iter': [100],\n",
    "             }\n",
    "\n",
    "SVC_Linear = LinearSVC(random_state=42)\n",
    "CV_svc = GridSearchCV(estimator = SVC_Linear, param_grid=param_grid, cv= 5, n_jobs =-1,verbose=1)\n",
    "Start=time.time()\n",
    "CV_svc_mod_5000 = CV_svc.fit(Xtrain_5000, ytrain_5000)\n",
    "Stop=time.time()\n",
    "Time4=Stop-Start\n",
    "Time4\n",
    "pkl_filename = \"Pickle/CV_SVM_Linear_5000.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(CV_svc_mod_5000, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"C://Users/18322/OneDrive - Southern Methodist University/Desktop/QOW/week7/case study 8/case_study_81_2/CV_SVM_Linear_5000.pkl\", 'rb') as file:\n",
    "#    CV_svc = pickle.load(file)\n",
    "    \n",
    "CV_svc_mod_5000 = pickle.load( open(\"Pickle/CV_SVM_Linear_5000.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_gridsearch = pd.DataFrame(CV_svc_mod_5000.cv_results_)\n",
    "svc_columns = [\n",
    "    \"param_C\",\n",
    "    \"param_loss\",\n",
    "    \"param_dual\",\n",
    "    \"param_tol\",\n",
    "    \"param_max_iter\",\n",
    "    \"mean_fit_time\",\n",
    "    \"mean_test_score\",\n",
    "    \"rank_test_score\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1.029846</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>0.939270</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.230186</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.244742</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.227392</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1.177088</td>\n",
       "      <td>0.7646</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1.197936</td>\n",
       "      <td>0.6860</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1.296276</td>\n",
       "      <td>0.6860</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01</td>\n",
       "      <td>hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1.226919</td>\n",
       "      <td>0.6544</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1.168087</td>\n",
       "      <td>0.6544</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_dual param_tol param_max_iter  mean_fit_time  \\\n",
       "6    0.001  squared_hinge      False     1e-05            100       1.029846   \n",
       "22     0.1  squared_hinge      False     1e-05            100       0.939270   \n",
       "23     0.1  squared_hinge      False      0.01            100       0.230186   \n",
       "15    0.01  squared_hinge      False      0.01            100       0.244742   \n",
       "7    0.001  squared_hinge      False      0.01            100       0.227392   \n",
       "14    0.01  squared_hinge      False     1e-05            100       1.177088   \n",
       "0    0.001          hinge       True     1e-05            100       1.197936   \n",
       "1    0.001          hinge       True      0.01            100       1.296276   \n",
       "8     0.01          hinge       True     1e-05            100       1.226919   \n",
       "9     0.01          hinge       True      0.01            100       1.168087   \n",
       "\n",
       "    mean_test_score  rank_test_score  \n",
       "6            0.7660                1  \n",
       "22           0.7648                2  \n",
       "23           0.7648                3  \n",
       "15           0.7648                3  \n",
       "7            0.7648                3  \n",
       "14           0.7646                6  \n",
       "0            0.6860                7  \n",
       "1            0.6860                7  \n",
       "8            0.6544                9  \n",
       "9            0.6544                9  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_gridsearch[svc_columns].sort_values(by=\"rank_test_score\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Accuracy:', CV_svc_mod_5000.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features 10000: (10000, 538)\n",
      "Training Labels 10000: (10000,)\n",
      "Testing Features 10000: (10000, 538)\n",
      "Testing Labels 10000: (10000,)\n"
     ]
    }
   ],
   "source": [
    "#10000\n",
    "# Create Dataframe of 10000 Rows\n",
    "Xtrain_10000 = pd.DataFrame.sample(X_train, n=10000, random_state=123)\n",
    "ytrain_10000 = pd.DataFrame.sample(y_train,n=10000, random_state=123)\n",
    "Xtest_10000 = pd.DataFrame.sample(X_test,n=10000, random_state=123)\n",
    "ytest_10000 = pd.DataFrame.sample(y_test,n=10000, random_state=123)\n",
    "print('Training Features 10000:', Xtrain_10000.shape)\n",
    "print('Training Labels 10000:', ytrain_10000.shape)\n",
    "print('Testing Features 10000:', Xtest_10000.shape)\n",
    "print('Testing Labels 10000:', ytest_10000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   14.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch to determine the value of C\n",
    "param_grid = {'C': [0.001,0.01,0.1],\n",
    "              'loss': ['hinge', 'squared_hinge'],\n",
    "              'penalty' : ['l2'],\n",
    "              'dual' : [True,False],\n",
    "              'tol': [0.00001,0.01], #0.0001 is the Default\n",
    "              'max_iter': [100],\n",
    "             }\n",
    "\n",
    "SVC_Linear = LinearSVC(random_state=42)\n",
    "CV_svc = GridSearchCV(estimator = SVC_Linear, param_grid=param_grid, cv= 5, n_jobs =-1,verbose=1)\n",
    "Start=time.time()\n",
    "CV_svc_mod_10000 = CV_svc.fit(Xtrain_10000, ytrain_10000)\n",
    "Stop=time.time()\n",
    "Time5=Stop-Start\n",
    "Time5\n",
    "pkl_filename = \"Pickle/CV_SVM_Linear_10000.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(CV_svc_mod_10000, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"C://Users/18322/OneDrive - Southern Methodist University/Desktop/QOW/week7/case study 8/case_study_81_2/CV_SVM_Linear_10000.pkl\", 'rb') as file:\n",
    "#    CV_svc = pickle.load(file)\n",
    "\n",
    "CV_svc_mod_10000 = pickle.load( open(\"Pickle/CV_SVM_Linear_10000.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_gridsearch = pd.DataFrame(CV_svc_mod_10000.cv_results_)\n",
    "svc_columns = [\n",
    "    \"param_C\",\n",
    "    \"param_loss\",\n",
    "    \"param_dual\",\n",
    "    \"param_tol\",\n",
    "    \"param_max_iter\",\n",
    "    \"mean_fit_time\",\n",
    "    \"mean_test_score\",\n",
    "    \"rank_test_score\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_dual</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1.248989</td>\n",
       "      <td>0.7686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1.117655</td>\n",
       "      <td>0.7686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1.184583</td>\n",
       "      <td>0.7679</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.249406</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.241507</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.262091</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1.260491</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1.278927</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1.309391</td>\n",
       "      <td>0.7652</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.01</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>True</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1.259128</td>\n",
       "      <td>0.7652</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C     param_loss param_dual param_tol param_max_iter  mean_fit_time  \\\n",
       "14    0.01  squared_hinge      False     1e-05            100       1.248989   \n",
       "22     0.1  squared_hinge      False     1e-05            100       1.117655   \n",
       "6    0.001  squared_hinge      False     1e-05            100       1.184583   \n",
       "23     0.1  squared_hinge      False      0.01            100       0.249406   \n",
       "15    0.01  squared_hinge      False      0.01            100       0.241507   \n",
       "7    0.001  squared_hinge      False      0.01            100       0.262091   \n",
       "19     0.1  squared_hinge       True      0.01            100       1.260491   \n",
       "18     0.1  squared_hinge       True     1e-05            100       1.278927   \n",
       "10    0.01  squared_hinge       True     1e-05            100       1.309391   \n",
       "11    0.01  squared_hinge       True      0.01            100       1.259128   \n",
       "\n",
       "    mean_test_score  rank_test_score  \n",
       "14           0.7686                1  \n",
       "22           0.7686                1  \n",
       "6            0.7679                3  \n",
       "23           0.7660                4  \n",
       "15           0.7660                4  \n",
       "7            0.7660                4  \n",
       "19           0.7656                7  \n",
       "18           0.7656                7  \n",
       "10           0.7652                9  \n",
       "11           0.7652                9  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_gridsearch[svc_columns].sort_values(by=\"rank_test_score\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Accuracy:', CV_svc_mod_10000.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Random Forest Model\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cda592a95acd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Default max_levels is None, so the tree is very large\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mrf_base\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# RF Base Model\n",
    "########################\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Full Dataset used for Base Model.\n",
    "# Default max_levels is None, so the tree is very large\n",
    "\n",
    "rf_base = RandomForestClassifier(n_estimators=10, random_state=123 ) \n",
    "\n",
    "start = time.time()\n",
    "rf_base.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "rf_base_time=round((end-start),2)\n",
    "rf_base_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base_preds = rf_base.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9337292313310098\n",
      "0.7515241478025765\n"
     ]
    }
   ],
   "source": [
    "rf_base_log_loss = log_loss(y_test,rf_base_preds[:,1]) # each column is class probability, \n",
    "print(rf_base_log_loss)\n",
    "rf_base_accuracy = accuracy_score(y_test,np.rint(rf_base_preds[:,1]))\n",
    "print(rf_base_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Begin Hypertuning for Random Forest\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters Used by Base Model:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 10,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 123,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Citation:  Thank you to Will Koehrsen and Towards Data Science. RF Hypertuning code is borrowed from his example. \n",
    "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "# Note - different from tutorial, we are using rf=RandomForestClassifier(), not RandomForestRegressor()\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters Used by Base Model:\\n')\n",
    "pprint(rf_base.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Grid Parameters:\n",
      "\n",
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [100, 500, 1000, 1500]}\n"
     ]
    }
   ],
   "source": [
    "# Define Random Grid Parameters and use RandomizedSearchCV to choose \n",
    "# different combinations of parameters for different sizes of datasets\n",
    "\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [100,500,1000,1500]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [10, 100, 200,300,400,500,600,700,800,900,1000]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print('Random Grid Parameters:\\n')\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (76595, 538)\n",
      "Training Labels Shape: (76595,)\n",
      "Testing Features Shape: (37726, 538)\n",
      "Testing Labels Shape: (37726,)\n"
     ]
    }
   ],
   "source": [
    "# Adapt variable names for this example\n",
    "train_features = X_train\n",
    "train_labels = y_train\n",
    "test_features = X_test\n",
    "test_labels = y_test\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features 1000: (1000, 538)\n",
      "Training Labels 1000: (1000,)\n",
      "Testing Features 1000: (1000, 538)\n",
      "Testing Labels 1000: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Create Smaller Dataframe of 1000 Rows\n",
    "train_features_1000 = pd.DataFrame.sample(X_train, n=1000, random_state=123)\n",
    "train_labels_1000 = pd.DataFrame.sample(y_train,n=1000, random_state=123)\n",
    "test_features_1000 = pd.DataFrame.sample(X_test,n=1000, random_state=123)\n",
    "test_labels_1000 = pd.DataFrame.sample(y_test,n=1000, random_state=123)\n",
    "print('Training Features 1000:', train_features_1000.shape)\n",
    "print('Training Labels 1000:', train_labels_1000.shape)\n",
    "print('Testing Features 1000:', test_features_1000.shape)\n",
    "print('Testing Labels 1000:', test_labels_1000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features 5000: (5000, 538)\n",
      "Training Labels 5000: (5000,)\n",
      "Testing Features 5000: (5000, 538)\n",
      "Testing Labels 5000: (5000,)\n"
     ]
    }
   ],
   "source": [
    "# Create Medium DataFrame of 5000 Rows\n",
    "train_features_5000 = pd.DataFrame.sample(X_train, n=5000, random_state=123)\n",
    "train_labels_5000 = pd.DataFrame.sample(y_train,n=5000, random_state=123)\n",
    "test_features_5000 = pd.DataFrame.sample(X_test,n=5000, random_state=123)\n",
    "test_labels_5000 = pd.DataFrame.sample(y_test,n=5000, random_state=123)\n",
    "print('Training Features 5000:', train_features_5000.shape)\n",
    "print('Training Labels 5000:', train_labels_5000.shape)\n",
    "print('Testing Features 5000:', test_features_5000.shape)\n",
    "print('Testing Labels 5000:', test_labels_5000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Code Commented - Using Pickled Models\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# Define estimator - same parameters as base model\n",
    "\n",
    "# rf = RandomForestClassifier(n_estimators=50, random_state=123 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the FULL model based on the random_grid parameters\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = 5, verbose=2, random_state=123, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the SMALL random search model with 1000 rows\n",
    "# rf_random_1000 = rf_random.fit(train_features_1000, train_labels_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the MEDIUM model with 5000 rows\n",
    "# rf_random_5000 = rf_random.fit(train_features_5000, train_labels_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a model on all data using the same random_grid parameters\n",
    "# rf_random_all = rf_random.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(rf_random_all,open(\"rf_random_all.pkl\",\"wb\"))\n",
    "#pickle.dump(rf_random_1000,open(\"rf_random_1000.pkl\",\"wb\"))\n",
    "#pickle.dump(rf_random_5000,open(\"rf_random_5000.pkl\",\"wb\"))\n",
    "#pickle.dump(rf_base,open(\"rf_base.pkl\",\"wb\"))\n",
    "#pickle.dump(rf_base_time,open(\"rf_base_time.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pickled Models to avoid re-running models\n",
    "\n",
    "rf_random_all = pickle.load( open(\"Pickle/rf_random_all.pkl\", \"rb\"))\n",
    "rf_random_1000 = pickle.load( open(\"Pickle/rf_random_1000.pkl\", \"rb\"))\n",
    "rf_random_5000 = pickle.load( open(\"Pickle/rf_random_5000.pkl\", \"rb\"))\n",
    "rf_base = pickle.load( open(\"Pickle/rf_base.pkl\", \"rb\"))\n",
    "\n",
    "# Load other stored variables\n",
    "rf_base_time = pickle.load( open(\"Pickle/rf_base_time.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Compare Random Grid Parameters among different datasets - 1000, 5000, All\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random_1000.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 1000,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random_5000.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 1000,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random_all.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Determine Log-Loss and Accuracy for All RF Models\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Predictions for Base model\n",
    "rf_base_preds = rf_base.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24818377998398874\n",
      "0.9273975507607486\n"
     ]
    }
   ],
   "source": [
    "# Log-Loss and Accuracy for Base Model\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import log_loss, accuracy_score\n",
    "rf_base_log_loss = log_loss(y_test,rf_base_preds[:,1]) # each column is class probability, \n",
    "print(rf_base_log_loss)\n",
    "rf_base_accuracy = accuracy_score(y_test,np.rint(rf_base_preds[:,1]))\n",
    "print(rf_base_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Predictions for 1000 element tuned model\n",
    "rf_1000_preds = rf_random_1000.predict_proba(test_features_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48383002447131424\n",
      "0.786\n"
     ]
    }
   ],
   "source": [
    "# Log-Loss and Accuracy for 1000 Row Model\n",
    "rf_1000_log_loss = log_loss(test_labels_1000,rf_1000_preds[:,1]) # each column is class probability, \n",
    "print(rf_1000_log_loss)\n",
    "rf_1000_accuracy = accuracy_score(test_labels_1000,np.rint(rf_1000_preds[:,1]))\n",
    "print(rf_1000_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Predictions for 5000 element tuned model\n",
    "rf_5000_preds = rf_random_5000.predict_proba(test_features_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2587950210933267\n",
      "0.9172\n"
     ]
    }
   ],
   "source": [
    "# Log-Loss and Accuracy for 5000 Row Model\n",
    "rf_5000_log_loss = log_loss(test_labels_5000,rf_5000_preds[:,1]) # each column is class probability, \n",
    "print(rf_5000_log_loss)\n",
    "rf_5000_accuracy = accuracy_score(test_labels_5000,np.rint(rf_5000_preds[:,1]))\n",
    "print(rf_5000_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Predictions for Full Model\n",
    "rf_all_preds = rf_random_all.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26495811383785384\n",
      "0.9139585431797699\n"
     ]
    }
   ],
   "source": [
    "# Log-Loss and Accuracy for Full Model\n",
    "rf_all_log_loss = log_loss(test_labels,rf_all_preds[:,1]) # each column is class probability, \n",
    "print(rf_all_log_loss)\n",
    "rf_all_accuracy = accuracy_score(test_labels,np.rint(rf_all_preds[:,1]))\n",
    "print(rf_all_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  Feature Importance of Base RF Model\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.19576698e-02, 4.61408532e-03, 4.54027314e-03, 4.70482752e-03,\n",
       "       5.04434562e-03, 4.89174431e-03, 4.29335739e-03, 4.71446799e-03,\n",
       "       4.33285167e-03, 2.53118395e-02, 4.18768936e-03, 2.74401645e-02,\n",
       "       4.24549574e-03, 2.24728625e-02, 4.51155587e-03, 4.70138546e-03,\n",
       "       4.07981463e-03, 4.66154902e-03, 4.32649362e-03, 4.55287778e-03,\n",
       "       2.36252049e-02, 2.97495910e-03, 4.83270092e-03, 4.10554682e-03,\n",
       "       4.39553108e-03, 4.58738124e-03, 3.93261673e-03, 4.28856168e-03,\n",
       "       4.11493552e-03, 2.35251656e-02, 4.48150958e-03, 4.97092891e-03,\n",
       "       4.69097167e-03, 8.44852224e-04, 4.56074273e-03, 2.38307012e-02,\n",
       "       4.06558251e-03, 4.10675339e-03, 4.14507300e-03, 4.40307200e-03,\n",
       "       4.35607051e-03, 4.62930976e-03, 4.05495603e-03, 4.23632962e-03,\n",
       "       6.04834561e-02, 4.31834504e-03, 4.42748648e-03, 4.86906825e-03,\n",
       "       4.45527694e-03, 4.49465475e-03, 4.47505121e-03, 4.40967058e-03,\n",
       "       4.30586393e-03, 4.24420884e-03, 5.77902399e-03, 4.65919257e-03,\n",
       "       4.29646248e-03, 4.23596110e-03, 4.13769516e-03, 4.62747596e-03,\n",
       "       4.79847581e-03, 4.96326744e-03, 4.85468987e-03, 4.34816359e-03,\n",
       "       4.08267411e-03, 4.10669970e-03, 4.48577477e-03, 4.27239846e-03,\n",
       "       4.90572625e-03, 4.94663101e-03, 4.45542365e-03, 4.20347419e-03,\n",
       "       4.88923151e-03, 4.37896839e-03, 4.82268390e-03, 4.60666937e-03,\n",
       "       4.63525565e-03, 4.42760693e-03, 4.04569835e-03, 4.08931141e-03,\n",
       "       4.35296175e-03, 4.23361427e-03, 4.06210305e-03, 4.26940698e-03,\n",
       "       5.03295089e-03, 4.90955336e-03, 4.48772712e-03, 4.54793638e-03,\n",
       "       4.66487371e-03, 4.52246681e-03, 4.29532532e-03, 4.51421155e-03,\n",
       "       3.91441636e-03, 4.94528532e-03, 4.76524496e-03, 4.36378715e-03,\n",
       "       2.49368096e-02, 4.72404952e-03, 4.22808435e-03, 4.68432405e-03,\n",
       "       4.31596025e-03, 4.50018141e-03, 4.82522551e-03, 4.14196338e-03,\n",
       "       4.34990601e-03, 4.29001663e-03, 4.71185014e-03, 4.56621538e-03,\n",
       "       4.47170104e-03, 4.57825000e-03, 5.53908348e-03, 4.12908563e-03,\n",
       "       4.41852369e-03, 2.54004394e-05, 2.74933728e-05, 2.12694991e-05,\n",
       "       1.24306579e-04, 7.06309615e-05, 1.83493530e-04, 1.95827069e-04,\n",
       "       1.66573377e-04, 1.89412937e-04, 2.01096373e-04, 1.09923060e-04,\n",
       "       2.23111695e-04, 1.08342626e-04, 1.36453881e-04, 1.40313608e-04,\n",
       "       9.23674689e-04, 1.80819595e-04, 7.88653360e-05, 1.74448423e-04,\n",
       "       1.81885577e-04, 2.70236367e-04, 1.66474916e-04, 1.42727207e-04,\n",
       "       1.55435636e-04, 8.89766900e-05, 1.53067639e-04, 2.73087641e-04,\n",
       "       1.03984958e-04, 8.11105103e-05, 1.15089862e-04, 1.28179643e-04,\n",
       "       2.71396471e-04, 8.82736849e-05, 1.25203360e-04, 1.25073893e-04,\n",
       "       3.63750965e-04, 1.48598787e-04, 1.26851273e-04, 1.95659326e-04,\n",
       "       1.32535811e-04, 1.07272428e-04, 1.04785043e-04, 7.72072166e-05,\n",
       "       1.77091445e-04, 2.36757909e-04, 1.70837183e-04, 2.90568738e-04,\n",
       "       3.12715120e-04, 3.43341381e-04, 1.02091925e-04, 1.43551548e-04,\n",
       "       1.19334686e-04, 1.88758136e-04, 1.32031075e-04, 1.70739977e-04,\n",
       "       1.34041510e-04, 2.47020596e-04, 2.36518270e-04, 8.68803090e-05,\n",
       "       1.76367906e-04, 1.00568646e-04, 1.90118218e-04, 7.75785426e-04,\n",
       "       1.75561688e-04, 1.22049161e-03, 1.54836293e-03, 2.61477475e-03,\n",
       "       3.61264114e-03, 3.43330327e-03, 5.43763469e-04, 4.22599984e-05,\n",
       "       2.04852161e-03, 1.07197816e-03, 5.68018268e-04, 5.29238189e-04,\n",
       "       1.38754061e-03, 4.73326287e-03, 1.27595597e-03, 5.74684827e-04,\n",
       "       3.04144390e-05, 1.45258311e-05, 2.68055121e-03, 2.33255330e-04,\n",
       "       1.07274183e-03, 6.86160049e-04, 7.46941091e-04, 0.00000000e+00,\n",
       "       2.68969182e-03, 7.07513138e-04, 2.27735842e-03, 2.24227069e-03,\n",
       "       2.46207353e-03, 2.32227765e-03, 2.33086267e-03, 2.52010851e-03,\n",
       "       2.37228516e-03, 2.29398076e-03, 2.48736925e-03, 2.66476152e-03,\n",
       "       2.13190093e-03, 2.28080932e-03, 1.20596312e-05, 3.13181928e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.53716157e-04,\n",
       "       4.62617392e-04, 3.22426617e-05, 1.32723410e-04, 0.00000000e+00,\n",
       "       3.96113319e-05, 7.24101742e-05, 4.80447222e-07, 1.59100020e-04,\n",
       "       1.00228622e-04, 0.00000000e+00, 7.62196353e-05, 9.13298174e-04,\n",
       "       2.29698122e-06, 1.56694305e-05, 0.00000000e+00, 9.42177642e-04,\n",
       "       0.00000000e+00, 2.51536688e-05, 9.65568867e-05, 7.24120813e-07,\n",
       "       1.75796957e-04, 0.00000000e+00, 1.02147554e-05, 0.00000000e+00,\n",
       "       2.31585403e-06, 5.78321660e-05, 2.23130924e-05, 6.82549862e-06,\n",
       "       8.58384446e-04, 5.74466965e-04, 5.14431604e-04, 1.02733948e-04,\n",
       "       1.31125866e-05, 0.00000000e+00, 0.00000000e+00, 5.13112954e-05,\n",
       "       1.21673683e-06, 1.20252649e-05, 0.00000000e+00, 2.50264158e-05,\n",
       "       4.63700364e-04, 2.60120604e-03, 3.11364563e-04, 4.93507569e-05,\n",
       "       1.23851821e-03, 3.46982077e-05, 4.79993237e-05, 6.57883778e-06,\n",
       "       9.26484896e-05, 0.00000000e+00, 0.00000000e+00, 3.31148179e-05,\n",
       "       0.00000000e+00, 5.61997005e-05, 1.10851826e-04, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.79237738e-05, 1.86935927e-04, 1.19757564e-03,\n",
       "       1.49372707e-05, 1.91049485e-04, 0.00000000e+00, 1.19433666e-04,\n",
       "       8.53069442e-07, 0.00000000e+00, 9.14139534e-06, 7.14993594e-07,\n",
       "       1.79725404e-03, 0.00000000e+00, 0.00000000e+00, 1.87453695e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.23094797e-06,\n",
       "       6.76028780e-04, 1.86917371e-05, 2.88857284e-04, 1.35746406e-03,\n",
       "       5.10741293e-04, 3.77701227e-05, 4.21926473e-05, 1.93095000e-05,\n",
       "       5.43978123e-05, 1.39638366e-03, 1.13187976e-03, 1.69381039e-05,\n",
       "       5.39827564e-04, 4.40109539e-04, 0.00000000e+00, 4.42090457e-05,\n",
       "       2.72504858e-05, 1.72614436e-05, 8.07719691e-04, 5.93405813e-04,\n",
       "       3.00543378e-05, 0.00000000e+00, 1.72129229e-06, 4.38762351e-04,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       7.50338005e-04, 0.00000000e+00, 2.74232348e-03, 0.00000000e+00,\n",
       "       2.55836996e-04, 0.00000000e+00, 3.72568845e-04, 2.21190838e-04,\n",
       "       1.43084138e-07, 0.00000000e+00, 2.03106847e-04, 4.14633004e-05,\n",
       "       4.47640158e-03, 5.46458158e-03, 6.95946871e-03, 0.00000000e+00,\n",
       "       2.93317877e-03, 1.73990829e-03, 0.00000000e+00, 2.99929110e-03,\n",
       "       2.56776743e-06, 1.70231687e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "       7.52471660e-06, 2.43865672e-04, 2.66432655e-04, 1.72003022e-05,\n",
       "       2.76946338e-03, 3.87356054e-05, 2.86155345e-03, 8.84101574e-05,\n",
       "       4.00973227e-03, 2.34966438e-03, 9.46756254e-04, 1.32674100e-03,\n",
       "       7.47842613e-05, 1.50761212e-05, 5.60172094e-04, 8.50274306e-04,\n",
       "       1.14709526e-04, 6.07251902e-04, 0.00000000e+00, 8.09251666e-04,\n",
       "       1.83656204e-05, 3.58782012e-04, 2.03227006e-04, 5.64559573e-04,\n",
       "       1.28860827e-05, 3.10084072e-03, 2.84709424e-03, 2.96224209e-03,\n",
       "       9.68176636e-05, 7.26218018e-04, 2.19342257e-03, 3.15095697e-03,\n",
       "       2.19159580e-03, 2.84088295e-03, 2.88437032e-03, 2.96774490e-03,\n",
       "       3.09536333e-03, 7.05958777e-04, 1.15147677e-04, 4.08359096e-03,\n",
       "       3.22983596e-03, 2.58329173e-04, 1.88723942e-03, 9.34313633e-04,\n",
       "       7.57055648e-04, 1.76222247e-03, 1.49479948e-03, 3.08634085e-03,\n",
       "       7.13091307e-04, 1.44654322e-03, 2.20296468e-03, 1.39830127e-03,\n",
       "       1.12689287e-03, 1.23370596e-03, 5.72953441e-04, 1.88697845e-03,\n",
       "       1.16985829e-03, 1.46906566e-03, 8.77790809e-04, 1.27767507e-03,\n",
       "       4.11196560e-04, 1.16643982e-03, 1.33464864e-03, 7.74161609e-04,\n",
       "       2.88282305e-04, 1.56963778e-08, 6.58285595e-04, 1.66247279e-03,\n",
       "       2.01795038e-04, 5.57773878e-04, 1.19065500e-03, 8.59052095e-04,\n",
       "       5.14626666e-04, 3.26117624e-04, 5.58825139e-04, 2.21572557e-07,\n",
       "       5.84951695e-04, 3.85437459e-04, 1.76457117e-04, 2.17623585e-04,\n",
       "       9.21530546e-05, 3.21602650e-03, 1.22140220e-05, 9.60876638e-04,\n",
       "       1.60124049e-04, 3.09974776e-04, 9.75534992e-04, 2.01688740e-04,\n",
       "       8.31186668e-05, 9.71383991e-04, 3.57265403e-04, 1.25548067e-04,\n",
       "       5.10551899e-04, 4.94192270e-04, 3.61042372e-04, 6.57704490e-04,\n",
       "       7.08350161e-04, 6.41547994e-04, 7.26995550e-04, 2.72957610e-04,\n",
       "       8.33271017e-04, 3.85393631e-04, 9.61226200e-05, 1.01715035e-03,\n",
       "       3.61970603e-04, 4.12161562e-04, 7.12664832e-04, 4.26350366e-04,\n",
       "       3.09721409e-04, 6.00479217e-04, 8.51278834e-05, 1.36145431e-03,\n",
       "       5.99698843e-04, 3.72760455e-04, 6.86691465e-04, 3.75835536e-04,\n",
       "       1.36797109e-03, 2.47316479e-04, 1.02583890e-03, 3.23943725e-04,\n",
       "       4.87512832e-04, 5.91838392e-04, 3.65676160e-04, 3.69384385e-04,\n",
       "       4.17627861e-05, 5.08768857e-04, 7.78862369e-04, 8.68579165e-04,\n",
       "       2.50864184e-04, 7.93733299e-05, 2.64925241e-04, 9.41540318e-04,\n",
       "       4.17095219e-04, 4.02885951e-04, 1.60405536e-04, 4.96035495e-04,\n",
       "       4.28745449e-04, 1.42545366e-03, 7.53628543e-04, 6.26934009e-04,\n",
       "       1.77717844e-03, 4.61356253e-04, 5.11173338e-04, 4.01239311e-04,\n",
       "       3.67931304e-04, 4.21301233e-04, 2.35173402e-04, 2.49097441e-04,\n",
       "       5.74008478e-04, 4.82927529e-04, 1.04483759e-03, 7.18448703e-04,\n",
       "       1.37272816e-03, 1.82682680e-06, 3.31779683e-04, 6.97077519e-04,\n",
       "       4.24798918e-04, 4.37114327e-04, 8.57595020e-04, 4.95756146e-04,\n",
       "       5.86053205e-04, 1.21320890e-03, 4.93604290e-04, 2.52189488e-04,\n",
       "       7.74686488e-04, 3.62113573e-04, 2.91734814e-04, 5.98962065e-04,\n",
       "       1.01921155e-03, 2.43672730e-04, 9.76607112e-04, 1.24287848e-03,\n",
       "       2.86509193e-04, 5.14574235e-04, 1.17435983e-03, 1.18877379e-03,\n",
       "       4.67374030e-04, 6.28369628e-04, 2.37936407e-04, 7.97930511e-04,\n",
       "       6.62439286e-04, 5.69390890e-04, 4.97797317e-04, 4.72505073e-04,\n",
       "       5.31497414e-04, 1.00473644e-03, 3.97094551e-04, 4.76147072e-04,\n",
       "       5.54053070e-04, 5.95136452e-04])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_base.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Features for Base Model\n",
    "importances = rf_base.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf_base.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Ten Features:\n",
      "1. feature 44 (0.060483)\n",
      "2. feature 11 (0.027440)\n",
      "3. feature 9 (0.025312)\n",
      "4. feature 96 (0.024937)\n",
      "5. feature 35 (0.023831)\n",
      "6. feature 20 (0.023625)\n",
      "7. feature 29 (0.023525)\n",
      "8. feature 13 (0.022473)\n",
      "9. feature 0 (0.021958)\n",
      "10. feature 338 (0.006959)\n"
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "\n",
    "#for f in range(X_train.shape[1]):\n",
    "#    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "print(\"Top Ten Features:\")\n",
    "\n",
    "for f in range(0, 10):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "#  RESULTS\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Summary Table for All Model Types\n",
    "data = [['XGBoost','Base',xgb_base_log_loss, xgb_base_accuracy, xgb_base_time],\n",
    "        ['Random Forest Complete Dataset','Base',rf_base_log_loss, rf_base_accuracy, rf_base_time],\n",
    "        ['Random Forest Complete Dataset','Tuned',rf_all_log_loss, rf_all_accuracy, 90],\n",
    "        ['Random Forest 1000 Entries', 'Tuned', rf_1000_log_loss, rf_1000_accuracy, 2],\n",
    "        [' Random Forest 5000 Entries', 'Tuned', rf_5000_log_loss, rf_5000_accuracy, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                           Tuning      Log-Loss    Accuracy    Wall Time\n",
      "------------------------------  --------  ----------  ----------  -----------\n",
      "XGBoost                         Base        0.585187    0.766395         7.89\n",
      "Random Forest Complete Dataset  Base        0.248184    0.927398        41.22\n",
      "Random Forest Complete Dataset  Tuned       0.264958    0.913959        90\n",
      "Random Forest 1000 Entries      Tuned       0.48383     0.786            2\n",
      "Random Forest 5000 Entries      Tuned       0.258795    0.9172           7\n"
     ]
    }
   ],
   "source": [
    "#from tabulate import tabulate\n",
    "print (tabulate(data, headers=[\"Model\", \"Tuning\",\"Log-Loss\", \"Accuracy\", \"Wall Time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#  Visualizations\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Tree Visualization \n",
    "# All Credit to https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough#Visualize-Single-Decision-Tree\n",
    "\n",
    "#model = RandomForestClassifier(max_depth = 3, n_estimators=10)\n",
    "#model.fit(train_selected, train_labels)\n",
    "model = rf_base\n",
    "estimator_limited = model.estimators_[1]\n",
    "estimator_limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_selected = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(estimator_limited, out_file='Images/1_tree.dot', feature_names = train_selected.columns,\n",
    "                rounded = True, proportion = False, precision = 2, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert .dot file to .png - commented out because run time is long.\n",
    "# Using .png in write-up\n",
    "#import os\n",
    "#os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "#os.system('dot -Tpng tree_limited.dot -o tree_limited.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 50,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 123,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "### Create Small Tree with 3 Levels to be able to visualize\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf_base.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit depth of tree to 3 levels to be able to see details. \n",
    "rf_small = RandomForestClassifier(n_estimators=10, max_depth = 3)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "# Extract the small tree\n",
    "tree_small = rf_small.estimators_[5]\n",
    "\n",
    "# Save the tree as a png image - Commented out to save time since already done\n",
    "# export_graphviz(tree_small, out_file = 'Images\\\\small_tree.dot', feature_names = train_selected.columns, rounded = True, precision = 1)\n",
    "# (graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "# graph.write_png('small_tree.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Old Code Below Here ##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.57"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "start = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "rf_time=round((end-start),2)\n",
    "rf_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4925212965112307\n",
      "0.7761755818268569\n"
     ]
    }
   ],
   "source": [
    "rf_base_log_loss = log_loss(y_test,preds[:,1]) # each column is class probability, \n",
    "print(rf_base_log_loss)\n",
    "rf_base_accuracy = accuracy_score(y_test,np.rint(preds[:,1]))\n",
    "print(rf_base_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['XGBoost',xgb_base_log_loss, xgb_base_accuracy, xgb_time],\n",
    "        ['LinearSVC', \"N/A\", svm_base_accuracy, LinearSVC_time],\n",
    "        ['Random Forest',rf_base_log_loss, rf_base_accuracy, rf_time]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['XGBoost', 0.5851586336031108, 0.7655198006679743, 10.97], ['LinearSVC', 'N/A', 0.528547951015215, 61.67], ['Random Forest', 0.4925212965112307, 0.7761755818268569, 31.57]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "rowlen=len(data)\n",
    "print(rowlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Model', 'Log-Loss', 'Accuracy', 'Wall Time']\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rownums=np.arange(0,rowlen,1)\n",
    "rownums=rownums+1\n",
    "\n",
    "headers=['Model', 'Log-Loss', 'Accuracy', 'Wall Time']\n",
    "print(headers)\n",
    "print(rownums)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model  Log-Loss  Accuracy  Wall Time\n",
      "1        XGBoost  0.585159  0.765520      10.97\n",
      "2      LinearSVC       N/A  0.528548      61.67\n",
      "3  Random Forest  0.492521  0.776176      31.57\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(data, rownums,headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model          Log-Loss              Accuracy    Wall Time\n",
      "-------------  ------------------  ----------  -----------\n",
      "XGBoost        0.5851586336031108    0.76552         10.97\n",
      "LinearSVC      N/A                   0.528548        61.67\n",
      "Random Forest  0.4925212965112307    0.776176        31.57\n"
     ]
    }
   ],
   "source": [
    "# Output table of the models results\n",
    "\n",
    "print (tabulate(data, headers=[\"Model\", \"Log-Loss\", \"Accuracy\", \"Wall Time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#. Extra code for loading and plotting\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1a23145f50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 385.78125 262.19625\" width=\"385.78125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 262.19625 \n",
       "L 385.78125 262.19625 \n",
       "L 385.78125 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 43.78125 224.64 \n",
       "L 378.58125 224.64 \n",
       "L 378.58125 7.2 \n",
       "L 43.78125 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"mcccece5c45\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.999432\" xlink:href=\"#mcccece5c45\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "       <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(51.047869 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"119.872159\" xlink:href=\"#mcccece5c45\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.2 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(111.920597 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"180.744886\" xlink:href=\"#mcccece5c45\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.4 -->\n",
       "      <defs>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(172.793324 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.617614\" xlink:href=\"#mcccece5c45\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0.6 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(233.666051 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.490341\" xlink:href=\"#mcccece5c45\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.8 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(294.538778 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"363.363068\" xlink:href=\"#mcccece5c45\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1.0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(355.411506 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- False Positive Rate -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 51.703125 72.90625 \n",
       "L 51.703125 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.109375 \n",
       "L 48.578125 43.109375 \n",
       "L 48.578125 34.8125 \n",
       "L 19.671875 34.8125 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-70\"/>\n",
       "      <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "      <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "      <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "      <path d=\"M 19.671875 64.796875 \n",
       "L 19.671875 37.40625 \n",
       "L 32.078125 37.40625 \n",
       "Q 38.96875 37.40625 42.71875 40.96875 \n",
       "Q 46.484375 44.53125 46.484375 51.125 \n",
       "Q 46.484375 57.671875 42.71875 61.234375 \n",
       "Q 38.96875 64.796875 32.078125 64.796875 \n",
       "z\n",
       "M 9.8125 72.90625 \n",
       "L 32.078125 72.90625 \n",
       "Q 44.34375 72.90625 50.609375 67.359375 \n",
       "Q 56.890625 61.8125 56.890625 51.125 \n",
       "Q 56.890625 40.328125 50.609375 34.8125 \n",
       "Q 44.34375 29.296875 32.078125 29.296875 \n",
       "L 19.671875 29.296875 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-80\"/>\n",
       "      <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "      <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "      <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "      <path d=\"M 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 8.796875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "L 35.6875 0 \n",
       "L 23.484375 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-118\"/>\n",
       "      <path d=\"M 44.390625 34.1875 \n",
       "Q 47.5625 33.109375 50.5625 29.59375 \n",
       "Q 53.5625 26.078125 56.59375 19.921875 \n",
       "L 66.609375 0 \n",
       "L 56 0 \n",
       "L 46.6875 18.703125 \n",
       "Q 43.0625 26.03125 39.671875 28.421875 \n",
       "Q 36.28125 30.8125 30.421875 30.8125 \n",
       "L 19.671875 30.8125 \n",
       "L 19.671875 0 \n",
       "L 9.8125 0 \n",
       "L 9.8125 72.90625 \n",
       "L 32.078125 72.90625 \n",
       "Q 44.578125 72.90625 50.734375 67.671875 \n",
       "Q 56.890625 62.453125 56.890625 51.90625 \n",
       "Q 56.890625 45.015625 53.6875 40.46875 \n",
       "Q 50.484375 35.9375 44.390625 34.1875 \n",
       "z\n",
       "M 19.671875 64.796875 \n",
       "L 19.671875 38.921875 \n",
       "L 32.078125 38.921875 \n",
       "Q 39.203125 38.921875 42.84375 42.21875 \n",
       "Q 46.484375 45.515625 46.484375 51.90625 \n",
       "Q 46.484375 58.296875 42.84375 61.546875 \n",
       "Q 39.203125 64.796875 32.078125 64.796875 \n",
       "z\n",
       "\" id=\"DejaVuSans-82\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(163.975781 252.916562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use x=\"57.378906\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"118.658203\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use x=\"146.441406\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"198.541016\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"260.064453\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"291.851562\" xlink:href=\"#DejaVuSans-80\"/>\n",
       "      <use x=\"352.107422\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"413.289062\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"465.388672\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"493.171875\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"532.380859\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"560.164062\" xlink:href=\"#DejaVuSans-118\"/>\n",
       "      <use x=\"619.34375\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"680.867188\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"712.654297\" xlink:href=\"#DejaVuSans-82\"/>\n",
       "      <use x=\"782.105469\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"843.384766\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"882.59375\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m3066c37533\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m3066c37533\" y=\"214.756364\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(20.878125 218.555582)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m3066c37533\" y=\"175.221818\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(20.878125 179.021037)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m3066c37533\" y=\"135.687273\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(20.878125 139.486491)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m3066c37533\" y=\"96.152727\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(20.878125 99.951946)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m3066c37533\" y=\"56.618182\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(20.878125 60.417401)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m3066c37533\" y=\"17.083636\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(20.878125 20.882855)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- True Positive Rate -->\n",
       "     <defs>\n",
       "      <path d=\"M -0.296875 72.90625 \n",
       "L 61.375 72.90625 \n",
       "L 61.375 64.59375 \n",
       "L 35.5 64.59375 \n",
       "L 35.5 0 \n",
       "L 25.59375 0 \n",
       "L 25.59375 64.59375 \n",
       "L -0.296875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-84\"/>\n",
       "      <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "      <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-117\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(14.798438 161.466094)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-84\"/>\n",
       "      <use x=\"60.865234\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"101.978516\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "      <use x=\"165.357422\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"226.880859\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"258.667969\" xlink:href=\"#DejaVuSans-80\"/>\n",
       "      <use x=\"318.923828\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"380.105469\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"432.205078\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"459.988281\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"499.197266\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"526.980469\" xlink:href=\"#DejaVuSans-118\"/>\n",
       "      <use x=\"586.160156\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"647.683594\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"679.470703\" xlink:href=\"#DejaVuSans-82\"/>\n",
       "      <use x=\"748.921875\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"810.201172\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"849.410156\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path clip-path=\"url(#pb5a98b660a)\" d=\"M 58.999432 214.756364 \n",
       "L 59.471732 210.858553 \n",
       "L 60.551275 203.283302 \n",
       "L 63.013982 193.476795 \n",
       "L 66.083932 183.091815 \n",
       "L 66.083932 183.084929 \n",
       "L 71.245497 172.569103 \n",
       "L 71.245497 172.562216 \n",
       "L 77.385397 161.52301 \n",
       "L 84.469898 150.16702 \n",
       "L 84.469898 150.160134 \n",
       "L 92.532734 139.038288 \n",
       "L 92.532734 139.031402 \n",
       "L 100.831721 128.219453 \n",
       "L 100.831721 128.212566 \n",
       "L 100.865456 128.212566 \n",
       "L 111.458471 116.904783 \n",
       "L 122.490051 106.691967 \n",
       "L 135.512037 97.436388 \n",
       "L 135.512037 97.422615 \n",
       "L 135.512037 97.415728 \n",
       "L 150.490696 88.270334 \n",
       "L 150.490696 88.263448 \n",
       "L 164.929582 79.627662 \n",
       "L 177.985305 71.756288 \n",
       "L 177.985305 71.742514 \n",
       "L 191.074763 64.119057 \n",
       "L 191.108499 64.112171 \n",
       "L 205.952214 57.1636 \n",
       "L 205.952214 57.156713 \n",
       "L 220.762194 50.648884 \n",
       "L 234.526366 45.284229 \n",
       "L 234.526366 45.277343 \n",
       "L 234.560102 45.277343 \n",
       "L 248.729103 40.794171 \n",
       "L 248.729103 40.787285 \n",
       "L 260.772754 36.834381 \n",
       "L 260.772754 36.820608 \n",
       "L 271.770597 33.294673 \n",
       "L 271.804333 33.287787 \n",
       "L 282.835912 30.133728 \n",
       "L 282.835912 30.119954 \n",
       "L 292.787949 27.812946 \n",
       "L 292.787949 27.80606 \n",
       "L 301.525499 25.726309 \n",
       "L 309.385921 23.82561 \n",
       "L 309.419657 23.818723 \n",
       "L 316.571629 22.393199 \n",
       "L 323.18383 21.043427 \n",
       "L 323.217565 21.043427 \n",
       "L 329.08758 20.093077 \n",
       "L 333.878052 19.397531 \n",
       "L 333.911787 19.397531 \n",
       "L 338.634788 18.777738 \n",
       "L 343.357788 18.378316 \n",
       "L 347.237396 18.047759 \n",
       "L 350.138667 17.779182 \n",
       "L 352.533903 17.545038 \n",
       "L 354.389368 17.421079 \n",
       "L 356.548453 17.310894 \n",
       "L 358.032825 17.228255 \n",
       "L 359.281046 17.200708 \n",
       "L 360.191911 17.166275 \n",
       "L 361.102775 17.118069 \n",
       "L 362.047375 17.104296 \n",
       "L 362.48594 17.09741 \n",
       "L 363.025711 17.083636 \n",
       "L 363.160654 17.083636 \n",
       "L 363.261861 17.083636 \n",
       "L 363.329332 17.083636 \n",
       "L 363.363068 17.083636 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-opacity:0.8;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path clip-path=\"url(#pb5a98b660a)\" d=\"M 58.999432 214.756364 \n",
       "L 59.100639 214.253642 \n",
       "L 59.16811 214.191663 \n",
       "L 59.269318 213.206881 \n",
       "L 59.336789 213.138015 \n",
       "L 59.437996 212.552654 \n",
       "L 59.471732 212.552654 \n",
       "L 59.572939 211.953521 \n",
       "L 59.606675 211.953521 \n",
       "L 59.707882 211.554099 \n",
       "L 59.741618 211.554099 \n",
       "L 59.842825 211.037604 \n",
       "L 59.944032 210.975625 \n",
       "L 60.045239 210.169894 \n",
       "L 60.078975 210.169894 \n",
       "L 60.180182 209.522554 \n",
       "L 60.213918 209.522554 \n",
       "L 60.315125 208.992286 \n",
       "L 60.382596 208.978513 \n",
       "L 60.483803 207.71138 \n",
       "L 60.618746 207.601195 \n",
       "L 60.719953 207.394597 \n",
       "L 60.854896 207.298185 \n",
       "L 60.956103 206.657732 \n",
       "L 60.989839 206.657732 \n",
       "L 61.091046 206.251423 \n",
       "L 61.158518 206.23765 \n",
       "L 61.259725 205.962186 \n",
       "L 61.360932 205.87266 \n",
       "L 61.462139 205.714269 \n",
       "L 61.563346 205.700496 \n",
       "L 61.664553 205.342393 \n",
       "L 61.698289 205.342393 \n",
       "L 61.799496 204.819012 \n",
       "L 61.934439 204.736373 \n",
       "L 62.035646 204.151012 \n",
       "L 62.204325 204.061487 \n",
       "L 62.305532 203.75159 \n",
       "L 62.440475 203.73093 \n",
       "L 62.541682 203.407261 \n",
       "L 62.609154 203.400374 \n",
       "L 62.710361 202.966519 \n",
       "L 62.777832 202.925199 \n",
       "L 62.879039 202.615303 \n",
       "L 63.013982 202.567096 \n",
       "L 63.115189 202.326066 \n",
       "L 63.216396 202.243427 \n",
       "L 63.283868 201.5892 \n",
       "L 63.452546 201.540994 \n",
       "L 63.553754 200.934974 \n",
       "L 63.654961 200.845448 \n",
       "L 63.756168 200.521779 \n",
       "L 63.823639 200.43914 \n",
       "L 63.924846 200.315181 \n",
       "L 64.093525 200.204995 \n",
       "L 64.194732 199.874439 \n",
       "L 64.295939 199.77114 \n",
       "L 64.397146 199.585202 \n",
       "L 64.430882 199.585202 \n",
       "L 64.532089 199.16512 \n",
       "L 64.667032 199.096254 \n",
       "L 64.768239 198.813904 \n",
       "L 64.903182 198.703718 \n",
       "L 65.004389 198.407595 \n",
       "L 65.105597 198.393822 \n",
       "L 65.206804 198.221657 \n",
       "L 65.274275 198.111472 \n",
       "L 65.341747 197.636297 \n",
       "L 65.442954 197.594977 \n",
       "L 65.544161 197.126689 \n",
       "L 65.679104 197.02339 \n",
       "L 65.780311 196.651514 \n",
       "L 65.915254 196.561988 \n",
       "L 66.016461 196.327844 \n",
       "L 66.117668 196.320958 \n",
       "L 66.218875 195.914649 \n",
       "L 66.286347 195.866443 \n",
       "L 66.387554 195.349948 \n",
       "L 66.623704 195.246649 \n",
       "L 66.691175 195.102031 \n",
       "L 66.961061 195.033165 \n",
       "L 67.062268 194.468465 \n",
       "L 67.096004 194.468465 \n",
       "L 67.197211 194.007063 \n",
       "L 67.264682 193.938197 \n",
       "L 67.332154 193.841785 \n",
       "L 67.399625 193.841785 \n",
       "L 67.500832 193.552548 \n",
       "L 67.534568 193.552548 \n",
       "L 67.635775 193.070486 \n",
       "L 67.736982 192.967188 \n",
       "L 67.83819 192.753703 \n",
       "L 67.939397 192.71927 \n",
       "L 68.040604 192.492013 \n",
       "L 68.141811 192.443807 \n",
       "L 68.243018 191.954859 \n",
       "L 68.31049 191.858446 \n",
       "L 68.411697 191.369498 \n",
       "L 68.54664 191.266199 \n",
       "L 68.647847 190.983849 \n",
       "L 68.749054 190.94253 \n",
       "L 68.850261 190.708386 \n",
       "L 68.917733 190.646406 \n",
       "L 69.01894 190.398489 \n",
       "L 69.120147 190.31585 \n",
       "L 69.221354 190.026613 \n",
       "L 69.288825 190.005953 \n",
       "L 69.390033 189.751149 \n",
       "L 69.558711 189.661624 \n",
       "L 69.626183 189.558325 \n",
       "L 69.794861 189.517005 \n",
       "L 69.896068 189.227768 \n",
       "L 70.064747 189.124469 \n",
       "L 70.165954 188.663068 \n",
       "L 70.267161 188.628635 \n",
       "L 70.368368 188.298078 \n",
       "L 70.402104 188.298078 \n",
       "L 70.503311 187.988182 \n",
       "L 70.537047 187.988182 \n",
       "L 70.638254 187.698945 \n",
       "L 70.773197 187.602533 \n",
       "L 70.874404 187.285749 \n",
       "L 70.975611 187.189337 \n",
       "L 71.076818 187.003399 \n",
       "L 71.178026 186.906987 \n",
       "L 71.279233 186.700389 \n",
       "L 71.346704 186.631523 \n",
       "L 71.447911 186.500678 \n",
       "L 71.582854 186.390493 \n",
       "L 71.684061 186.225214 \n",
       "L 71.785268 186.115029 \n",
       "L 71.886476 185.915318 \n",
       "L 72.021418 185.818905 \n",
       "L 72.122626 185.653627 \n",
       "L 72.223833 185.564102 \n",
       "L 72.32504 185.412597 \n",
       "L 72.392511 185.343731 \n",
       "L 72.493719 185.040721 \n",
       "L 72.594926 184.958081 \n",
       "L 72.696133 184.75837 \n",
       "L 72.763604 184.717051 \n",
       "L 72.864811 184.489793 \n",
       "L 73.067226 184.400268 \n",
       "L 73.168433 184.166123 \n",
       "L 73.235904 184.138577 \n",
       "L 73.337111 183.739155 \n",
       "L 73.50579 183.635856 \n",
       "L 73.606997 183.387939 \n",
       "L 73.674469 183.319073 \n",
       "L 73.775676 183.071155 \n",
       "L 73.843147 183.050496 \n",
       "L 73.944354 182.726826 \n",
       "L 74.045561 182.692393 \n",
       "L 74.146769 182.472022 \n",
       "L 74.416654 182.382496 \n",
       "L 74.484126 182.120806 \n",
       "L 74.652804 182.024393 \n",
       "L 74.754012 181.838455 \n",
       "L 74.855219 181.797136 \n",
       "L 74.956426 181.659404 \n",
       "L 75.023897 181.611198 \n",
       "L 75.057633 181.452806 \n",
       "L 75.192576 181.349507 \n",
       "L 75.293783 181.12225 \n",
       "L 75.428726 181.025838 \n",
       "L 75.529933 180.805467 \n",
       "L 75.63114 180.750374 \n",
       "L 75.732347 180.550663 \n",
       "L 75.766083 180.550663 \n",
       "L 75.86729 180.220106 \n",
       "L 76.069704 180.109921 \n",
       "L 76.170912 179.999735 \n",
       "L 76.238383 179.979076 \n",
       "L 76.33959 179.655406 \n",
       "L 76.407062 179.54522 \n",
       "L 76.508269 179.428148 \n",
       "L 76.710683 179.345509 \n",
       "L 76.81189 179.255984 \n",
       "L 77.115512 179.166458 \n",
       "L 77.216719 178.973633 \n",
       "L 77.28419 178.946087 \n",
       "L 77.385397 178.581098 \n",
       "L 77.587812 178.470912 \n",
       "L 77.689019 178.133469 \n",
       "L 77.790226 178.037057 \n",
       "L 77.891433 177.913098 \n",
       "L 78.026376 177.871779 \n",
       "L 78.127583 177.382831 \n",
       "L 78.329998 177.286418 \n",
       "L 78.431205 177.183119 \n",
       "L 78.599883 177.072934 \n",
       "L 78.667355 176.914542 \n",
       "L 78.903505 176.825017 \n",
       "L 79.004712 176.55644 \n",
       "L 79.17339 176.466914 \n",
       "L 79.274598 176.260316 \n",
       "L 79.40954 176.205223 \n",
       "L 79.510748 176.039945 \n",
       "L 79.611955 175.92976 \n",
       "L 79.713162 175.750708 \n",
       "L 79.814369 175.64741 \n",
       "L 79.915576 175.3444 \n",
       "L 80.185462 175.254874 \n",
       "L 80.286669 175.117142 \n",
       "L 80.556555 175.013843 \n",
       "L 80.657762 174.765926 \n",
       "L 80.691498 174.765926 \n",
       "L 80.792705 174.573101 \n",
       "L 81.028855 174.462916 \n",
       "L 81.130062 174.366503 \n",
       "L 81.298741 174.270091 \n",
       "L 81.399948 174.187452 \n",
       "L 81.602362 174.077267 \n",
       "L 81.703569 173.925762 \n",
       "L 81.838512 173.850009 \n",
       "L 81.939719 173.491906 \n",
       "L 82.142133 173.402381 \n",
       "L 82.243341 173.299082 \n",
       "L 82.277076 173.299082 \n",
       "L 82.378284 173.078711 \n",
       "L 82.580698 172.975412 \n",
       "L 82.681905 172.706835 \n",
       "L 82.749376 172.610423 \n",
       "L 82.850584 172.458918 \n",
       "L 82.985526 172.355619 \n",
       "L 83.086734 172.259206 \n",
       "L 83.255412 172.169681 \n",
       "L 83.356619 172.080155 \n",
       "L 83.424091 171.997516 \n",
       "L 83.525298 171.790918 \n",
       "L 83.660241 171.728939 \n",
       "L 83.761448 171.32263 \n",
       "L 83.896391 171.253764 \n",
       "L 83.997598 170.985187 \n",
       "L 84.132541 170.971414 \n",
       "L 84.233748 170.751043 \n",
       "L 84.267484 170.751043 \n",
       "L 84.368691 170.468693 \n",
       "L 84.469898 170.379167 \n",
       "L 84.571105 170.062384 \n",
       "L 84.672312 169.959085 \n",
       "L 84.773519 169.704281 \n",
       "L 84.975934 169.600982 \n",
       "L 85.077141 169.263539 \n",
       "L 85.178348 169.167127 \n",
       "L 85.245819 169.063828 \n",
       "L 85.583177 168.953642 \n",
       "L 85.684384 168.87789 \n",
       "L 85.920534 168.802137 \n",
       "L 86.021741 168.423375 \n",
       "L 86.257891 168.313189 \n",
       "L 86.359098 168.258097 \n",
       "L 86.628984 168.147911 \n",
       "L 86.730191 168.023953 \n",
       "L 86.89887 167.920654 \n",
       "L 87.000077 167.631417 \n",
       "L 87.269962 167.528118 \n",
       "L 87.37117 167.280201 \n",
       "L 87.573584 167.183788 \n",
       "L 87.674791 167.032283 \n",
       "L 87.775998 166.956531 \n",
       "L 87.877205 166.701727 \n",
       "L 88.012148 166.612201 \n",
       "L 88.113355 166.474469 \n",
       "L 88.214563 166.384944 \n",
       "L 88.31577 166.185233 \n",
       "L 88.383241 166.13014 \n",
       "L 88.416977 165.985521 \n",
       "L 88.720598 165.895996 \n",
       "L 88.821805 165.758264 \n",
       "L 88.956748 165.654965 \n",
       "L 89.02422 165.517233 \n",
       "L 89.226634 165.413934 \n",
       "L 89.327841 165.310635 \n",
       "L 89.462784 165.227996 \n",
       "L 89.563991 165.104038 \n",
       "L 89.73267 164.993852 \n",
       "L 89.800141 164.924986 \n",
       "L 90.002555 164.828574 \n",
       "L 90.103763 164.601317 \n",
       "L 90.20497 164.518677 \n",
       "L 90.306177 164.325853 \n",
       "L 90.44112 164.222554 \n",
       "L 90.542327 164.084822 \n",
       "L 90.744741 163.981523 \n",
       "L 90.845948 163.905771 \n",
       "L 91.014627 163.823132 \n",
       "L 91.115834 163.699173 \n",
       "L 91.217041 163.595874 \n",
       "L 91.318248 163.471915 \n",
       "L 91.38572 163.451256 \n",
       "L 91.486927 162.982967 \n",
       "L 91.588134 162.914102 \n",
       "L 91.689341 162.75571 \n",
       "L 91.790548 162.679957 \n",
       "L 91.85802 162.43204 \n",
       "L 91.959227 162.342514 \n",
       "L 92.060434 162.218556 \n",
       "L 92.161641 162.12903 \n",
       "L 92.262849 161.949979 \n",
       "L 92.465263 161.853566 \n",
       "L 92.56647 161.736494 \n",
       "L 92.768884 161.633196 \n",
       "L 92.870091 161.578103 \n",
       "L 92.937563 161.54367 \n",
       "L 93.03877 161.357732 \n",
       "L 93.207449 161.26132 \n",
       "L 93.308656 161.027175 \n",
       "L 93.376127 161.020289 \n",
       "L 93.477334 160.737939 \n",
       "L 93.74722 160.662186 \n",
       "L 93.848427 160.496908 \n",
       "L 93.915899 160.414269 \n",
       "L 94.017106 160.33163 \n",
       "L 94.118313 160.26965 \n",
       "L 94.21952 160.042393 \n",
       "L 94.388199 159.932207 \n",
       "L 94.489406 159.760043 \n",
       "L 94.624349 159.649857 \n",
       "L 94.725556 159.601651 \n",
       "L 94.894234 159.512125 \n",
       "L 94.995442 159.415713 \n",
       "L 95.062913 159.395053 \n",
       "L 95.130384 159.195342 \n",
       "L 95.299063 159.09893 \n",
       "L 95.40027 158.899219 \n",
       "L 95.501477 158.830353 \n",
       "L 95.602684 158.603095 \n",
       "L 95.838834 158.548002 \n",
       "L 95.906306 158.341405 \n",
       "L 96.041249 158.238106 \n",
       "L 96.142456 158.031508 \n",
       "L 96.277399 157.955756 \n",
       "L 96.378606 157.742271 \n",
       "L 96.446077 157.694065 \n",
       "L 96.547285 157.528787 \n",
       "L 96.58102 157.528787 \n",
       "L 96.682227 157.315303 \n",
       "L 96.715963 157.315303 \n",
       "L 96.81717 157.053612 \n",
       "L 96.918377 156.950313 \n",
       "L 97.019585 156.867674 \n",
       "L 97.154527 156.805695 \n",
       "L 97.255735 156.640417 \n",
       "L 97.424413 156.530231 \n",
       "L 97.52562 156.392499 \n",
       "L 97.694299 156.2892 \n",
       "L 97.76177 156.206561 \n",
       "L 97.964185 156.117036 \n",
       "L 98.065392 155.827799 \n",
       "L 98.200335 155.765819 \n",
       "L 98.301542 155.607428 \n",
       "L 98.47022 155.497242 \n",
       "L 98.571428 155.228665 \n",
       "L 98.740106 155.11848 \n",
       "L 98.841313 154.712171 \n",
       "L 99.009992 154.622645 \n",
       "L 99.077463 154.4918 \n",
       "L 99.246142 154.402274 \n",
       "L 99.347349 154.002852 \n",
       "L 99.65097 153.947759 \n",
       "L 99.718442 153.803141 \n",
       "L 99.954592 153.699842 \n",
       "L 100.055799 153.589656 \n",
       "L 100.291949 153.493244 \n",
       "L 100.393156 153.272873 \n",
       "L 100.460628 153.21778 \n",
       "L 100.561835 153.080049 \n",
       "L 100.595571 153.080049 \n",
       "L 100.663042 152.866564 \n",
       "L 100.831721 152.756379 \n",
       "L 100.932928 152.67374 \n",
       "L 101.034135 152.604874 \n",
       "L 101.135342 152.356957 \n",
       "L 101.405228 152.267431 \n",
       "L 101.506435 151.991967 \n",
       "L 101.810056 151.888668 \n",
       "L 101.911264 151.675184 \n",
       "L 102.079942 151.564998 \n",
       "L 102.181149 151.468586 \n",
       "L 102.451035 151.358401 \n",
       "L 102.552242 151.234442 \n",
       "L 102.720921 151.179349 \n",
       "L 102.822128 151.000298 \n",
       "L 102.923335 150.965865 \n",
       "L 102.990806 150.83502 \n",
       "L 103.159485 150.821247 \n",
       "L 103.226956 150.587102 \n",
       "L 103.395635 150.504463 \n",
       "L 103.496842 150.339185 \n",
       "L 103.766728 150.242773 \n",
       "L 103.834199 150.132587 \n",
       "L 103.935407 150.036175 \n",
       "L 104.036614 149.912216 \n",
       "L 104.272764 149.857124 \n",
       "L 104.373971 149.705619 \n",
       "L 104.542649 149.616093 \n",
       "L 104.610121 149.437042 \n",
       "L 104.745064 149.333743 \n",
       "L 104.846271 149.189124 \n",
       "L 105.014949 149.106485 \n",
       "L 105.116157 149.023846 \n",
       "L 105.149892 149.023846 \n",
       "L 105.251099 148.803475 \n",
       "L 105.386042 148.748382 \n",
       "L 105.487249 148.638197 \n",
       "L 105.723399 148.541785 \n",
       "L 105.824607 148.410939 \n",
       "L 105.925814 148.355847 \n",
       "L 106.027021 148.197455 \n",
       "L 106.398114 148.08727 \n",
       "L 106.499321 147.963311 \n",
       "L 106.701735 147.873785 \n",
       "L 106.802942 147.694734 \n",
       "L 106.937885 147.625868 \n",
       "L 107.039092 147.501909 \n",
       "L 107.207771 147.412384 \n",
       "L 107.308978 147.253992 \n",
       "L 107.578864 147.15758 \n",
       "L 107.680071 146.889003 \n",
       "L 107.781278 146.778817 \n",
       "L 107.882485 146.592879 \n",
       "L 108.051164 146.517127 \n",
       "L 108.118635 146.448261 \n",
       "L 108.287314 146.386282 \n",
       "L 108.388521 146.152137 \n",
       "L 108.523464 146.103931 \n",
       "L 108.624671 145.835354 \n",
       "L 108.827085 145.738942 \n",
       "L 108.928293 145.587437 \n",
       "L 109.164443 145.511684 \n",
       "L 109.26565 145.263767 \n",
       "L 109.400593 145.188015 \n",
       "L 109.5018 145.022736 \n",
       "L 109.704214 144.967644 \n",
       "L 109.805421 144.616427 \n",
       "L 110.007836 144.513129 \n",
       "L 110.109043 144.451149 \n",
       "L 110.378928 144.34785 \n",
       "L 110.480136 144.258325 \n",
       "L 110.615078 144.223892 \n",
       "L 110.716286 144.099933 \n",
       "L 110.851228 144.024181 \n",
       "L 110.952436 143.810696 \n",
       "L 111.053643 143.721171 \n",
       "L 111.15485 143.659191 \n",
       "L 111.357264 143.549006 \n",
       "L 111.458471 143.487026 \n",
       "L 111.525943 143.43882 \n",
       "L 111.62715 143.314862 \n",
       "L 111.728357 143.287315 \n",
       "L 111.829564 143.15647 \n",
       "L 111.964507 143.060058 \n",
       "L 112.065714 142.929213 \n",
       "L 112.200657 142.825914 \n",
       "L 112.301864 142.777708 \n",
       "L 112.470543 142.674409 \n",
       "L 112.57175 142.55045 \n",
       "L 112.774164 142.460924 \n",
       "L 112.774164 142.412718 \n",
       "L 113.077786 142.302533 \n",
       "L 113.178993 142.102822 \n",
       "L 113.415143 142.006409 \n",
       "L 113.51635 141.813585 \n",
       "L 113.651293 141.710286 \n",
       "L 113.7525 141.545008 \n",
       "L 113.819972 141.462369 \n",
       "L 113.921179 141.180018 \n",
       "L 114.123593 141.097379 \n",
       "L 114.191064 141.000967 \n",
       "L 114.292272 140.890781 \n",
       "L 114.393479 140.787483 \n",
       "L 114.595893 140.725503 \n",
       "L 114.6971 140.608431 \n",
       "L 114.798307 140.518905 \n",
       "L 114.899514 140.456926 \n",
       "L 115.236872 140.381174 \n",
       "L 115.338079 140.243442 \n",
       "L 115.742907 140.147029 \n",
       "L 115.810379 140.057504 \n",
       "L 115.87785 140.057504 \n",
       "L 115.911586 139.76138 \n",
       "L 116.215207 139.692514 \n",
       "L 116.316415 139.492803 \n",
       "L 116.451357 139.437711 \n",
       "L 116.552565 139.21734 \n",
       "L 116.687507 139.134701 \n",
       "L 116.788715 138.934989 \n",
       "L 116.889922 138.89367 \n",
       "L 116.991129 138.755938 \n",
       "L 117.328486 138.652639 \n",
       "L 117.429693 138.618206 \n",
       "L 117.699579 138.514907 \n",
       "L 117.800786 138.404722 \n",
       "L 117.901993 138.397835 \n",
       "L 117.935729 138.273877 \n",
       "L 118.23935 138.211897 \n",
       "L 118.340558 138.108598 \n",
       "L 118.4755 138.039732 \n",
       "L 118.576708 137.819362 \n",
       "L 118.880329 137.722949 \n",
       "L 118.981536 137.537011 \n",
       "L 119.082743 137.447486 \n",
       "L 119.18395 137.371733 \n",
       "L 119.352629 137.268434 \n",
       "L 119.453836 136.965424 \n",
       "L 119.689986 136.862125 \n",
       "L 119.791193 136.758826 \n",
       "L 119.993608 136.662414 \n",
       "L 120.094815 136.345631 \n",
       "L 120.229758 136.235445 \n",
       "L 120.330965 136.118373 \n",
       "L 120.432172 136.042621 \n",
       "L 120.533379 135.849796 \n",
       "L 120.668322 135.739611 \n",
       "L 120.769529 135.546786 \n",
       "L 120.938208 135.457261 \n",
       "L 121.005679 135.257549 \n",
       "L 121.275565 135.154251 \n",
       "L 121.376772 135.078498 \n",
       "L 121.545451 134.975199 \n",
       "L 121.646658 134.747942 \n",
       "L 121.815336 134.699735 \n",
       "L 121.849072 134.582663 \n",
       "L 122.085222 134.500024 \n",
       "L 122.186429 134.320973 \n",
       "L 122.321372 134.210787 \n",
       "L 122.422579 133.96287 \n",
       "L 122.523786 133.859571 \n",
       "L 122.624994 133.68052 \n",
       "L 122.726201 133.597881 \n",
       "L 122.827408 133.315531 \n",
       "L 122.928615 133.205345 \n",
       "L 123.029822 133.09516 \n",
       "L 123.131029 133.03318 \n",
       "L 123.164765 132.874789 \n",
       "L 123.400915 132.764603 \n",
       "L 123.502122 132.537346 \n",
       "L 123.637065 132.475366 \n",
       "L 123.738272 132.261882 \n",
       "L 123.940687 132.193016 \n",
       "L 124.041894 132.020851 \n",
       "L 124.278044 131.924439 \n",
       "L 124.379251 131.80048 \n",
       "L 124.480458 131.710955 \n",
       "L 124.581665 131.580109 \n",
       "L 124.716608 131.51813 \n",
       "L 124.784079 131.414831 \n",
       "L 125.087701 131.304646 \n",
       "L 125.188908 131.139368 \n",
       "L 125.458794 131.036069 \n",
       "L 125.560001 130.960316 \n",
       "L 125.694944 130.898337 \n",
       "L 125.796151 130.739945 \n",
       "L 126.032301 130.62976 \n",
       "L 126.099772 130.554007 \n",
       "L 126.268451 130.443822 \n",
       "L 126.369658 130.374956 \n",
       "L 126.605808 130.26477 \n",
       "L 126.707015 130.085719 \n",
       "L 126.808222 129.975534 \n",
       "L 126.875694 129.886008 \n",
       "L 126.976901 129.837802 \n",
       "L 127.078108 129.624317 \n",
       "L 127.347994 129.534792 \n",
       "L 127.449201 129.438379 \n",
       "L 127.685351 129.348854 \n",
       "L 127.786558 129.211122 \n",
       "L 127.955237 129.107823 \n",
       "L 128.056444 129.045844 \n",
       "L 128.225123 128.970091 \n",
       "L 128.32633 128.832359 \n",
       "L 128.461273 128.722174 \n",
       "L 128.56248 128.584442 \n",
       "L 128.697423 128.474257 \n",
       "L 128.764894 128.432937 \n",
       "L 128.866101 128.322752 \n",
       "L 128.967308 128.191906 \n",
       "L 129.135987 128.081721 \n",
       "L 129.237194 127.992195 \n",
       "L 129.50708 127.88201 \n",
       "L 129.608287 127.751164 \n",
       "L 129.776966 127.696072 \n",
       "L 129.878173 127.523907 \n",
       "L 130.046851 127.434381 \n",
       "L 130.148058 127.303536 \n",
       "L 130.249266 127.21401 \n",
       "L 130.350473 126.883454 \n",
       "L 130.485416 126.800815 \n",
       "L 130.586623 126.690629 \n",
       "L 130.856508 126.594217 \n",
       "L 130.957716 126.539124 \n",
       "L 131.025187 126.497805 \n",
       "L 131.092658 126.380733 \n",
       "L 131.261337 126.277434 \n",
       "L 131.362544 126.153475 \n",
       "L 131.497487 126.070836 \n",
       "L 131.598694 125.926218 \n",
       "L 131.834844 125.850465 \n",
       "L 131.902316 125.788486 \n",
       "L 132.037259 125.685187 \n",
       "L 132.138466 125.588775 \n",
       "L 132.34088 125.485476 \n",
       "L 132.442087 125.347744 \n",
       "L 132.509559 125.320198 \n",
       "L 132.610766 125.09294 \n",
       "L 132.880651 125.017188 \n",
       "L 132.981859 124.900116 \n",
       "L 133.04933 124.886342 \n",
       "L 133.150537 124.707291 \n",
       "L 133.420423 124.617765 \n",
       "L 133.52163 124.46626 \n",
       "L 133.690309 124.362961 \n",
       "L 133.791516 124.170137 \n",
       "L 133.99393 124.073725 \n",
       "L 134.061402 124.025518 \n",
       "L 134.196344 123.991085 \n",
       "L 134.297552 123.853354 \n",
       "L 134.634909 123.750055 \n",
       "L 134.736116 123.626096 \n",
       "L 134.803587 123.564117 \n",
       "L 134.904794 123.316199 \n",
       "L 135.039737 123.206014 \n",
       "L 135.140944 123.040736 \n",
       "L 135.41083 122.944324 \n",
       "L 135.512037 122.813478 \n",
       "L 135.714452 122.703293 \n",
       "L 135.815659 122.655087 \n",
       "L 135.984337 122.586221 \n",
       "L 136.085545 122.420943 \n",
       "L 136.254223 122.310757 \n",
       "L 136.287959 122.269438 \n",
       "L 136.456637 122.166139 \n",
       "L 136.524109 122.111046 \n",
       "L 136.659052 122.055953 \n",
       "L 136.760259 121.938881 \n",
       "L 137.030145 121.876902 \n",
       "L 137.131352 121.663417 \n",
       "L 137.333766 121.587665 \n",
       "L 137.434973 121.518799 \n",
       "L 137.839802 121.429273 \n",
       "L 137.941009 121.257109 \n",
       "L 138.210895 121.174469 \n",
       "L 138.312102 121.016078 \n",
       "L 138.48078 120.905892 \n",
       "L 138.581988 120.823253 \n",
       "L 138.750666 120.78882 \n",
       "L 138.851873 120.595996 \n",
       "L 139.222966 120.48581 \n",
       "L 139.324173 120.423831 \n",
       "L 139.391645 120.375625 \n",
       "L 139.492852 120.1828 \n",
       "L 139.695266 120.113934 \n",
       "L 139.796473 120.010635 \n",
       "L 139.863945 119.90045 \n",
       "L 139.931416 119.852244 \n",
       "L 140.066359 119.824697 \n",
       "L 140.167566 119.494141 \n",
       "L 140.369981 119.439048 \n",
       "L 140.437452 119.287543 \n",
       "L 140.538659 119.239337 \n",
       "L 140.639866 119.018966 \n",
       "L 140.876016 118.915667 \n",
       "L 140.943488 118.881234 \n",
       "L 141.247109 118.784822 \n",
       "L 141.348316 118.695296 \n",
       "L 141.483259 118.598884 \n",
       "L 141.584466 118.447379 \n",
       "L 141.786881 118.34408 \n",
       "L 141.888088 118.227008 \n",
       "L 142.090502 118.158142 \n",
       "L 142.191709 118.04107 \n",
       "L 142.562802 117.930885 \n",
       "L 142.664009 117.841359 \n",
       "L 142.798952 117.793153 \n",
       "L 142.900159 117.682967 \n",
       "L 142.933895 117.682967 \n",
       "L 143.035102 117.421277 \n",
       "L 143.406195 117.345524 \n",
       "L 143.473667 117.283545 \n",
       "L 143.642345 117.194019 \n",
       "L 143.743552 117.097607 \n",
       "L 144.080909 117.021855 \n",
       "L 144.182117 116.822144 \n",
       "L 144.350795 116.711958 \n",
       "L 144.452002 116.601773 \n",
       "L 144.519474 116.532907 \n",
       "L 144.620681 116.298763 \n",
       "L 144.755624 116.26433 \n",
       "L 144.856831 116.147258 \n",
       "L 145.26166 116.037072 \n",
       "L 145.362867 115.864907 \n",
       "L 145.464074 115.809815 \n",
       "L 145.565281 115.623877 \n",
       "L 145.835167 115.513691 \n",
       "L 145.902638 115.479258 \n",
       "L 146.105052 115.389732 \n",
       "L 146.20626 115.252001 \n",
       "L 146.543617 115.162475 \n",
       "L 146.611088 115.086722 \n",
       "L 146.847238 115.03163 \n",
       "L 146.948445 114.804372 \n",
       "L 147.049652 114.769939 \n",
       "L 147.15086 114.522022 \n",
       "L 147.319538 114.411836 \n",
       "L 147.420745 114.212125 \n",
       "L 147.488217 114.163919 \n",
       "L 147.589424 114.026187 \n",
       "L 147.893045 113.916002 \n",
       "L 147.994253 113.833363 \n",
       "L 148.09546 113.79893 \n",
       "L 148.196667 113.571672 \n",
       "L 148.365345 113.482147 \n",
       "L 148.466553 113.351301 \n",
       "L 148.736438 113.254889 \n",
       "L 148.837645 113.117157 \n",
       "L 148.938853 113.006972 \n",
       "L 149.04006 112.938106 \n",
       "L 149.377417 112.84858 \n",
       "L 149.478624 112.676415 \n",
       "L 149.647303 112.600663 \n",
       "L 149.74851 112.442271 \n",
       "L 150.018396 112.345859 \n",
       "L 150.085867 112.276993 \n",
       "L 150.254546 112.2219 \n",
       "L 150.355753 112.029076 \n",
       "L 150.490696 111.967096 \n",
       "L 150.591903 111.801818 \n",
       "L 150.794317 111.705406 \n",
       "L 150.861788 111.478148 \n",
       "L 151.064203 111.381736 \n",
       "L 151.16541 111.154479 \n",
       "L 151.367824 111.071839 \n",
       "L 151.469031 110.940994 \n",
       "L 151.63771 110.830809 \n",
       "L 151.738917 110.70685 \n",
       "L 151.975067 110.603551 \n",
       "L 152.042539 110.328088 \n",
       "L 152.244953 110.224789 \n",
       "L 152.34616 110.114603 \n",
       "L 152.58231 110.011304 \n",
       "L 152.683517 109.949325 \n",
       "L 152.852196 109.83914 \n",
       "L 152.919667 109.7565 \n",
       "L 153.155817 109.660088 \n",
       "L 153.257024 109.611882 \n",
       "L 153.493174 109.529243 \n",
       "L 153.594382 109.467264 \n",
       "L 153.729324 109.357078 \n",
       "L 153.830532 109.246893 \n",
       "L 153.898003 109.17114 \n",
       "L 153.99921 109.026522 \n",
       "L 154.201624 108.923223 \n",
       "L 154.302832 108.840584 \n",
       "L 154.606453 108.737285 \n",
       "L 154.673924 108.592666 \n",
       "L 155.011282 108.482481 \n",
       "L 155.112489 108.344749 \n",
       "L 155.213696 108.289656 \n",
       "L 155.281167 108.089945 \n",
       "L 155.449846 107.993533 \n",
       "L 155.551053 107.890234 \n",
       "L 155.685996 107.800708 \n",
       "L 155.787203 107.69741 \n",
       "L 156.12456 107.600997 \n",
       "L 156.225767 107.504585 \n",
       "L 156.326975 107.401286 \n",
       "L 156.428182 107.35308 \n",
       "L 156.698067 107.270441 \n",
       "L 156.799275 107.153369 \n",
       "L 156.967953 107.07073 \n",
       "L 157.06916 106.932998 \n",
       "L 157.406518 106.822812 \n",
       "L 157.507725 106.74706 \n",
       "L 157.642668 106.7264 \n",
       "L 157.743875 106.540462 \n",
       "L 158.01376 106.430277 \n",
       "L 158.01376 106.388957 \n",
       "L 158.283646 106.278772 \n",
       "L 158.384853 106.230566 \n",
       "L 158.72221 106.12038 \n",
       "L 158.823418 106.065287 \n",
       "L 158.924625 105.989535 \n",
       "L 159.025832 105.893123 \n",
       "L 159.127039 105.789824 \n",
       "L 159.228246 105.679638 \n",
       "L 159.498132 105.569453 \n",
       "L 159.498132 105.562566 \n",
       "L 159.768018 105.500587 \n",
       "L 159.869225 105.349082 \n",
       "L 159.970432 105.280216 \n",
       "L 160.004168 105.204463 \n",
       "L 160.274053 105.094278 \n",
       "L 160.375261 104.880794 \n",
       "L 160.510203 104.784381 \n",
       "L 160.577675 104.694856 \n",
       "L 160.746353 104.619103 \n",
       "L 160.847561 104.536464 \n",
       "L 160.948768 104.440052 \n",
       "L 161.049975 104.254114 \n",
       "L 161.184918 104.157701 \n",
       "L 161.286125 104.088836 \n",
       "L 161.488539 103.97865 \n",
       "L 161.556011 103.882238 \n",
       "L 161.960839 103.806485 \n",
       "L 162.062046 103.71696 \n",
       "L 162.264461 103.627434 \n",
       "L 162.331932 103.537908 \n",
       "L 162.568082 103.427723 \n",
       "L 162.669289 103.241785 \n",
       "L 162.837968 103.179805 \n",
       "L 162.939175 102.925002 \n",
       "L 163.175325 102.835476 \n",
       "L 163.242797 102.76661 \n",
       "L 163.344004 102.74595 \n",
       "L 163.344004 102.649538 \n",
       "L 163.580154 102.560012 \n",
       "L 163.681361 102.436054 \n",
       "L 163.850039 102.325868 \n",
       "L 163.951247 102.112384 \n",
       "L 164.288604 102.015971 \n",
       "L 164.389811 101.885126 \n",
       "L 164.491018 101.823147 \n",
       "L 164.592225 101.595889 \n",
       "L 164.693432 101.506364 \n",
       "L 164.760904 101.389292 \n",
       "L 165.03079 101.292879 \n",
       "L 165.131997 101.086282 \n",
       "L 165.368147 100.996756 \n",
       "L 165.469354 100.872797 \n",
       "L 165.73924 100.762612 \n",
       "L 165.840447 100.631766 \n",
       "L 166.144068 100.542241 \n",
       "L 166.245275 100.432055 \n",
       "L 166.717575 100.335643 \n",
       "L 166.818782 100.184138 \n",
       "L 167.021197 100.073953 \n",
       "L 167.122404 100.03952 \n",
       "L 167.324818 99.97754 \n",
       "L 167.426025 99.894901 \n",
       "L 167.830854 99.784716 \n",
       "L 167.932061 99.722736 \n",
       "L 168.134475 99.619438 \n",
       "L 168.235683 99.516139 \n",
       "L 168.539304 99.419726 \n",
       "L 168.640511 99.357747 \n",
       "L 168.944133 99.281995 \n",
       "L 169.04534 99.206242 \n",
       "L 169.247754 99.10983 \n",
       "L 169.348961 99.013417 \n",
       "L 169.551376 98.923892 \n",
       "L 169.652583 98.855026 \n",
       "L 169.854997 98.78616 \n",
       "L 169.956204 98.682861 \n",
       "L 170.124883 98.620882 \n",
       "L 170.22609 98.434944 \n",
       "L 170.529711 98.331645 \n",
       "L 170.597183 98.242119 \n",
       "L 170.833333 98.145707 \n",
       "L 170.900804 98.035521 \n",
       "L 171.069483 97.925336 \n",
       "L 171.17069 97.83581 \n",
       "L 171.474311 97.732511 \n",
       "L 171.575519 97.670532 \n",
       "L 171.845404 97.587893 \n",
       "L 171.946611 97.470821 \n",
       "L 172.553854 97.360635 \n",
       "L 172.655061 97.264223 \n",
       "L 172.82374 97.195357 \n",
       "L 172.924947 97.098945 \n",
       "L 173.262304 96.98876 \n",
       "L 173.363512 96.892347 \n",
       "L 173.53219 96.789048 \n",
       "L 173.599662 96.699523 \n",
       "L 174.00449 96.589337 \n",
       "L 174.105697 96.499811 \n",
       "L 174.375583 96.396513 \n",
       "L 174.443054 96.348306 \n",
       "L 174.780412 96.258781 \n",
       "L 174.881619 96.107276 \n",
       "L 175.084033 96.031523 \n",
       "L 175.18524 95.955771 \n",
       "L 175.488862 95.880018 \n",
       "L 175.590069 95.776719 \n",
       "L 175.961162 95.687194 \n",
       "L 176.028633 95.556348 \n",
       "L 176.332255 95.459936 \n",
       "L 176.399726 95.397957 \n",
       "L 176.60214 95.335978 \n",
       "L 176.703347 95.177586 \n",
       "L 176.973233 95.122493 \n",
       "L 177.07444 94.950328 \n",
       "L 177.31059 94.847029 \n",
       "L 177.411798 94.736844 \n",
       "L 177.580476 94.626659 \n",
       "L 177.681683 94.52336 \n",
       "L 177.850362 94.413174 \n",
       "L 177.951569 94.254783 \n",
       "L 178.25519 94.172144 \n",
       "L 178.356398 93.999979 \n",
       "L 178.49134 93.931113 \n",
       "L 178.592548 93.834701 \n",
       "L 178.761226 93.745175 \n",
       "L 178.862433 93.669422 \n",
       "L 179.233526 93.57301 \n",
       "L 179.334733 93.538577 \n",
       "L 179.570883 93.435278 \n",
       "L 179.672091 93.256227 \n",
       "L 179.739562 93.166701 \n",
       "L 179.807033 93.111608 \n",
       "L 180.178126 93.028969 \n",
       "L 180.245598 92.960103 \n",
       "L 180.616691 92.863691 \n",
       "L 180.684162 92.808598 \n",
       "L 181.156462 92.698413 \n",
       "L 181.257669 92.636434 \n",
       "L 181.628762 92.533135 \n",
       "L 181.729969 92.416063 \n",
       "L 181.864912 92.333424 \n",
       "L 181.932384 92.209465 \n",
       "L 182.202269 92.106166 \n",
       "L 182.303476 92.064846 \n",
       "L 182.472155 91.954661 \n",
       "L 182.505891 91.878908 \n",
       "L 182.674569 91.844476 \n",
       "L 182.775777 91.672311 \n",
       "L 182.944455 91.562125 \n",
       "L 183.045662 91.486373 \n",
       "L 183.214341 91.376187 \n",
       "L 183.315548 91.341754 \n",
       "L 183.450491 91.245342 \n",
       "L 183.517962 91.093837 \n",
       "L 183.686641 90.990538 \n",
       "L 183.754112 90.921672 \n",
       "L 183.956527 90.811487 \n",
       "L 184.057734 90.742621 \n",
       "L 184.260148 90.639322 \n",
       "L 184.361355 90.591116 \n",
       "L 184.563769 90.48093 \n",
       "L 184.664977 90.418951 \n",
       "L 184.867391 90.350085 \n",
       "L 184.968598 90.260559 \n",
       "L 185.440898 90.150374 \n",
       "L 185.542105 90.067735 \n",
       "L 185.643312 90.019529 \n",
       "L 185.710784 89.888683 \n",
       "L 185.845727 89.806044 \n",
       "L 185.946934 89.565014 \n",
       "L 186.250555 89.461715 \n",
       "L 186.351762 89.317096 \n",
       "L 186.722855 89.213798 \n",
       "L 186.824063 89.124272 \n",
       "L 187.060213 89.048519 \n",
       "L 187.16142 88.924561 \n",
       "L 187.330098 88.821262 \n",
       "L 187.431305 88.745509 \n",
       "L 187.836134 88.635324 \n",
       "L 187.937341 88.573344 \n",
       "L 188.139755 88.470046 \n",
       "L 188.240963 88.38052 \n",
       "L 188.443377 88.297881 \n",
       "L 188.544584 88.194582 \n",
       "L 188.713263 88.105056 \n",
       "L 188.81447 88.043077 \n",
       "L 189.084356 87.939778 \n",
       "L 189.185563 87.884685 \n",
       "L 189.590391 87.802046 \n",
       "L 189.657863 87.671201 \n",
       "L 190.028956 87.561016 \n",
       "L 190.130163 87.47149 \n",
       "L 190.366313 87.361304 \n",
       "L 190.46752 87.223573 \n",
       "L 190.70367 87.12716 \n",
       "L 190.804877 87.058294 \n",
       "L 191.041027 86.948109 \n",
       "L 191.142234 86.913676 \n",
       "L 191.682006 86.80349 \n",
       "L 191.783213 86.679532 \n",
       "L 191.951891 86.583119 \n",
       "L 191.985627 86.466047 \n",
       "L 192.221777 86.383408 \n",
       "L 192.289249 86.183697 \n",
       "L 192.457927 86.080398 \n",
       "L 192.559134 85.983986 \n",
       "L 192.694077 85.880687 \n",
       "L 192.727813 85.853141 \n",
       "L 193.098906 85.763615 \n",
       "L 193.200113 85.618997 \n",
       "L 193.402527 85.508811 \n",
       "L 193.469999 85.460605 \n",
       "L 193.638677 85.364193 \n",
       "L 193.739884 85.28844 \n",
       "L 193.874827 85.226461 \n",
       "L 193.976034 85.123162 \n",
       "L 194.279656 85.019863 \n",
       "L 194.380863 84.937224 \n",
       "L 194.617013 84.847698 \n",
       "L 194.71822 84.785719 \n",
       "L 195.021842 84.675534 \n",
       "L 195.123049 84.592894 \n",
       "L 195.359199 84.510255 \n",
       "L 195.460406 84.393183 \n",
       "L 195.595349 84.310544 \n",
       "L 195.696556 84.165926 \n",
       "L 195.865235 84.062627 \n",
       "L 195.89897 83.979988 \n",
       "L 196.303799 83.876689 \n",
       "L 196.405006 83.828483 \n",
       "L 196.708628 83.718297 \n",
       "L 196.809835 83.614998 \n",
       "L 197.012249 83.504813 \n",
       "L 197.07972 83.47038 \n",
       "L 197.31587 83.360195 \n",
       "L 197.417078 83.298215 \n",
       "L 197.686963 83.194916 \n",
       "L 197.78817 83.084731 \n",
       "L 198.159263 83.002092 \n",
       "L 198.226735 82.88502 \n",
       "L 198.597828 82.774834 \n",
       "L 198.665299 82.623329 \n",
       "L 198.935185 82.533804 \n",
       "L 199.002656 82.361639 \n",
       "L 199.238806 82.279 \n",
       "L 199.340013 82.155041 \n",
       "L 199.643635 82.086175 \n",
       "L 199.744842 81.989763 \n",
       "L 199.947256 81.879577 \n",
       "L 200.014728 81.796938 \n",
       "L 200.284613 81.707413 \n",
       "L 200.385821 81.617887 \n",
       "L 200.588235 81.514588 \n",
       "L 200.655706 81.438836 \n",
       "L 200.824385 81.356196 \n",
       "L 200.925592 81.266671 \n",
       "L 201.330421 81.163372 \n",
       "L 201.431628 81.032527 \n",
       "L 201.667778 80.936114 \n",
       "L 201.768985 80.825929 \n",
       "L 201.903928 80.770836 \n",
       "L 202.005135 80.516032 \n",
       "L 202.275021 80.405847 \n",
       "L 202.308756 80.261228 \n",
       "L 202.747321 80.164816 \n",
       "L 202.848528 80.11661 \n",
       "L 203.084678 80.006424 \n",
       "L 203.185885 79.971991 \n",
       "L 203.556978 79.861806 \n",
       "L 203.658185 79.786054 \n",
       "L 203.894335 79.730961 \n",
       "L 203.995542 79.607002 \n",
       "L 204.231692 79.51059 \n",
       "L 204.3329 79.372858 \n",
       "L 204.535314 79.262673 \n",
       "L 204.636521 79.16626 \n",
       "L 204.906407 79.097394 \n",
       "L 205.007614 79.000982 \n",
       "L 205.210028 78.897683 \n",
       "L 205.311235 78.835704 \n",
       "L 205.547385 78.739292 \n",
       "L 205.648592 78.663539 \n",
       "L 205.884742 78.553354 \n",
       "L 205.952214 78.429395 \n",
       "L 206.289571 78.319209 \n",
       "L 206.390778 78.250344 \n",
       "L 206.559457 78.147045 \n",
       "L 206.660664 78.119498 \n",
       "L 206.863078 78.009313 \n",
       "L 206.93055 77.940447 \n",
       "L 207.301643 77.850921 \n",
       "L 207.40285 77.733849 \n",
       "L 207.537793 77.664983 \n",
       "L 207.537793 77.603004 \n",
       "L 207.773943 77.506592 \n",
       "L 207.773943 77.485932 \n",
       "L 207.976357 77.403293 \n",
       "L 208.043828 77.334427 \n",
       "L 208.448657 77.224241 \n",
       "L 208.549864 77.134716 \n",
       "L 208.752278 77.04519 \n",
       "L 208.786014 76.996984 \n",
       "L 208.954693 76.886798 \n",
       "L 209.0559 76.804159 \n",
       "L 209.224578 76.735293 \n",
       "L 209.325786 76.570015 \n",
       "L 209.595671 76.466716 \n",
       "L 209.696878 76.377191 \n",
       "L 209.798086 76.273892 \n",
       "L 209.899293 76.205026 \n",
       "L 210.101707 76.122387 \n",
       "L 210.135443 76.081067 \n",
       "L 210.540271 75.984655 \n",
       "L 210.641479 75.895129 \n",
       "L 210.776421 75.798717 \n",
       "L 210.877629 75.709191 \n",
       "L 211.080043 75.647212 \n",
       "L 211.18125 75.502593 \n",
       "L 211.586079 75.406181 \n",
       "L 211.65355 75.364862 \n",
       "L 212.024643 75.268449 \n",
       "L 212.12585 75.151377 \n",
       "L 212.530679 75.041192 \n",
       "L 212.59815 74.992986 \n",
       "L 213.07045 74.889687 \n",
       "L 213.137922 74.793275 \n",
       "L 213.407807 74.683089 \n",
       "L 213.475279 74.607337 \n",
       "L 213.54275 74.607337 \n",
       "L 213.643957 74.435172 \n",
       "L 213.812636 74.345646 \n",
       "L 213.913843 74.25612 \n",
       "L 214.116257 74.187254 \n",
       "L 214.217465 74.090842 \n",
       "L 214.521086 73.980657 \n",
       "L 214.588557 73.856698 \n",
       "L 214.790972 73.753399 \n",
       "L 214.892179 73.725853 \n",
       "L 214.993386 73.629441 \n",
       "L 215.060857 73.588121 \n",
       "L 215.499422 73.526142 \n",
       "L 215.600629 73.422843 \n",
       "L 215.836779 73.319544 \n",
       "L 215.90425 73.291998 \n",
       "L 216.005457 73.195585 \n",
       "L 216.039193 73.126719 \n",
       "L 216.241608 73.037194 \n",
       "L 216.309079 73.002761 \n",
       "L 216.545229 72.933895 \n",
       "L 216.646436 72.865029 \n",
       "L 216.916322 72.76173 \n",
       "L 216.950058 72.699751 \n",
       "L 217.253679 72.623998 \n",
       "L 217.32115 72.527586 \n",
       "L 217.624772 72.4174 \n",
       "L 217.692243 72.389854 \n",
       "L 218.063336 72.286555 \n",
       "L 218.164543 72.162597 \n",
       "L 218.434429 72.052411 \n",
       "L 218.535636 71.969772 \n",
       "L 218.872993 71.866473 \n",
       "L 218.974201 71.797607 \n",
       "L 219.277822 71.687422 \n",
       "L 219.277822 71.680535 \n",
       "L 219.547708 71.584123 \n",
       "L 219.648915 71.542803 \n",
       "L 219.817593 71.439504 \n",
       "L 219.885065 71.384412 \n",
       "L 220.154951 71.281113 \n",
       "L 220.256158 71.24668 \n",
       "L 220.694722 71.170927 \n",
       "L 220.728458 71.095175 \n",
       "L 220.930872 71.074515 \n",
       "L 221.032079 70.94367 \n",
       "L 221.200758 70.833484 \n",
       "L 221.301965 70.709526 \n",
       "L 221.571851 70.613113 \n",
       "L 221.673058 70.496041 \n",
       "L 222.145358 70.392742 \n",
       "L 222.212829 70.261897 \n",
       "L 222.482715 70.158598 \n",
       "L 222.583922 70.103506 \n",
       "L 222.887544 70.000207 \n",
       "L 222.988751 69.876248 \n",
       "L 223.157429 69.834929 \n",
       "L 223.157429 69.759176 \n",
       "L 223.697201 69.676537 \n",
       "L 223.798408 69.587011 \n",
       "L 224.10203 69.511259 \n",
       "L 224.203237 69.290888 \n",
       "L 224.439387 69.180702 \n",
       "L 224.473122 69.160043 \n",
       "L 224.979158 69.056744 \n",
       "L 225.080365 68.80194 \n",
       "L 225.350251 68.698641 \n",
       "L 225.383987 68.629775 \n",
       "L 225.923758 68.526476 \n",
       "L 225.957494 68.492043 \n",
       "L 226.362323 68.402517 \n",
       "L 226.396058 68.312992 \n",
       "L 226.632208 68.271672 \n",
       "L 226.733415 68.13394 \n",
       "L 227.037037 68.023755 \n",
       "L 227.138244 67.948002 \n",
       "L 227.475601 67.837817 \n",
       "L 227.576808 67.734518 \n",
       "L 227.812958 67.638106 \n",
       "L 227.914165 67.541694 \n",
       "L 228.049108 67.445281 \n",
       "L 228.082844 67.403962 \n",
       "L 228.420201 67.335096 \n",
       "L 228.487673 67.218024 \n",
       "L 229.027444 67.107838 \n",
       "L 229.094916 67.004539 \n",
       "L 229.29733 66.9219 \n",
       "L 229.364801 66.804828 \n",
       "L 229.668423 66.715303 \n",
       "L 229.735894 66.63955 \n",
       "L 230.039516 66.536251 \n",
       "L 230.140723 66.453612 \n",
       "L 230.511816 66.343427 \n",
       "L 230.545551 66.29522 \n",
       "L 230.882909 66.185035 \n",
       "L 230.95038 66.150602 \n",
       "L 231.085323 66.116169 \n",
       "L 231.18653 65.957777 \n",
       "L 231.557623 65.895798 \n",
       "L 231.625094 65.778726 \n",
       "L 231.996187 65.70986 \n",
       "L 232.097394 65.613448 \n",
       "L 232.36728 65.551469 \n",
       "L 232.468487 65.365531 \n",
       "L 232.637166 65.269118 \n",
       "L 232.738373 65.165819 \n",
       "L 233.176937 65.055634 \n",
       "L 233.176937 65.041861 \n",
       "L 233.581766 64.945448 \n",
       "L 233.649237 64.911016 \n",
       "L 233.851652 64.807717 \n",
       "L 233.952859 64.752624 \n",
       "L 234.458895 64.642438 \n",
       "L 234.560102 64.608005 \n",
       "L 234.796252 64.511593 \n",
       "L 234.897459 64.442727 \n",
       "L 235.20108 64.373861 \n",
       "L 235.302287 64.270562 \n",
       "L 235.605909 64.167264 \n",
       "L 235.707116 64.057078 \n",
       "L 235.977002 63.946893 \n",
       "L 236.044473 63.857367 \n",
       "L 236.348095 63.802274 \n",
       "L 236.449302 63.650769 \n",
       "L 236.651716 63.554357 \n",
       "L 236.752923 63.485491 \n",
       "L 237.191488 63.402852 \n",
       "L 237.191488 63.368419 \n",
       "L 237.596316 63.299553 \n",
       "L 237.697523 63.210027 \n",
       "L 238.304766 63.099842 \n",
       "L 238.405973 63.037863 \n",
       "L 238.743331 62.927677 \n",
       "L 238.844538 62.796832 \n",
       "L 239.114423 62.727966 \n",
       "L 239.215631 62.63844 \n",
       "L 239.384309 62.542028 \n",
       "L 239.485516 62.500708 \n",
       "L 239.721666 62.39741 \n",
       "L 239.822874 62.287224 \n",
       "L 240.328909 62.177039 \n",
       "L 240.430116 62.149492 \n",
       "L 240.632531 62.05308 \n",
       "L 240.733738 61.984214 \n",
       "L 240.834945 61.880915 \n",
       "L 240.936152 61.812049 \n",
       "L 241.307245 61.70875 \n",
       "L 241.408452 61.646771 \n",
       "L 241.712074 61.550359 \n",
       "L 241.813281 61.488379 \n",
       "L 242.150638 61.385081 \n",
       "L 242.251845 61.288668 \n",
       "L 242.487995 61.199143 \n",
       "L 242.589202 61.088957 \n",
       "L 242.994031 60.978772 \n",
       "L 243.095238 60.84104 \n",
       "L 243.466331 60.744628 \n",
       "L 243.567538 60.696421 \n",
       "L 243.904895 60.593123 \n",
       "L 243.972367 60.414071 \n",
       "L 244.444667 60.303886 \n",
       "L 244.512138 60.25568 \n",
       "L 245.018174 60.145494 \n",
       "L 245.119381 60.062855 \n",
       "L 245.389267 59.987102 \n",
       "L 245.490474 59.828711 \n",
       "L 245.659153 59.746072 \n",
       "L 245.659153 59.711639 \n",
       "L 245.99651 59.60834 \n",
       "L 246.030245 59.560134 \n",
       "L 246.536281 59.463721 \n",
       "L 246.603753 59.381082 \n",
       "L 246.772431 59.270897 \n",
       "L 246.839903 59.229577 \n",
       "L 247.278467 59.119392 \n",
       "L 247.379674 59.091846 \n",
       "L 247.717031 58.995433 \n",
       "L 247.750767 58.961 \n",
       "L 248.12186 58.871475 \n",
       "L 248.223067 58.809495 \n",
       "L 248.627896 58.733743 \n",
       "L 248.729103 58.602898 \n",
       "L 249.032724 58.499599 \n",
       "L 249.133931 58.458279 \n",
       "L 249.30261 58.389413 \n",
       "L 249.403817 58.306774 \n",
       "L 249.808646 58.224135 \n",
       "L 249.876117 58.155269 \n",
       "L 250.213474 58.05197 \n",
       "L 250.314681 57.955558 \n",
       "L 250.550831 57.852259 \n",
       "L 250.618303 57.817826 \n",
       "L 250.888189 57.707641 \n",
       "L 250.888189 57.659434 \n",
       "L 251.461696 57.563022 \n",
       "L 251.461696 57.514816 \n",
       "L 252.001467 57.418404 \n",
       "L 252.035203 57.356424 \n",
       "L 252.507503 57.246239 \n",
       "L 252.60871 57.198033 \n",
       "L 252.84486 57.101621 \n",
       "L 252.946067 57.018981 \n",
       "L 253.350896 56.908796 \n",
       "L 253.452103 56.846817 \n",
       "L 253.823196 56.743518 \n",
       "L 253.856932 56.709085 \n",
       "L 254.126817 56.605786 \n",
       "L 254.228025 56.543807 \n",
       "L 254.464175 56.433621 \n",
       "L 254.565382 56.344095 \n",
       "L 254.869003 56.240797 \n",
       "L 254.97021 56.137498 \n",
       "L 255.375039 56.027312 \n",
       "L 255.408775 55.992879 \n",
       "L 255.746132 55.937787 \n",
       "L 255.847339 55.841374 \n",
       "L 256.184696 55.765622 \n",
       "L 256.285903 55.669209 \n",
       "L 256.791939 55.559024 \n",
       "L 256.893146 55.469498 \n",
       "L 257.163032 55.379973 \n",
       "L 257.196768 55.338653 \n",
       "L 257.534125 55.235354 \n",
       "L 257.635332 55.111396 \n",
       "L 257.905218 55.00121 \n",
       "L 258.006425 54.932344 \n",
       "L 258.208839 54.822159 \n",
       "L 258.310046 54.746406 \n",
       "L 258.613668 54.636221 \n",
       "L 258.714875 54.574241 \n",
       "L 259.119703 54.491602 \n",
       "L 259.220911 54.388303 \n",
       "L 259.558268 54.278118 \n",
       "L 259.659475 54.188592 \n",
       "L 259.828154 54.119726 \n",
       "L 259.929361 54.009541 \n",
       "L 260.266718 53.913129 \n",
       "L 260.367925 53.837376 \n",
       "L 260.806489 53.74785 \n",
       "L 260.907696 53.678984 \n",
       "L 261.447468 53.617005 \n",
       "L 261.514939 53.50682 \n",
       "L 261.717354 53.417294 \n",
       "L 261.818561 53.293335 \n",
       "L 262.155918 53.190036 \n",
       "L 262.257125 53.100511 \n",
       "L 262.661954 53.010985 \n",
       "L 262.729425 52.914573 \n",
       "L 263.033047 52.825047 \n",
       "L 263.134254 52.728635 \n",
       "L 263.606554 52.632223 \n",
       "L 263.707761 52.590903 \n",
       "L 263.910175 52.494491 \n",
       "L 263.977647 52.411852 \n",
       "L 264.146325 52.322326 \n",
       "L 264.180061 52.246573 \n",
       "L 264.517418 52.170821 \n",
       "L 264.517418 52.129501 \n",
       "L 264.955982 52.026202 \n",
       "L 265.05719 51.874697 \n",
       "L 265.52949 51.764512 \n",
       "L 265.630697 51.743852 \n",
       "L 265.833111 51.661213 \n",
       "L 265.934318 51.578574 \n",
       "L 266.204204 51.482162 \n",
       "L 266.204204 51.399523 \n",
       "L 266.609033 51.289337 \n",
       "L 266.71024 51.213585 \n",
       "L 267.18254 51.103399 \n",
       "L 267.250011 51.075853 \n",
       "L 267.452426 50.993214 \n",
       "L 267.519897 50.889915 \n",
       "L 267.89099 50.807276 \n",
       "L 267.992197 50.69709 \n",
       "L 268.295818 50.600678 \n",
       "L 268.295818 50.580018 \n",
       "L 268.734383 50.469833 \n",
       "L 268.83559 50.270122 \n",
       "L 269.105476 50.173709 \n",
       "L 269.206683 50.056637 \n",
       "L 269.645247 49.953338 \n",
       "L 269.746454 49.85004 \n",
       "L 270.083811 49.7674 \n",
       "L 270.185019 49.691648 \n",
       "L 270.589847 49.602122 \n",
       "L 270.657319 49.540143 \n",
       "L 271.028411 49.429957 \n",
       "L 271.062147 49.409298 \n",
       "L 271.534447 49.299112 \n",
       "L 271.568183 49.175154 \n",
       "L 271.90554 49.078741 \n",
       "L 272.006747 48.996102 \n",
       "L 272.411576 48.906576 \n",
       "L 272.512783 48.837711 \n",
       "L 272.782669 48.734412 \n",
       "L 272.883876 48.699979 \n",
       "L 273.356176 48.603566 \n",
       "L 273.423647 48.541587 \n",
       "L 273.727269 48.438288 \n",
       "L 273.828476 48.355649 \n",
       "L 274.233305 48.245464 \n",
       "L 274.334512 48.128392 \n",
       "L 274.773076 48.018206 \n",
       "L 274.840547 47.963113 \n",
       "L 275.312848 47.873588 \n",
       "L 275.346583 47.825382 \n",
       "L 275.616469 47.715196 \n",
       "L 275.717676 47.584351 \n",
       "L 275.953826 47.522372 \n",
       "L 276.055033 47.412186 \n",
       "L 276.291183 47.302001 \n",
       "L 276.358655 47.253794 \n",
       "L 276.763483 47.157382 \n",
       "L 276.86469 47.088516 \n",
       "L 277.168312 46.978331 \n",
       "L 277.269519 46.923238 \n",
       "L 277.741819 46.813053 \n",
       "L 277.843026 46.764846 \n",
       "L 277.944233 46.709754 \n",
       "L 278.011705 46.640888 \n",
       "L 278.214119 46.613341 \n",
       "L 278.315326 46.45495 \n",
       "L 278.652683 46.344764 \n",
       "L 278.753891 46.186373 \n",
       "L 279.124983 46.096847 \n",
       "L 279.226191 46.041754 \n",
       "L 279.529812 45.959115 \n",
       "L 279.597284 45.890249 \n",
       "L 279.799698 45.842043 \n",
       "L 279.900905 45.656105 \n",
       "L 280.305734 45.54592 \n",
       "L 280.406941 45.518373 \n",
       "L 280.710562 45.408188 \n",
       "L 280.778034 45.311776 \n",
       "L 281.081655 45.208477 \n",
       "L 281.182862 45.146497 \n",
       "L 281.351541 45.139611 \n",
       "L 281.452748 44.946786 \n",
       "L 281.655162 44.843487 \n",
       "L 281.688898 44.774621 \n",
       "L 282.026255 44.671323 \n",
       "L 282.127462 44.568024 \n",
       "L 282.397348 44.471611 \n",
       "L 282.498555 44.416519 \n",
       "L 282.835912 44.306333 \n",
       "L 282.937119 44.203034 \n",
       "L 283.038327 44.106622 \n",
       "L 283.139534 43.996437 \n",
       "L 283.375684 43.900024 \n",
       "L 283.476891 43.748519 \n",
       "L 283.713041 43.638334 \n",
       "L 283.780512 43.597014 \n",
       "L 284.421491 43.486829 \n",
       "L 284.522698 43.438623 \n",
       "L 285.096205 43.34221 \n",
       "L 285.163677 43.266458 \n",
       "L 285.737184 43.176932 \n",
       "L 285.838391 43.08052 \n",
       "L 286.108277 43.032314 \n",
       "L 286.142013 42.956561 \n",
       "L 286.580577 42.846376 \n",
       "L 286.681784 42.784396 \n",
       "L 286.917934 42.674211 \n",
       "L 287.019141 42.564026 \n",
       "L 287.289027 42.460727 \n",
       "L 287.322763 42.440067 \n",
       "L 287.693856 42.371201 \n",
       "L 287.795063 42.274789 \n",
       "L 288.098684 42.164603 \n",
       "L 288.199891 42.123284 \n",
       "L 288.334834 42.061304 \n",
       "L 288.402306 41.937346 \n",
       "L 288.773398 41.84782 \n",
       "L 288.874606 41.799614 \n",
       "L 289.178227 41.730748 \n",
       "L 289.211963 41.668769 \n",
       "L 289.886677 41.579243 \n",
       "L 289.987884 41.52415 \n",
       "L 290.595127 41.413965 \n",
       "L 290.662599 41.365759 \n",
       "L 291.20237 41.269346 \n",
       "L 291.303577 41.193594 \n",
       "L 291.843349 41.097182 \n",
       "L 291.944556 41.069635 \n",
       "L 292.248177 40.973223 \n",
       "L 292.349384 40.842378 \n",
       "L 292.585534 40.787285 \n",
       "L 292.686742 40.573801 \n",
       "L 292.922892 40.477388 \n",
       "L 292.990363 40.429182 \n",
       "L 293.361456 40.318997 \n",
       "L 293.428927 40.29145 \n",
       "L 293.80002 40.201925 \n",
       "L 293.867492 40.139945 \n",
       "L 294.069906 40.077966 \n",
       "L 294.171113 40.002213 \n",
       "L 294.339792 39.981554 \n",
       "L 294.339792 39.864482 \n",
       "L 294.643413 39.809389 \n",
       "L 294.74462 39.719863 \n",
       "L 295.115713 39.630337 \n",
       "L 295.21692 39.561472 \n",
       "L 295.486806 39.471946 \n",
       "L 295.588013 39.36176 \n",
       "L 295.857899 39.251575 \n",
       "L 295.959106 39.210255 \n",
       "L 296.094049 39.155163 \n",
       "L 296.195256 38.989884 \n",
       "L 296.63382 38.886586 \n",
       "L 296.701292 38.831493 \n",
       "L 297.139856 38.721307 \n",
       "L 297.207328 38.673101 \n",
       "L 297.713363 38.562916 \n",
       "L 297.814571 38.445844 \n",
       "L 298.050721 38.335658 \n",
       "L 298.118192 38.321885 \n",
       "L 298.455549 38.2117 \n",
       "L 298.556756 38.156607 \n",
       "L 298.894114 38.046421 \n",
       "L 298.995321 37.991329 \n",
       "L 299.197735 37.88803 \n",
       "L 299.298942 37.853597 \n",
       "L 299.568828 37.743411 \n",
       "L 299.568828 37.736525 \n",
       "L 300.344749 37.640112 \n",
       "L 300.445956 37.571247 \n",
       "L 300.749578 37.474834 \n",
       "L 300.817049 37.323329 \n",
       "L 301.188142 37.233804 \n",
       "L 301.289349 37.144278 \n",
       "L 301.694178 37.040979 \n",
       "L 301.795385 36.972113 \n",
       "L 302.065271 36.875701 \n",
       "L 302.166478 36.779289 \n",
       "L 302.335157 36.724196 \n",
       "L 302.402628 36.586464 \n",
       "L 302.976135 36.503825 \n",
       "L 303.077342 36.455619 \n",
       "L 303.718321 36.35232 \n",
       "L 303.785792 36.290341 \n",
       "L 304.224357 36.180155 \n",
       "L 304.224357 36.173268 \n",
       "L 304.764128 36.083743 \n",
       "L 304.865335 35.973557 \n",
       "L 305.101485 35.884032 \n",
       "L 305.202693 35.760073 \n",
       "L 305.742464 35.649888 \n",
       "L 305.843671 35.587908 \n",
       "L 306.01235 35.477723 \n",
       "L 306.113557 35.436403 \n",
       "L 306.450914 35.339991 \n",
       "L 306.518385 35.298671 \n",
       "L 306.855743 35.195372 \n",
       "L 306.95695 35.154053 \n",
       "L 307.462986 35.043867 \n",
       "L 307.530457 34.913022 \n",
       "L 307.732871 34.809723 \n",
       "L 307.834078 34.720198 \n",
       "L 308.171436 34.610012 \n",
       "L 308.205171 34.568693 \n",
       "L 308.407586 34.527373 \n",
       "L 308.508793 34.382755 \n",
       "L 308.913621 34.272569 \n",
       "L 308.981093 34.245023 \n",
       "L 309.183507 34.141724 \n",
       "L 309.183507 34.079745 \n",
       "L 309.689543 33.983332 \n",
       "L 309.79075 33.942013 \n",
       "L 309.993164 33.831827 \n",
       "L 310.094371 33.756075 \n",
       "L 310.634143 33.652776 \n",
       "L 310.73535 33.590797 \n",
       "L 311.038972 33.521931 \n",
       "L 311.140179 33.453065 \n",
       "L 311.713686 33.377312 \n",
       "L 311.814893 33.246467 \n",
       "L 312.287193 33.136282 \n",
       "L 312.320929 33.101849 \n",
       "L 312.62455 33.032983 \n",
       "L 312.725757 32.929684 \n",
       "L 313.063115 32.853931 \n",
       "L 313.164322 32.764406 \n",
       "L 313.737829 32.667993 \n",
       "L 313.8053 32.626674 \n",
       "L 314.108922 32.516488 \n",
       "L 314.210129 32.440736 \n",
       "L 314.547486 32.33055 \n",
       "L 314.581222 32.309891 \n",
       "L 314.952315 32.213478 \n",
       "L 315.019786 32.165272 \n",
       "L 315.525822 32.055087 \n",
       "L 315.627029 32.034427 \n",
       "L 316.065593 31.924241 \n",
       "L 316.1668 31.903582 \n",
       "L 316.537893 31.793396 \n",
       "L 316.605365 31.772736 \n",
       "L 317.111401 31.690097 \n",
       "L 317.145136 31.593685 \n",
       "L 317.786115 31.497273 \n",
       "L 317.819851 31.44218 \n",
       "L 318.427093 31.338881 \n",
       "L 318.494565 31.270015 \n",
       "L 318.798186 31.166716 \n",
       "L 318.899394 31.090964 \n",
       "L 319.607844 30.980778 \n",
       "L 319.709051 30.960119 \n",
       "L 319.978936 30.849933 \n",
       "L 320.046408 30.8155 \n",
       "L 320.619915 30.705315 \n",
       "L 320.653651 30.650222 \n",
       "L 321.024744 30.540036 \n",
       "L 321.024744 30.526263 \n",
       "L 321.260894 30.429851 \n",
       "L 321.362101 30.360985 \n",
       "L 321.733194 30.2508 \n",
       "L 321.766929 30.216367 \n",
       "L 322.036815 30.126841 \n",
       "L 322.138022 30.051088 \n",
       "L 322.542851 29.968449 \n",
       "L 322.610322 29.90647 \n",
       "L 322.913944 29.837604 \n",
       "L 322.981415 29.761852 \n",
       "L 323.217565 29.686099 \n",
       "L 323.285037 29.610347 \n",
       "L 323.521187 29.513934 \n",
       "L 323.622394 29.431295 \n",
       "L 324.027222 29.327996 \n",
       "L 324.12843 29.25913 \n",
       "L 324.465787 29.155832 \n",
       "L 324.566994 29.059419 \n",
       "L 325.039294 28.949234 \n",
       "L 325.106765 28.894141 \n",
       "L 325.714008 28.790842 \n",
       "L 325.815215 28.770182 \n",
       "L 326.152573 28.701317 \n",
       "L 326.152573 28.639337 \n",
       "L 326.422458 28.536038 \n",
       "L 326.456194 28.494719 \n",
       "L 327.19838 28.384533 \n",
       "L 327.299587 28.315667 \n",
       "L 327.569473 28.226142 \n",
       "L 327.636944 28.171049 \n",
       "L 328.075508 28.060863 \n",
       "L 328.176716 28.033317 \n",
       "L 328.446601 27.923132 \n",
       "L 328.547809 27.888699 \n",
       "L 328.885166 27.80606 \n",
       "L 328.885166 27.74408 \n",
       "L 329.593616 27.633895 \n",
       "L 329.694823 27.620122 \n",
       "L 330.167123 27.516823 \n",
       "L 330.26833 27.44107 \n",
       "L 330.571952 27.379091 \n",
       "L 330.639423 27.303338 \n",
       "L 331.381609 27.193153 \n",
       "L 331.482816 27.124287 \n",
       "L 331.955116 27.041648 \n",
       "L 331.988852 27.000328 \n",
       "L 332.15753 26.931462 \n",
       "L 332.258737 26.828164 \n",
       "L 332.697302 26.731751 \n",
       "L 332.731037 26.690432 \n",
       "L 332.933452 26.580246 \n",
       "L 333.000923 26.5527 \n",
       "L 333.304545 26.442514 \n",
       "L 333.405752 26.394308 \n",
       "L 333.709373 26.304783 \n",
       "L 333.81058 26.215257 \n",
       "L 334.28288 26.105071 \n",
       "L 334.384088 26.049979 \n",
       "L 335.126273 25.94668 \n",
       "L 335.193745 25.919133 \n",
       "L 335.632309 25.808948 \n",
       "L 335.69978 25.726309 \n",
       "L 335.969666 25.636783 \n",
       "L 336.037138 25.60235 \n",
       "L 336.475702 25.492165 \n",
       "L 336.543173 25.464618 \n",
       "L 336.880531 25.368206 \n",
       "L 336.914266 25.27868 \n",
       "L 337.521509 25.202928 \n",
       "L 337.521509 25.161608 \n",
       "L 338.162488 25.05831 \n",
       "L 338.263695 24.97567 \n",
       "L 338.567316 24.872372 \n",
       "L 338.668524 24.803506 \n",
       "L 339.107088 24.700207 \n",
       "L 339.174559 24.658887 \n",
       "L 339.579388 24.548702 \n",
       "L 339.680595 24.528042 \n",
       "L 340.017952 24.43163 \n",
       "L 340.119159 24.355877 \n",
       "L 340.321574 24.266351 \n",
       "L 340.389045 24.169939 \n",
       "L 340.827609 24.06664 \n",
       "L 340.928817 23.977115 \n",
       "L 341.299909 23.866929 \n",
       "L 341.367381 23.832496 \n",
       "L 341.738474 23.729197 \n",
       "L 341.805945 23.667218 \n",
       "L 342.278245 23.557033 \n",
       "L 342.345717 23.543259 \n",
       "L 342.750545 23.43996 \n",
       "L 342.851752 23.398641 \n",
       "L 343.42526 23.309115 \n",
       "L 343.492731 23.233363 \n",
       "L 343.830088 23.130064 \n",
       "L 343.931295 23.061198 \n",
       "L 344.268653 22.964786 \n",
       "L 344.336124 22.91658 \n",
       "L 344.774688 22.806394 \n",
       "L 344.808424 22.792621 \n",
       "L 345.179517 22.682435 \n",
       "L 345.246988 22.641116 \n",
       "L 345.651817 22.53093 \n",
       "L 345.719288 22.489611 \n",
       "L 346.191588 22.379425 \n",
       "L 346.292796 22.331219 \n",
       "L 346.832567 22.221034 \n",
       "L 346.900038 22.179714 \n",
       "L 347.608488 22.069529 \n",
       "L 347.67596 22.014436 \n",
       "L 347.945846 21.92491 \n",
       "L 348.047053 21.883591 \n",
       "L 348.62056 21.780292 \n",
       "L 348.721767 21.711426 \n",
       "L 348.924181 21.608127 \n",
       "L 349.025389 21.518601 \n",
       "L 349.295274 21.422189 \n",
       "L 349.396481 21.332663 \n",
       "L 349.835046 21.236251 \n",
       "L 349.936253 21.146725 \n",
       "L 350.341082 21.070973 \n",
       "L 350.442289 21.008994 \n",
       "L 350.880853 20.898808 \n",
       "L 350.98206 20.857489 \n",
       "L 351.420624 20.774849 \n",
       "L 351.521832 20.678437 \n",
       "L 351.825453 20.568252 \n",
       "L 351.892924 20.554479 \n",
       "L 352.297753 20.492499 \n",
       "L 352.331489 20.396087 \n",
       "L 353.10741 20.285901 \n",
       "L 353.208617 20.223922 \n",
       "L 353.57971 20.141283 \n",
       "L 353.680917 20.072417 \n",
       "L 354.389368 19.976005 \n",
       "L 354.456839 19.927799 \n",
       "L 355.030346 19.852046 \n",
       "L 355.097818 19.762521 \n",
       "L 355.435175 19.652335 \n",
       "L 355.536382 19.604129 \n",
       "L 355.907475 19.528376 \n",
       "L 356.008682 19.445737 \n",
       "L 356.211096 19.335552 \n",
       "L 356.211096 19.328665 \n",
       "L 356.582189 19.232253 \n",
       "L 356.582189 19.211593 \n",
       "L 357.054489 19.101408 \n",
       "L 357.054489 19.094521 \n",
       "L 357.526789 18.991222 \n",
       "L 357.627996 18.943016 \n",
       "L 357.999089 18.832831 \n",
       "L 358.100296 18.729532 \n",
       "L 358.403918 18.619346 \n",
       "L 358.505125 18.598687 \n",
       "L 359.011161 18.488501 \n",
       "L 359.112368 18.467841 \n",
       "L 359.719611 18.385202 \n",
       "L 359.787082 18.323223 \n",
       "L 360.293118 18.240584 \n",
       "L 360.394325 18.164831 \n",
       "L 360.866625 18.054646 \n",
       "L 360.967832 18.013326 \n",
       "L 361.203982 17.910027 \n",
       "L 361.203982 17.896254 \n",
       "L 361.676282 17.792955 \n",
       "L 361.777489 17.689656 \n",
       "L 362.350997 17.579471 \n",
       "L 362.452204 17.517492 \n",
       "L 362.654618 17.427966 \n",
       "L 362.755825 17.365987 \n",
       "L 363.059447 17.255801 \n",
       "L 363.160654 17.152502 \n",
       "L 363.363068 17.09741 \n",
       "L 363.363068 17.083636 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-opacity:0.8;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 43.78125 224.64 \n",
       "L 43.78125 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 378.58125 224.64 \n",
       "L 378.58125 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 43.78125 224.64 \n",
       "L 378.58125 224.64 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 43.78125 7.2 \n",
       "L 378.58125 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 151.932813 219.64 \n",
       "L 371.58125 219.64 \n",
       "Q 373.58125 219.64 373.58125 217.64 \n",
       "L 373.58125 189.28375 \n",
       "Q 373.58125 187.28375 371.58125 187.28375 \n",
       "L 151.932813 187.28375 \n",
       "Q 149.932813 187.28375 149.932813 189.28375 \n",
       "L 149.932813 217.64 \n",
       "Q 149.932813 219.64 151.932813 219.64 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_15\">\n",
       "     <path d=\"M 153.932813 195.382187 \n",
       "L 173.932813 195.382187 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-opacity:0.8;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_16\"/>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- RandomForestClassifier (AUC = 0.74) -->\n",
       "     <defs>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "      <path d=\"M 45.40625 46.390625 \n",
       "L 45.40625 75.984375 \n",
       "L 54.390625 75.984375 \n",
       "L 54.390625 0 \n",
       "L 45.40625 0 \n",
       "L 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "z\n",
       "M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-100\"/>\n",
       "      <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "      <path d=\"M 64.40625 67.28125 \n",
       "L 64.40625 56.890625 \n",
       "Q 59.421875 61.53125 53.78125 63.8125 \n",
       "Q 48.140625 66.109375 41.796875 66.109375 \n",
       "Q 29.296875 66.109375 22.65625 58.46875 \n",
       "Q 16.015625 50.828125 16.015625 36.375 \n",
       "Q 16.015625 21.96875 22.65625 14.328125 \n",
       "Q 29.296875 6.6875 41.796875 6.6875 \n",
       "Q 48.140625 6.6875 53.78125 8.984375 \n",
       "Q 59.421875 11.28125 64.40625 15.921875 \n",
       "L 64.40625 5.609375 \n",
       "Q 59.234375 2.09375 53.4375 0.328125 \n",
       "Q 47.65625 -1.421875 41.21875 -1.421875 \n",
       "Q 24.65625 -1.421875 15.125 8.703125 \n",
       "Q 5.609375 18.84375 5.609375 36.375 \n",
       "Q 5.609375 53.953125 15.125 64.078125 \n",
       "Q 24.65625 74.21875 41.21875 74.21875 \n",
       "Q 47.75 74.21875 53.53125 72.484375 \n",
       "Q 59.328125 70.75 64.40625 67.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-67\"/>\n",
       "      <path d=\"M 37.109375 75.984375 \n",
       "L 37.109375 68.5 \n",
       "L 28.515625 68.5 \n",
       "Q 23.6875 68.5 21.796875 66.546875 \n",
       "Q 19.921875 64.59375 19.921875 59.515625 \n",
       "L 19.921875 54.6875 \n",
       "L 34.71875 54.6875 \n",
       "L 34.71875 47.703125 \n",
       "L 19.921875 47.703125 \n",
       "L 19.921875 0 \n",
       "L 10.890625 0 \n",
       "L 10.890625 47.703125 \n",
       "L 2.296875 47.703125 \n",
       "L 2.296875 54.6875 \n",
       "L 10.890625 54.6875 \n",
       "L 10.890625 58.5 \n",
       "Q 10.890625 67.625 15.140625 71.796875 \n",
       "Q 19.390625 75.984375 28.609375 75.984375 \n",
       "z\n",
       "\" id=\"DejaVuSans-102\"/>\n",
       "      <path d=\"M 31 75.875 \n",
       "Q 24.46875 64.65625 21.28125 53.65625 \n",
       "Q 18.109375 42.671875 18.109375 31.390625 \n",
       "Q 18.109375 20.125 21.3125 9.0625 \n",
       "Q 24.515625 -2 31 -13.1875 \n",
       "L 23.1875 -13.1875 \n",
       "Q 15.875 -1.703125 12.234375 9.375 \n",
       "Q 8.59375 20.453125 8.59375 31.390625 \n",
       "Q 8.59375 42.28125 12.203125 53.3125 \n",
       "Q 15.828125 64.359375 23.1875 75.875 \n",
       "z\n",
       "\" id=\"DejaVuSans-40\"/>\n",
       "      <path d=\"M 34.1875 63.1875 \n",
       "L 20.796875 26.90625 \n",
       "L 47.609375 26.90625 \n",
       "z\n",
       "M 28.609375 72.90625 \n",
       "L 39.796875 72.90625 \n",
       "L 67.578125 0 \n",
       "L 57.328125 0 \n",
       "L 50.6875 18.703125 \n",
       "L 17.828125 18.703125 \n",
       "L 11.1875 0 \n",
       "L 0.78125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-65\"/>\n",
       "      <path d=\"M 8.6875 72.90625 \n",
       "L 18.609375 72.90625 \n",
       "L 18.609375 28.609375 \n",
       "Q 18.609375 16.890625 22.84375 11.734375 \n",
       "Q 27.09375 6.59375 36.625 6.59375 \n",
       "Q 46.09375 6.59375 50.34375 11.734375 \n",
       "Q 54.59375 16.890625 54.59375 28.609375 \n",
       "L 54.59375 72.90625 \n",
       "L 64.5 72.90625 \n",
       "L 64.5 27.390625 \n",
       "Q 64.5 13.140625 57.4375 5.859375 \n",
       "Q 50.390625 -1.421875 36.625 -1.421875 \n",
       "Q 22.796875 -1.421875 15.734375 5.859375 \n",
       "Q 8.6875 13.140625 8.6875 27.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-85\"/>\n",
       "      <path d=\"M 10.59375 45.40625 \n",
       "L 73.1875 45.40625 \n",
       "L 73.1875 37.203125 \n",
       "L 10.59375 37.203125 \n",
       "z\n",
       "M 10.59375 25.484375 \n",
       "L 73.1875 25.484375 \n",
       "L 73.1875 17.1875 \n",
       "L 10.59375 17.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-61\"/>\n",
       "      <path d=\"M 8.203125 72.90625 \n",
       "L 55.078125 72.90625 \n",
       "L 55.078125 68.703125 \n",
       "L 28.609375 0 \n",
       "L 18.3125 0 \n",
       "L 43.21875 64.59375 \n",
       "L 8.203125 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-55\"/>\n",
       "      <path d=\"M 8.015625 75.875 \n",
       "L 15.828125 75.875 \n",
       "Q 23.140625 64.359375 26.78125 53.3125 \n",
       "Q 30.421875 42.28125 30.421875 31.390625 \n",
       "Q 30.421875 20.453125 26.78125 9.375 \n",
       "Q 23.140625 -1.703125 15.828125 -13.1875 \n",
       "L 8.015625 -13.1875 \n",
       "Q 14.5 -2 17.703125 9.0625 \n",
       "Q 20.90625 20.125 20.90625 31.390625 \n",
       "Q 20.90625 42.671875 17.703125 53.65625 \n",
       "Q 14.5 64.65625 8.015625 75.875 \n",
       "z\n",
       "\" id=\"DejaVuSans-41\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(181.932813 198.882187)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-82\"/>\n",
       "      <use x=\"69.451172\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"130.730469\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"194.109375\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "      <use x=\"257.585938\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"318.767578\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "      <use x=\"416.179688\" xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use x=\"473.652344\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"534.833984\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"575.916016\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"637.439453\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"689.539062\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "      <use x=\"728.748047\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"798.572266\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use x=\"826.355469\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"887.634766\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"939.734375\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"991.833984\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"1019.617188\" xlink:href=\"#DejaVuSans-102\"/>\n",
       "      <use x=\"1054.822266\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"1082.605469\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"1144.128906\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"1185.242188\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"1217.029297\" xlink:href=\"#DejaVuSans-40\"/>\n",
       "      <use x=\"1256.042969\" xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use x=\"1324.451172\" xlink:href=\"#DejaVuSans-85\"/>\n",
       "      <use x=\"1397.644531\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"1467.46875\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"1499.255859\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"1583.044922\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"1614.832031\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      <use x=\"1678.455078\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "      <use x=\"1710.242188\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "      <use x=\"1773.865234\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "      <use x=\"1837.488281\" xlink:href=\"#DejaVuSans-41\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 153.932813 210.060312 \n",
       "L 173.932813 210.060312 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-opacity:0.8;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\"/>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- LinearSVC (AUC = 0.65) -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 19.671875 72.90625 \n",
       "L 19.671875 8.296875 \n",
       "L 55.171875 8.296875 \n",
       "L 55.171875 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-76\"/>\n",
       "      <path d=\"M 53.515625 70.515625 \n",
       "L 53.515625 60.890625 \n",
       "Q 47.90625 63.578125 42.921875 64.890625 \n",
       "Q 37.9375 66.21875 33.296875 66.21875 \n",
       "Q 25.25 66.21875 20.875 63.09375 \n",
       "Q 16.5 59.96875 16.5 54.203125 \n",
       "Q 16.5 49.359375 19.40625 46.890625 \n",
       "Q 22.3125 44.4375 30.421875 42.921875 \n",
       "L 36.375 41.703125 \n",
       "Q 47.40625 39.59375 52.65625 34.296875 \n",
       "Q 57.90625 29 57.90625 20.125 \n",
       "Q 57.90625 9.515625 50.796875 4.046875 \n",
       "Q 43.703125 -1.421875 29.984375 -1.421875 \n",
       "Q 24.8125 -1.421875 18.96875 -0.25 \n",
       "Q 13.140625 0.921875 6.890625 3.21875 \n",
       "L 6.890625 13.375 \n",
       "Q 12.890625 10.015625 18.65625 8.296875 \n",
       "Q 24.421875 6.59375 29.984375 6.59375 \n",
       "Q 38.421875 6.59375 43.015625 9.90625 \n",
       "Q 47.609375 13.234375 47.609375 19.390625 \n",
       "Q 47.609375 24.75 44.3125 27.78125 \n",
       "Q 41.015625 30.8125 33.5 32.328125 \n",
       "L 27.484375 33.5 \n",
       "Q 16.453125 35.6875 11.515625 40.375 \n",
       "Q 6.59375 45.0625 6.59375 53.421875 \n",
       "Q 6.59375 63.09375 13.40625 68.65625 \n",
       "Q 20.21875 74.21875 32.171875 74.21875 \n",
       "Q 37.3125 74.21875 42.625 73.28125 \n",
       "Q 47.953125 72.359375 53.515625 70.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-83\"/>\n",
       "      <path d=\"M 28.609375 0 \n",
       "L 0.78125 72.90625 \n",
       "L 11.078125 72.90625 \n",
       "L 34.1875 11.53125 \n",
       "L 57.328125 72.90625 \n",
       "L 67.578125 72.90625 \n",
       "L 39.796875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-86\"/>\n",
       "      <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(181.932813 213.560312)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use x=\"55.712891\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "      <use x=\"83.496094\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "      <use x=\"146.875\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"208.398438\" xlink:href=\"#DejaVuSans-97\"/>\n",
       "      <use x=\"269.677734\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "      <use x=\"310.791016\" xlink:href=\"#DejaVuSans-83\"/>\n",
       "      <use x=\"374.267578\" xlink:href=\"#DejaVuSans-86\"/>\n",
       "      <use x=\"442.675781\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"512.5\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"544.287109\" xlink:href=\"#DejaVuSans-40\"/>\n",
       "      <use x=\"583.300781\" xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use x=\"651.708984\" xlink:href=\"#DejaVuSans-85\"/>\n",
       "      <use x=\"724.902344\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "      <use x=\"794.726562\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"826.513672\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"910.302734\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"942.089844\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      <use x=\"1005.712891\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "      <use x=\"1037.5\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "      <use x=\"1101.123047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      <use x=\"1164.746094\" xlink:href=\"#DejaVuSans-41\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pb5a98b660a\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Random Forest model vs SVM\n",
    "ax = plt.gca()\n",
    "rfc_disp = plot_roc_curve(rf, X_test, y_test, ax=ax, alpha=0.8)\n",
    "svm_disp.plot(ax=ax, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVCLinear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-863beec980c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVCLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msvc_disp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SVCLinear' is not defined"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(random_state=123)\n",
    "svc.fit(X_train, y_train)\n",
    "svc_disp = plot_roc_curve(svc, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ramdom forest classifier \n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "ax = plt.gca()\n",
    "rfc_disp = plot_roc_curve(rfc, X_test, y_test, ax=ax, alpha=0.8)\n",
    "svc_disp.plot(ax=ax, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = datasets.make_classification(random_state=0)\n",
    "clf = svm.SVC(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "SVC(random_state=0)\n",
    "metrics.det_curve(clf, X_test, y_test)  \n",
    "plt.show()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "rf = RandomForestClassifier()\n",
    "lr = LogisticRegression()\n",
    "nb = GaussianNB()\n",
    "svm = LinearSVC()\n",
    "rf_probas = rf.fit(X_train, y_train).predict_proba(X_test)\n",
    "lr_probas = lr.fit(X_train, y_train).predict_proba(X_test)\n",
    "nb_probas = nb.fit(X_train, y_train).predict_proba(X_test)\n",
    "svm_scores = svm.fit(X_train, y_train).decision_function(X_test)\n",
    "probas_list = [rf_probas, lr_probas, nb_probas, svm_scores]\n",
    "clf_names = ['Random Forest', 'Logistic Regression',\n",
    "              'Gaussian Naive Bayes', 'Support Vector Machine']\n",
    "skplt.metrics.plot_calibration_curve(y_test,\n",
    "                                      probas_list,\n",
    "                                     clf_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.det_curve(clf, X_test, y_test)  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1613960288246,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}